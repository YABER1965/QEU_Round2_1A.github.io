---
title: QEUR21_RL2048T33:　番外編～AACでCARTPOLE
date: 2022-06-14
tags: ["QEUシステム", "メトリックス", "Python言語", "強化学習", "RT法", "ディープラーニング", "2048"]
excerpt: Python言語とディープラーニングを使ったゲーム2048の強化学習
---

## QEUR21_RL2048T33:　番外編～AACでCARTPOLE

## ～　念押しの念押し・・・、これは「趣味のコーナー」です　～

QEU:FOUNDER ： “あ～っと、もうちょっとロボティックスを進めたいなぁ・・・。環境を変えて２０４８みたいに複雑なものじゃなく、OPENAIに入っているCARTPOLEという単純な環境で実験をやってみましょう。”

![imageRL1-33-1](/2022-06-14-QEUR21_RL2048T33/imageRL1-33-1.jpg)

D先生 ： “CARTPOLEの強化学習の事例はWeb上に山ほどあります。”

![imageRL1-33-2](/2022-06-14-QEUR21_RL2048T33/imageRL1-33-2.jpg)

QEU:FOUNDER ： “テキスト（本）を見たかったら、やっぱりこの本（↑）だよね。いろんな手法が学べます。サンプルコードもあるし・・・。今回はCARTPOLEの環境でACTOR-CRITICの学習をします。”

![imageRL1-33-3](/2022-06-14-QEUR21_RL2048T33/imageRL1-33-3.jpg)

D先生 ： “環境に「ある種の最適解」がある場合にはACTOR-CRITIC（AAC）は使いやすいよね。このAAC手法の特殊な点は、ディープラーニングの関数の定義方法です。”

![imageRL1-33-4](/2022-06-14-QEUR21_RL2048T33/imageRL1-33-4.jpg)

QEU:FOUNDER ： “ディープラーニングの関数にはACTOR用とCRITIC用の関数が共存しています。そして、2つの関数の当てはめのために、ACTOR損失とCRITIC損失の足し算を損失LOSSにしています。”

![imageRL1-33-5](/2022-06-14-QEUR21_RL2048T33/imageRL1-33-5.jpg)

QEU:FOUNDER ： “そういえば・・・、「なんとか工学」って多次元多変量の最適化（一石百鳥）をウリにしていたでしょう？いまはディープラーニングがあるから、**多次元多変量（しかも非線形！）の最適化って、いとも簡単にできるようになったんです。**もし大量のデータがあるのならば、無理して基本機能を探さなくてもいいです。”

D先生 ： “じゃあ、プログラムをドン・・・。”

```python
# ----------------
# GYM Cartpoleの強化学習システム
# step7 : AAC_cartpole_agent.py
# step7 : AACで強化学習します
# ---------------- 
import numpy as np
import gym
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.distributions import Categorical

import matplotlib.pyplot as plt
plt.rcParams['figure.figsize'] = (16, 10)

# ------
# Hyperparameters
learning_rate = 0.004
gamma         = 0.99

env = gym.make('CartPole-v0')
input_shape = env.observation_space.shape[0]
num_actions = env.action_space.n
hidden_size = 32

# ------
# ACモデルを定義する
class ACModel(nn.Module):
    def __init__(self, input_shape, num_actions):
        super(ACModel, self).__init__()
        self.fc1 = nn.Linear(input_shape,hidden_size)
        #self.fc2 = nn.Linear(hidden_size,hidden_size)
        self.fc_pi = nn.Linear(hidden_size,num_actions)
        self.fc_v = nn.Linear(hidden_size,1)

    def v(self, x):
        x = F.relu(self.fc1(x))
        # x = F.relu(self.fc2(x))
        v = self.fc_v(x)
        return v

    def pi(self, x, softmax_dim = 0):
        x = F.relu(self.fc1(x))
        #x = F.relu(self.fc2(x))
        x = self.fc_pi(x)
        prob = F.softmax(x, dim=softmax_dim)
        return prob

# --------
# parameters
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
#device

modelAC = ACModel(input_shape, num_actions).to(device)

# --------
# 学習結果を読み出す
model_path = './model_ActorCritic.pth'
modelAC.load_state_dict(torch.load(model_path))

# --------
# Actor-Criticsのクラス
class ActorCritic():
    def __init__(self):
        super(ActorCritic, self).__init__()
        self.data = []        
        #modelAC    = ACModel()
        self.optimizer  = optim.Adam(modelAC.parameters(), lr=learning_rate)
        self.scheduler  = optim.lr_scheduler.StepLR(self.optimizer, step_size=10, gamma=0.98)
    
    def put_data(self, transition):
        self.data.append(transition)
        
    def make_batch(self):
        s_lst, a_lst, r_lst, s_prime_lst, done_lst = [], [], [], [], []
        for transition in self.data:
            s,a,r,s_prime,done = transition
            s_lst.append(s)
            a_lst.append([a])
            r_lst.append([r/100.0])
            s_prime_lst.append(s_prime)
            done_mask = 0.0 if done else 1.0
            done_lst.append([done_mask])
        
        s_lst       = np.array(s_lst)
        #a_lst       = np.array(a_lst)
        r_lst       = np.array(r_lst)
        s_prime_lst = np.array(s_prime_lst)
        s_batch, a_batch, r_batch, s_prime_batch, done_batch = torch.tensor(s_lst, dtype=torch.float), torch.tensor(a_lst), \
                                                               torch.tensor(r_lst, dtype=torch.float), torch.tensor(s_prime_lst, dtype=torch.float), \
                                                               torch.tensor(done_lst, dtype=torch.float)
        self.data = []
        return s_batch, a_batch, r_batch, s_prime_batch, done_batch
  
    def train_net(self):
        s, a, r, s_prime, done = self.make_batch()
        td_target = r + gamma * modelAC.v(s_prime) * done
        delta = td_target - modelAC.v(s)
        
        pi = modelAC.pi(s, softmax_dim=1)
        pi_a = pi.gather(1,a)
        loss = -torch.log(pi_a) * delta.detach() + F.smooth_l1_loss(modelAC.v(s), td_target.detach())

        self.optimizer.zero_grad()
        loss.mean().backward()
        self.optimizer.step()      
        
    def play_game():
        done = False
        state = env.reset()    
        while(not done):        
            prob = modelAC.pi(torch.from_numpy(s).float())
            m = Categorical(prob)
            a = m.sample().item()
            s_prime, r, done, info = env.step(a)
            env.render()
            state = s_prime      
  
# ------
model = ActorCritic()    
n_rollout = 10
print_interval = 10
score = 0.0
iterations = 3000
min_play_reward = 100

# ------
val_episodes = 0
episodes = []
scores = []
for iteration in range(iterations):
    done = False
    s = env.reset()
    while not done:
        #val_reward = 0
        for t in range(n_rollout):
            prob = modelAC.pi(torch.from_numpy(s).float())
            m = Categorical(prob)
            a = m.sample().item()
            s_prime, r, done, info = env.step(a)
            model.put_data((s,a,r,s_prime,done))
                
            s = s_prime
            score += r

            if done:
               break                     

        model.train_net()
            
    if iteration%print_interval==0 and iteration!=0:
        val_episodes = val_episodes + print_interval
        episodes.append(val_episodes)
        scores.append(score/print_interval)
        print("# of episode :{}, avg score : {:.1f}".format(iteration, score/print_interval))
        score = 0.0
env.close()

# --------
# 学習結果を保管する
model_path = './model_ActorCritic2.pth'
torch.save(modelAC.to('cpu').state_dict(), model_path)

# --------
# 結果を表示する
fig = plt.figure()
ax = fig.add_subplot(111)
ax.plot(episodes, scores)
ax.set_ylabel('Score')
ax.set_xlabel('Episode #')
plt.show()

```

QEU:FOUNDER ： “なにはともあれ、学習してみましょう。第1回目の学習をドン！”

**(AACによる第一回目の学習)**

![imageRL1-33-6](/2022-06-14-QEUR21_RL2048T33/imageRL1-33-6.jpg)

D先生 ： “第一回目の学習？”

QEU:FOUNDER ： “わざと短く学習しました。一度、学習結果を一旦ファイルに保存して、読み込んで再度学習します。それが第二回学習です。結果をドン・・・。”

**(AACによる第二回目の学習)**

![imageRL1-33-7](/2022-06-14-QEUR21_RL2048T33/imageRL1-33-7.jpg)

D先生 ： “まあ、前回の学習を読み込んでいますから、当たり前の結果がでました。”

QEU:FOUNDER ： “次は***REINFORCE***にいきましょう。”

## ～　まとめ　～

### ・・・　つづきです　・・・

D先生 : “昔は、関西って半導体が強かったのに・・・。なんで2000年代初めにやめちゃったんだろう・・・。”

![imageRL1-33-8](/2022-06-14-QEUR21_RL2048T33/imageRL1-33-8.jpg)

QEU:FOUNDER : “1990年代末、我らがエズさんの本（KAWAXI）に書いてあったよ。J国は工業生産を海外にシフトさせ、インバウンドを強化すべきだって・・・。その通りにしたんじゃないの？「なんとか30」という本もそうだし・・・。この本のレビューをもう一度みてみましょうか・・・。”

![imageRL1-33-9](/2022-06-14-QEUR21_RL2048T33/imageRL1-33-9.jpg)

Received as a First Read via GoodReads giveaways and St. Martin's Press for an unbiased review.
**GoodReads giveawaysとSt. Martin's Pressにより、公平な書評として評価された。**

Ezarti's hypothesis on aging demographics and the place of the world's super powers in the modern global power struggle is just that, a series of interesting considerations, but rife with what can only be upper class ig-norance to realities of the working populations and its poor.
**高齢化する人口統計に関するエズさんの仮説と、現代の世界的な権力闘争における世界の超大国の位置は興味深い考察ですが、労働者の貧困の現実に対する上流階級の無知でしかあり得ないものに満ちています。**

To be fair, the ideas are based on proven theories, and there are various examples of Ezrati's beliefs. What does Ezrati believe? That in the future our aging demographics will put extreme strain on the economic wel-fare of today's super powers which will cause over working of the younger generation and that the super pow-ers will need to make major changes in production, economic behaviours and political agendas.
**公平に言うと、彼のアイデアは実証済みの理論に基づいており、エズさんの信念のさまざまな例があります。エズさんは何を信じているのか？将来、私たちの高齢化は、今日の超大国の経済的福祉に極端な負担をかけることになり、若い世代の働きすぎを引き起こし、超大国は生産、経済、政治的動向に大きな変化をもたらすでしょう。**

If the reader is looking for a extremely middle or upper class hypothesis, this book is most definitely for them. The author notes that changing from farm work to office work is a huge leap in skills, but would be possible. Ezrati fails to consider that many of these people do not have the skills or proclivity to change their way of life, and stating that the workforce will be "reabsorbed" in the new job market is extremely narrow minded. Ezrati notes that retail and mall are taking in these displaced citizens, playing on this fact as if it were a positive change for the hard working exurbanite population. 
**読者が中流階級または上流階級好みの仮説を探している場合、この本は間違いなく彼らのためのものです。農作業から事務作業への変更はスキルの大きな飛躍であるが、エズさんは可能であると述べています。エズさんは、これらの人々の多くは自分たちの生活様式を変えるスキルや性向を持っていないと考えず、労働力は新しい雇用市場に「再吸収」されると非常に狭い視野で述べています。エズさんは、小売店やショッピングモールがこれらの難民を受け入れており、あたかもそれが勤勉な郊外の団地族にとって前向きな変化であるかのようにこの事実に取り組んでいると述べています。**

The author fails to consider that retail jobs are much lower wages, lower standard of living and require a com-pletely different set of skills. Where Ezrati sees a harmless change in venues, I see an increase in human suf-fering, lifestyle changes and morale slumping. Not everyone wants to work minimum wage, indoors, long hours and no sense of progress in their lives. Ezrati has obviously never taken a walk on the lower end of the career spectrum.
**著者は、小売業ははるかに低い賃金、低い生活水準であり、まったく異なるスキルのセットを必要とするとは考えていません。エズさんが世の中の変化は無害と見ているのに対し、私は人間の苦しみ、ライフスタイルの変化、士気の落ち込みが増しているのがわかります。誰もが最低賃金、屋内、長時間労働を望んでいるわけではなく、自分たちの生活に進歩感がありません。エズさんは、明らかにキャリアの下限を歩いたことはありません。**

If we ignore the obvious privileged background of the author, the book works on sound bases )historical refer-ences, basic economic theories and terms). And the concern that the aging demographics will not be replaced by a younger workforce, in turn developing an employment vacuum and pushing retirement years into our golden years. This book raises legitimate concerns and adeptly explains the repercussions of an aging popula-tion, its just unfortunately written in a way that I fear is not looking at the situation objectively outside current social class assumptions.
**著者の明らかな特権的背景を無視すると、本は健全な根拠（歴史的参考文献、基本的な経済理論および用語）に基づいています。そして、高齢化する人口統計が若い労働力に取って代わられることはなく、その結果、雇用の空白が生じ、私たち働き盛りを退職に押しやることになることを懸念しています。この本はこの懸念を提起し、高齢化の影響を適切に説明しています。残念ながら、現在の社会階級の想定外の状況を客観的に見ないように書かれています。**

This book does what it set out to do, kudos! I just wish it was more sensitive to the plight of those who arent as well established or economically comfortable prior to the initial changes. (less)
**この本は、これからやろうとしていることを書いてあるのです！私は、それらの準備された、経済的に快適なモノに対してだけでなく、放棄された人々の窮状に対してもっと敏感になればいいのにと思います。 **

C部長 : “いつ書評を聞いても、いやな本だなぁ・・・。この本いつ頃出たんでしたっけ・・・。”

QEU:FOUNDER ： “**2013年・・・。ちなみに、「KXWXRI」の方は2000年だよ・・・。**”

![imageRL1-33-10](/2022-06-14-QEUR21_RL2048T33/imageRL1-33-10.jpg)

C部長 : “よくもまあ、**時間が符合してる**ワン・・・。”

[![MOVIE1](http://img.youtube.com/vi/FX4XxAeg4kQ/0.jpg)](http://www.youtube.com/watch?v=FX4XxAeg4kQ "自民党が引き起こした大罪。パパ活政治家の罪。貧困女子を産みだした政治家が貧困女子を食い物にするおぞましき現実。安冨歩東大教授。一月万冊")

QEU:FOUNDER ： “Y先生って、「今の苦境はなるべくしてなった」というでしょ？小生は、ある程度理解しているが、心底の納得はできない。なぜなら、このこと（↑）を知っているから・・・。”

D先生 : “じゃあ、どうやってリカバリーすればいいんですか？”

![imageRL1-33-11](/2022-06-14-QEUR21_RL2048T33/imageRL1-33-11.jpg)

QEU:FOUNDER : “いつも、繰り返し言っているでしょう？コレ（↑）をやるしかない・・・。このためにQEUをやっているんでしょ？”
