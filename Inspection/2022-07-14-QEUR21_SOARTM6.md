---
title: QEUR21_SOARTM6 – SOART法をもう一度試してみる(SOART2-その7)
date: 2022-07-14
tags: ["QEUシステム", "メトリックス", "Python言語", "機械学習", "マハラノビス距離", "DX", "Blender", "SOART法", "異常判別"]
excerpt: Python言語とSOART法を使った異常判別
---

## QEUR21_SOARTM6 – SOART法をもう一度試してみる(SOART2-その7)

## ～　ちょっと、うまく行かないが・・・　～

D先生 ：“さて、前半の山場です。**「特徴量マップの出力」**に入りましょう。”

![imageRL3-26-1](/2022-07-14-QEUR21_SOARTM6/imageRL3-26-1.jpg)

QEU:FOUNDER ; “一つの画像を読み込み、その画像からマハラノビス距離に基づく特徴量マップを表示します。いままで、さんざんロジックについて話しているので説明不要ですね。それでは、プログラムをドン！！かなり長いよ・・・。”

```python
# -------------------- プログラムの始まり -------------------
# -*- coding: utf-8 -*-
# filename: soaRT2_featureMap_step2.py
# 1枚の画像を読み込み、マハラノビス距離の特徴量マップを出力する 
# SOART2法用（マルチ-step2）
# Step2の単位空間は3種類(A,B,C)とする
# ---------------------------------------------------
# モジュールのインポート
import cv2
from fastai.vision.all import *
import pandas as pd
import numpy as np
import seaborn as sns
from scipy.spatial import distance

#=================================================
# MAIN PROGRAM(1) : 画像名csvファイルを読み込む
#=================================================
# VR画像ファイルを読み込み表示する
def read_vrImgfile(file_readcsv): 
 
    # 畳み込みファイルの読み込み
    df = pd.read_csv(file_readcsv) 
    #df = df[df["rtm"]=="tani"]  # キャンセルすると、移動、回転画像も使うことになる
    num_VRfs = len(df)
    # ------------------
    # file_nameのリストを生成する
    mx_Xs = df.loc[:,"file_name":"label"].values
    arr_VRsignal = df.loc[:,"file_name"].values
    #print("----- mx_Xs -----")
    #print(mx_Xs)
  
    return num_VRfs, mx_Xs, arr_VRsignal

# ---------------------------
# CSVファイル(実験)情報を読み込み表示する
foldername   = "./ARRAY_RTCNN/"
file_VRinput = foldername + "labels0_NORMAL.csv"  # ファイルパス名の生成 
num_VRfs, mx_Xs, arr_VRsignal = read_vrImgfile(file_VRinput)
#print(arr_VRsignal)

#=================================================
# MAIN PROGRAM(2) : パラメタの準備
#=================================================
# インスタンス化
L1_loss  = torch.nn.L1Loss()
MSE_loss = torch.nn.MSELoss()

# 画像リサイズのパラメタ
newsize = (900, 300)
# テンソルイメージ処理のパラメタ
cmax_sp_col, cmax_sp_row   = newsize[0], newsize[1]  #(900, 300)
# ストライド量
stride_sp_row, stride_sp_col = 5, 5
# RT法処理のサイズ
crtm_sp_row, crtm_sp_col = 5, 5
# STEP1処理後のマトリックスサイズ
max_sp_row, max_sp_col = 60, 180

# ---------------------------
# テンソル行列の処理(for)開始点のベクトルを生成する
row_range, col_range, mx_noPin = [], [], np.zeros([max_sp_row, max_sp_col])
sum_row = 0
while sum_row <= cmax_sp_row-crtm_sp_row:
    row_range.append(sum_row)
    sum_row  += stride_sp_row
# -----
sum_col = 0
while sum_col <= cmax_sp_col-crtm_sp_col:
    col_range.append(sum_col)
    sum_col  += stride_sp_col
# -----
# STEP1処理後のマトリックスの各要素がどのPIN番号に当たるのかを示す
for row in range(max_sp_row):
    for col in range(max_sp_col):
        irow, jcol  = int(row/20), int(col/20)
        mx_noPin[row, col] = irow*9 + jcol
#print("--- mx_noPin ---")
#print(mx_noPin)

#=================================================
# INRODUCING IMAGE FUNCTIONS
#=================================================
# 計測画像ファイルを読んで、テンソルを出力する
def read_pictures(pic_signal): 

    # ------------------
    # 単位画像(C)
    filenameC = foldername + "average_pic.png"
    imgC = cv2.imread(filenameC, cv2.IMREAD_GRAYSCALE)
    img_cropC = imgC[212:856,47:1867]
    # リサイズ
    img_resizeC = cv2.resize(img_cropC , newsize)

    # ------------------
    # 信号画像(S)
    filenameS = foldername + pic_signal
    imgS = cv2.imread(filenameS, cv2.IMREAD_GRAYSCALE)
    img_cropS = imgS[212:856,47:1867]
    # リサイズ
    img_resizeS = cv2.resize(img_cropS , newsize)

    # ------------------
    # 単位、信号画像データのテンソル化
    img_tani    = tensor(img_resizeC/255)  # 単位空間（標準ベクトル）
    img_signal  = tensor(img_resizeS/255)  # 信号空間（計測ベクトル）
    
    return img_tani, img_signal

# ---------------------------
# soaRT(Step1)メトリックスを計算する(テンソル活用版)
def calc_soaRT_step1(L1_loss, MSE_loss, tsr_sig_array, tsr_tani_array): 

    y = tsr_sig_array
    x = tsr_tani_array
    tsr_zero = torch.zeros(len(x))

    # 体積ひずみを計測
    vol_xtani = MSE_loss(x, tsr_zero) + 0.0001
    vol_ysig  = MSE_loss(y, tsr_zero) + 0.0001
    ratio_vol = vol_ysig/vol_xtani

    # せん断ひずみを計測
    mDistance   = L1_loss(y, ratio_vol*x)
    #print("mDistance: ", mDistance.item())

    return ratio_vol.item(), mDistance.item()

# ---------------------------
# 畳み込みSOARTメトリックスを生成する
def create_CRTmetric(L1_loss, MSE_loss, iCnt_file, tani_image, signal_images):

    # 畳み込みSOARTメトリックスをCSVファイルに出力するための行列（マトリックス）を初期化
    arr_iCnt, arr_noPin, arr_soaY2, arr_soaY3 = [], [], [], []
    # --------------------------
    iCnt_pix  = 0
    cnt_row   = 0
    for row in row_range:
        cnt_col = 0
        for col in col_range:
            # ------
            # 単位空間の空間ベクトルを生成する
            tsr_tani_array = tani_image[row:row+crtm_sp_row,col:col+crtm_sp_col].flatten()
            #print(tsr_tani_array)
            # ------
            # 信号空間の空間マトリックスを生成する
            tsr_sig_array  = signal_images[row:row+crtm_sp_row,col:col+crtm_sp_col].flatten()
            #print("----- tsr_sig_array -----")
            #print(tsr_sig_array)
            # ------
            # RTメトリックスを計算する
            val_Y2, val_Y3 = calc_soaRT_step1(L1_loss, MSE_loss, tsr_sig_array, tsr_tani_array)
            # ------
            # リストを生成する  
            arr_iCnt.append(iCnt_pix)  # 画素NO
            arr_noPin.append(mx_noPin[cnt_row, cnt_col])    # PINNO
            arr_soaY2.append(round(val_Y2, 5))  # Y2類
            arr_soaY3.append(round(val_Y3, 5))  # Y3類
            # ------
            # COUNT UP
            iCnt_pix  = iCnt_pix + 1
            cnt_col   = cnt_col + 1
        # ------
        # COUNT UP
        cnt_row = cnt_row + 1
    # ---------------------------
    # マトリックス化
    temp_file  = np.array([[iCnt_file]*len(arr_noPin)]).T
    temp_noPin = np.array([arr_noPin]).T
    temp_iCnt  = np.array([arr_iCnt]).T
    temp_soaY2 = np.array([arr_soaY2]).T
    temp_soaY3 = np.array([arr_soaY3]).T
    mx_metrics = np.concatenate([temp_file, temp_noPin, temp_iCnt, temp_soaY2, temp_soaY3], axis=1)
    # 結果のテキスト出力する
    #print("--- mx_metrics ---")
    #print(mx_metrics)

    return mx_metrics

# ------------------
# マハラノビス距離の補正リストを生成する
def adjust_values(acc_adj_dYs, raw_idx, adj_dys): 
 
    # インディックスを抽出して補正する
    for i in range(len(raw_idx)):
        acc_adj_dYs[int(raw_idx[i])] = adj_dys[i]
  
    return acc_adj_dYs

#=================================================
# READ TANI SPACE CSV_FILE FUNCTIONS
#=================================================
# ファイルを読み込み表示する(分散共分散逆行列)
def read_invcorr(code_cnv_input): 

    # 相関逆行列ファイルの読み込み
    file_cnv_input = foldername + code_cnv_input + ".csv"  # ファイルパス名の生成 
    df = pd.read_csv(file_cnv_input)
    # 選択項目の読み込み
    # Xsマトリックス
    mx_Xs = df.loc[:,"0":"1"].values
    #print("----- mx_Xs -----")
    #print(mx_Xs)
  
    return mx_Xs

# ------------------
# ファイルを読み込み表示する(単位空間の中心)
def read_taniXs(code_cnv_input): 
 
    # 単位空間の中心ファイルの読み込み
    file_cnv_input = foldername + code_cnv_input + ".csv"  # ファイルパス名の生成
    df = pd.read_csv(file_cnv_input) 
    # 選択項目の読み込み
    # Xsマトリックス
    mx_Xs = df.loc[:,"0":"1"].values
    #print("----- mx_Xs -----")
    #print(mx_Xs)
  
    return mx_Xs.flatten()

# ------------------
# SOART(Step1)の項目数（Y2, Y3）
def read_mahaStep1():

    acc_mx_tani, acc_mx_covi = [], []

    # PINNO毎にCSVファイルを出力する
    for iPin in range(9*3):

        # ファイルを読み込み表示する(相関逆行列)
        code_invcorr  = "invCor_pin{}".format(iPin)
        cov_iY = read_invcorr(code_invcorr)
        #print(cov_iY)
        # ------------------
        # ファイルを読み込み表示する(単位空間の中心)
        code_taniXs   = "taniXs_pin{}".format(iPin)
        arr_Xs_tani = read_taniXs(code_taniXs)
        #print(arr_Xs_tani)
        # ------------------
        # 単位空間データを累積する
        acc_mx_tani.append(arr_Xs_tani)
        acc_mx_covi.append(cov_iY)
    # ------------------
    # 出力
    #print("--- acc_mx_covi ---")
    #print(acc_mx_covi)
    #print("--- acc_mx_tani ---")
    #print(acc_mx_tani)

    return acc_mx_tani, acc_mx_covi

#=================================================
# CREATING STEP1 METRICS FUNCTIONS(SIGNAL)
#=================================================
# Step1メトリックスを生成する
def create_mtxStep1(pic_signal, acc_mx_tani, acc_mx_covi):

    # データフレームのコラム初期化
    arr_columns = ["fileno", "pinno", "pix", "Y2", "Y3"]
    # 計測画像ファイルを読んで、テンソルを出力する
    tani_image, signal_images = read_pictures(pic_signal)
    # SOARTメトリックス(STEP1)を生成する
    mx_metrics = create_CRTmetric(L1_loss, MSE_loss, iCnt_file, tani_image, signal_images)
    # データフレームを作成する
    df_metrics = pd.DataFrame(mx_metrics, columns=arr_columns)
    arr_pins   = df_metrics.loc[:,"pinno"].values

    # -------------
    # マハラノビス距離(Step1)配列の初期化
    arr_index, arr_mahadis = [], []
    # マハラノビス距離(Step1)を計算する
    for iCnt_maha in range(len(arr_pins)):

        slice_data  = df_metrics.loc[iCnt_maha,"Y2":"Y3"].values
        val_pins    = arr_pins[iCnt_maha]
        arr_Xs_tani = acc_mx_tani[int(val_pins)]
        cov_iY      = acc_mx_covi[int(val_pins)]
        dY = distance.mahalanobis(slice_data, arr_Xs_tani, cov_iY)
        arr_index.append(iCnt_maha)
        arr_mahadis.append(round(dY,2))
    # -------------
    # データフレームを作成する
    df_metrics["maha"] = arr_mahadis
    df_metrics["idx"]  = arr_index
    #print("------------ df_metrics -------------")  
    #print(df_metrics) 

    # -------------
    # Step1メトリックスの補正(adjust)
    arr_max_dYs = []
    acc_adj_dYs = np.zeros(len(arr_pins))
    for iCnt_adj in range(3*9):

        temp_dYs = df_metrics[df_metrics["pinno"]==iCnt_adj]
        raw_idx  = temp_dYs["idx"].values
        raw_dYs  = temp_dYs["maha"].values
        arr_max_dYs.append(np.amax(raw_dYs))
        adj_dys  = np.amax(raw_dYs) - raw_dYs
        # 補正リストを生成する
        acc_adj_dYs = adjust_values(acc_adj_dYs, raw_idx, adj_dys)
    # -----
    # リスト結果を表示する
    df_metrics["adj"]  = acc_adj_dYs
    #print("len_metrics:",len(df_metrics))
    #print("----- df_metrics -----")
    #print(df_metrics)

    return df_metrics

#=================================================
# MAIN PROGRAM(3) : SOART(Step1)の蓄積マトリックス(SIGNAL)を生成する
#=================================================
# マハラノビス（STEP1）メトリックスデータを読む
acc_mx_tani, acc_mx_covi = read_mahaStep1()

# 読み込み先の指定
iCnt_file = 0   # ファイル番号の指定
pic_signal = arr_VRsignal[iCnt_file] + ".png"   # 計測画像(計測ベクトル)
print("iCnt_file: {}, pic_signal: {}".format(iCnt_file,pic_signal))

# Step1メトリックスを生成する
df_metrics = create_mtxStep1(pic_signal, acc_mx_tani, acc_mx_covi)
#print("len_metrics:",len(df_metrics))
#print("----- df_metrics -----")
#print(df_metrics)

# 行列(マトリックス)を作る
# STEP1処理後の信号マトリックスのサイズ
arr_temp = df_metrics["adj"].values
mx_sigStep1 = arr_temp.reshape([max_sp_row, max_sp_col])
print("----- mx_sigStep1 -----")
print(mx_sigStep1)

#=================================================
# READ STEP1 CSV_FILE FUNCTION(TANI)
#=================================================
# 畳み込みファイルを読み込み表示する
def read_tanifile(file_readcsv): 
 
    # 畳み込みファイルの読み込み
    df = pd.read_csv(file_readcsv) 
    # ------------------
    # 選択項目の読み込み
    # Xsマトリックス
    mx_Xs = df.loc[:,"0":"179"].values
    #print("----- mx_Xs -----")
    #print(mx_Xs)
  
    return mx_Xs

#=================================================
# MAIN PROGRAM(4) : SOART(Step1)の蓄積マトリックス(TANI)を生成する
#=================================================
# 単位空間ファイルを読み込み表示する
file_tani_input = foldername + "step1_metrics_tani.csv"  # ファイルパス名の生成
mx_taniStep1 = read_tanifile(file_tani_input)
# ------
# 蓄積された単位マトリックスを表示する
#print("----- mx_taniStep1 -----")
#print(mx_taniStep1)

#=================================================
# READ CONVOLUTION CSV_FILE FUNCTION
#=================================================
# 畳み込みファイルを読み込み表示する
def read_csvfile(file_readcsv): 
 
    # 畳み込みファイルの読み込み
    df = pd.read_csv(file_readcsv) 
    # ------------------
    # 選択項目の読み込み
    # Xsマトリックス
    mx_Xs = df.loc[:,"col1":"col5"].values
    #print("----- mx_Xs -----")
    #print(mx_Xs)
  
    return mx_Xs

#=================================================
# MAIN PROGRAM(5) : 畳み込みメトリックスの準備
#=================================================
# パラメタの設定
max_cnv_parts  = 8
# ファイル名の指定
nam_cnv_input = "基準用CSVデータ" 
code_cnv_input = ["NA"] * max_cnv_parts     # CSVコードの指定
code_cnv_input[0] = "bend1_cnv"     # CSVコードの指定
code_cnv_input[1] = "bend2_cnv"     # CSVコードの指定
code_cnv_input[2] = "bend3_cnv"     # CSVコードの指定
code_cnv_input[3] = "bend4_cnv"     # CSVコードの指定
code_cnv_input[4] = "line1_cnv"     # CSVコードの指定
code_cnv_input[5] = "line2_cnv"     # CSVコードの指定
code_cnv_input[6] = "datum1_cnv"    # CSVコードの指定
code_cnv_input[7] = "datum2_cnv"    # CSVコードの指定
# ------------------
# 畳み込み処理を実施する
for i in range(max_cnv_parts):
    # ---------------------------
    # CSVファイル(実験)情報を読み込み表示する
    # 畳み込みファイル
    file_cnv_input = foldername + code_cnv_input[i] + ".csv"  # ファイルパス名の生成 
    mx_conv = read_csvfile(file_cnv_input)
    if i == 0:    
        tensor_bend1 = tensor(mx_conv).float()
    elif i == 1:
        tensor_bend2 = tensor(mx_conv).float()
    elif i == 2:
        tensor_bend3 = tensor(mx_conv).float()
    elif i == 3:
        tensor_bend4 = tensor(mx_conv).float()
    elif i == 4:
        tensor_line1 = tensor(mx_conv).float()
    elif i == 5:
        tensor_line2 = tensor(mx_conv).float()
    elif i == 6:
        tensor_datum1 = tensor(mx_conv).float()
    elif i == 7:
        tensor_datum2 = tensor(mx_conv).float()
# ---------------------------
# 畳み込みカーネルを生成する
signal_kernels  = torch.stack([tensor_bend1, tensor_bend2, tensor_bend3, tensor_bend4, tensor_line1, tensor_line2])
tani_kernel     = tensor_datum1 + tensor_datum2
# カーネルを表示する
#print("--- signal_kernels ---")
#print(signal_kernels)
#print("--- tani_kernel ---")
#print(tani_kernel)

#=================================================
# MAIN PROGRAM(5) : 畳み込みRTメトリックスの準備
#=================================================
# STEP1処理後のマトリックスサイズ
conv_newsize = (180, 60)
# 畳み込み処理のパラメタ
max_cnv_col, max_cnv_row = conv_newsize[0], conv_newsize[1]  #(900, 300)
# 畳み込み処理のサイズ
cmx_cnv_row, cmx_cnv_col = 5, 5
# ストライド量
stride_cnv_row, stride_cnv_col = 5, 5

# ---------------------------
# [畳み込み] : テンソル行列の畳み込み処理開始点のベクトルを生成する
row_cnv_range, col_cnv_range = [], []
sum_row = 0
while sum_row <= max_cnv_row-cmx_cnv_row:
    row_cnv_range.append(sum_row)
    sum_row  += stride_cnv_row
# -----
sum_col = 0
while sum_col <= max_cnv_col-cmx_cnv_col:
    col_cnv_range.append(sum_col)
    sum_col  += stride_cnv_col

# ---------------------------
# STEP1処理後のマトリックスサイズ
rtm_newsize = (36, 12)
# テンソルイメージ処理のパラメタ
max_rtm_col, max_rtm_row = rtm_newsize[0], rtm_newsize[1]  #(900, 300)
# RT法処理のサイズ
dmx_rtm_row, dmx_rtm_col = 4, 4
# RT法処理のストライド量
stride_rtm_row, stride_rtm_col = 4, 4
# RTベクトル長と信号空間長
dmax_jy_idx  = 4 * 4    # 処理する領域のサイズ
len_dmx      = 6        # ベンド系とライン系

# ---------------------------
# [RTメトリックス] : テンソル行列の畳み込み処理開始点のベクトルを生成する
row_rtm_range, col_rtm_range = [], []
sum_row = 0
while sum_row <= max_rtm_row-dmx_rtm_row:
    row_rtm_range.append(sum_row)
    sum_row  += stride_rtm_row
# -----
sum_col = 0
while sum_col <= max_rtm_col-dmx_rtm_col:
    col_rtm_range.append(sum_col)
    sum_col  += stride_rtm_col

#=================================================
# CONVOLUTION FUNCTIONS
#=================================================
# 畳み込み処理を実施する
def apply_kernel(row, col, kernel, img_tensor):
    return (img_tensor[row:row+cmx_cnv_row,col:col+cmx_cnv_col] * kernel).sum()

# ---------------------------
# soaRT(Step2)メトリックスを計算する(テンソル活用版)
def calc_soaRT_step2(L1_loss, len_dmx, cmax_jy_idx, tsr_sig_matrix, tsr_tani_array): 

    # ---------------------------
    # 変数の初期化
    btY1_yarray, Y2_yarray = [], []

    # 繰り返し
    for iCmx in range(len_dmx):

        y = tsr_sig_matrix[iCmx]
        x = tsr_tani_array

        # 回転を計測
        xx = torch.dot(x,x) + 0.0001
        xy = torch.dot(x,y) + 0.0001
        beta = xy/xx
        #print("iCmx:{}, beta:{}".format(iCmx, beta))

        # せん断ひずみを計測
        mDistance   = L1_loss(y, beta*x)
        #print("mDistance: ", mDistance.item())
        
        btY1_yarray.append(beta.item())
        Y2_yarray.append(mDistance.item())

    return btY1_yarray, Y2_yarray

# ---------------------------
# 畳み込みテンソルイメージを生成する
def create_tsrConv(tensor_Y1Y2):

    # 単位空間用の畳み込み処理を実施する
    tani_image = tensor([[apply_kernel(i,j, tani_kernel, tensor_Y1Y2) for j in col_cnv_range] for i in row_cnv_range])
    #print("----- tani_image -----")
    #print(tani_image)
    # ------------------
    # 信号空間用の畳み込み処理を実施する
    for i in range(max_cnv_parts-2):
        # ---------------------------
        # CSVファイル(実験)情報を読み込み表示する
        kernel = signal_kernels[i]
        calc_conv = tensor([[apply_kernel(i,j, kernel, tensor_Y1Y2) for j in col_cnv_range] for i in row_cnv_range])
        # -----
        if i == 0:    
            tsr_cvbend1 = tensor(calc_conv).float()
        elif i == 1:
            tsr_cvbend2 = tensor(calc_conv).float()
        elif i == 2:
            tsr_cvbend3 = tensor(calc_conv).float()
        elif i == 3:
            tsr_cvbend4 = tensor(calc_conv).float()
        elif i == 4:
            tsr_cvline1 = tensor(calc_conv).float()
        elif i == 5:
            tsr_cvline2 = tensor(calc_conv).float()
    # ---------------------------
    # 畳み込みテンソルイメージの生成  
    signal_images = torch.stack([tsr_cvbend1, tsr_cvbend2, tsr_cvbend3, tsr_cvbend4, tsr_cvline1, tsr_cvline2])
    # 結果の出力
    #print(signal_images.shape)     # torch.Size([6, 12, 36])
    #print("----- signal_images[0] -----")
    #print(signal_images[0])

    return tani_image, signal_images

# ---------------------------
# 畳み込みSOARTメトリックスを生成する
def create_CRTmetric(tani_image, signal_images):

    # 畳み込みSOARTメトリックスをCSVファイルに出力するための行列（マトリックス）を初期化
    mx_p0Y1, mx_p1Y1, mx_p2Y1 = np.zeros([3,9]), np.zeros([3,9]), np.zeros([3,9])
    mx_p3Y1, mx_p4Y1, mx_p5Y1 = np.zeros([3,9]), np.zeros([3,9]), np.zeros([3,9])
    mx_p0Y2, mx_p1Y2, mx_p2Y2 = np.zeros([3,9]), np.zeros([3,9]), np.zeros([3,9])
    mx_p3Y2, mx_p4Y2, mx_p5Y2 = np.zeros([3,9]), np.zeros([3,9]), np.zeros([3,9])
    # ---------------------------
    cnt_row = 0
    for row in row_rtm_range:
        cnt_col = 0
        for col in col_rtm_range:
            # ------
            # 単位空間の空間ベクトルを生成する
            tsr_tani_array = tani_image[row:row+dmx_rtm_row,col:col+dmx_rtm_col].flatten()
            #print(tsr_tani_array)
            # ------
            # 信号空間の空間マトリックスを生成する
            temp_matrix = signal_images[0]
            tsr_sig_p0 = temp_matrix[row:row+dmx_rtm_row,col:col+dmx_rtm_col].flatten()
            temp_matrix = signal_images[1]
            tsr_sig_p1 = temp_matrix[row:row+dmx_rtm_row,col:col+dmx_rtm_col].flatten()
            temp_matrix = signal_images[2]
            tsr_sig_p2 = temp_matrix[row:row+dmx_rtm_row,col:col+dmx_rtm_col].flatten()
            temp_matrix = signal_images[3]
            tsr_sig_p3 = temp_matrix[row:row+dmx_rtm_row,col:col+dmx_rtm_col].flatten()
            temp_matrix = signal_images[4]
            tsr_sig_p4 = temp_matrix[row:row+dmx_rtm_row,col:col+dmx_rtm_col].flatten()
            temp_matrix = signal_images[5]
            tsr_sig_p5 = temp_matrix[row:row+dmx_rtm_row,col:col+dmx_rtm_col].flatten()
            # -----
            tsr_sig_matrix = torch.stack([tsr_sig_p0, tsr_sig_p1, tsr_sig_p2, tsr_sig_p3, tsr_sig_p4, tsr_sig_p5])
            #print("----- tsr_sig_matrix -----")
            #print(tsr_sig_matrix)
            # ------
            # soaRT(Step2)メトリックスを計算する(テンソル活用版)
            btY1_yarray, Y2_yarray = calc_soaRT_step2(L1_loss, len_dmx, dmax_jy_idx, tsr_sig_matrix, tsr_tani_array)
            # ------
            # CSV出力用のマトリックスを生成する  
            # Y1類
            mx_p0Y1[cnt_row, cnt_col] = round(btY1_yarray[0],3)
            mx_p1Y1[cnt_row, cnt_col] = round(btY1_yarray[1],3)
            mx_p2Y1[cnt_row, cnt_col] = round(btY1_yarray[2],3)
            mx_p3Y1[cnt_row, cnt_col] = round(btY1_yarray[3],3)
            mx_p4Y1[cnt_row, cnt_col] = round(btY1_yarray[4],3)
            mx_p5Y1[cnt_row, cnt_col] = round(btY1_yarray[5],3)
            # -----
            # Y2類
            mx_p0Y2[cnt_row, cnt_col] = round(Y2_yarray[0],3)
            mx_p1Y2[cnt_row, cnt_col] = round(Y2_yarray[1],3)
            mx_p2Y2[cnt_row, cnt_col] = round(Y2_yarray[2],3)
            mx_p3Y2[cnt_row, cnt_col] = round(Y2_yarray[3],3)
            mx_p4Y2[cnt_row, cnt_col] = round(Y2_yarray[4],3)
            mx_p5Y2[cnt_row, cnt_col] = round(Y2_yarray[5],3)
            # ------
            # COUNT UP
            #print(cnt_row, cnt_col)
            cnt_col = cnt_col + 1
        # ------
        # COUNT UP
        cnt_row = cnt_row + 1
    # ---------------------------
    # 行列（マトリックス）を生成する
    mx_Y1   = np.concatenate([[mx_p0Y1.flatten()], [mx_p1Y1.flatten()], [mx_p2Y1.flatten()], [mx_p3Y1.flatten()], [mx_p4Y1.flatten()], [mx_p5Y1.flatten()]], axis=0)
    mx_Y2   = np.concatenate([[mx_p0Y2.flatten()], [mx_p1Y2.flatten()], [mx_p2Y2.flatten()], [mx_p3Y2.flatten()], [mx_p4Y2.flatten()], [mx_p5Y2.flatten()]], axis=0)

    return mx_Y1.T, mx_Y2.T

#=================================================
# MAIN PROGRAM(6) : 畳み込みRTメトリックスを生成する
#=================================================
# 畳み込みテンソルイメージを生成する
tani_image, signal_images = create_tsrConv(torch.tensor(mx_taniStep1).float())
# 畳み込みSOART2(Step2)メトリックスを生成する
mx_tani_Y1T, mx_tani_Y2T = create_CRTmetric(tani_image, signal_images)
# 単位メトリックス(Y1)
#print("----- mx_tani_Y1T -----")
#print(mx_tani_Y1T)
# 単位メトリックス(Y2)
#print("----- mx_tani_Y2T -----")
#print(mx_tani_Y2T)

# ---------------------------
# 畳み込みテンソルイメージを生成する
tani_image, signal_images = create_tsrConv(torch.tensor(mx_sigStep1).float())
# 畳み込みSOART2(Step2)メトリックスを生成する
mx_sig_Y1T, mx_sig_Y2T = create_CRTmetric(tani_image, signal_images)
# 信号メトリックス(Y1)
#print("----- mx_sig_Y1T -----")
#print(mx_sig_Y1T)
# 信号メトリックス(Y2)
#print("----- mx_sig_Y2T -----")
#print(mx_sig_Y2T)

# ---------------------------
# [Diff]2(Step2)マトリックスの差異をとる
mx_diff_Y1 = mx_sig_Y1T - mx_tani_Y1T
mx_diff_Y2 = mx_sig_Y2T - mx_tani_Y2T
# 差異メトリックス(Y1)
print("----- mx_diff_Y1 -----")
print(mx_diff_Y1)
# 差異メトリックス(Y2)
print("----- mx_diff_Y2 -----")
print(mx_diff_Y2)

#=================================================
# READ CSV_FILE FUNCTION
#=================================================
# ファイルを読み込み表示する(相関逆行列)
def read_invcorr(code_cnv_input): 

    # 相関逆行列ファイルの読み込み
    file_cnv_input = foldername + code_cnv_input + ".csv"  # ファイルパス名の生成 
    df = pd.read_csv(file_cnv_input)
    # 選択項目の読み込み
    # Xsマトリックス
    mx_Xs = df.loc[:,"0":"5"].values
    #print("----- mx_Xs -----")
    #print(mx_Xs)
  
    return mx_Xs

# ------------------
# ファイルを読み込み表示する(単位空間の中心)
def read_taniXs(code_cnv_input): 
 
    # 単位空間の中心ファイルの読み込み
    file_cnv_input = foldername + code_cnv_input + ".csv"  # ファイルパス名の生成
    df = pd.read_csv(file_cnv_input) 
    # 選択項目の読み込み
    # Xsマトリックス
    mx_Xs = df.loc[:,"0":"5"].values
    #print("----- mx_Xs -----")
    #print(mx_Xs)
  
    return mx_Xs.flatten()

#=================================================
# MAIN PROGRAM(7) : MAHARANOBIS　FEATURE　ENGINEERING
#=================================================
# マハラノビスマトリックスとグラフ作画準備
max_iRow_cells = 3*9

# ------------------
# ファイルを読み込み表示する(相関逆行列)
# Y1類の場合
cov_iY1A = read_invcorr("Rtm_covY1A")
cov_iY1B = read_invcorr("Rtm_covY1B")
cov_iY1C = read_invcorr("Rtm_covY1C")
# -----
# Y2類の場合
cov_iY2A = read_invcorr("Rtm_covY2A")
cov_iY2B = read_invcorr("Rtm_covY2B")
cov_iY2C = read_invcorr("Rtm_covY2C")
#print(cov_iY2A)

# ------------------
# ファイルを読み込み表示する(単位空間の中心)
# Y1類の場合
arr_Xs_taniY1A = read_taniXs("Rtm_aveY1A")
arr_Xs_taniY1B = read_taniXs("Rtm_aveY1B")
arr_Xs_taniY1C = read_taniXs("Rtm_aveY1C")
# -----
# Y2類の場合
arr_Xs_taniY2A = read_taniXs("Rtm_aveY2A")
arr_Xs_taniY2B = read_taniXs("Rtm_aveY2B")
arr_Xs_taniY2C = read_taniXs("Rtm_aveY2C")
#print(arr_Xs_taniY2A)

# ------------------
# 単位空間の分配ベクトルの定義
bun_temp = np.array([[1,1,2,2,2,2,2,3,3],[1,1,2,2,2,2,2,3,3],[1,1,2,2,2,2,2,3,3],])
arr_bun  = bun_temp.flatten()
#print(arr_bun)

# ------------------
# 2つの標本 [X_tani, X_sig] と [(mean)arr_X_tani] のマハラノビス距離を計算する
arr_dY1, arr_dY2 = [], []
for iRow in range(max_iRow_cells):
    # -----
    if arr_bun[iRow] == 1:
        arr_Xs_taniY1 = arr_Xs_taniY1A
        arr_Xs_taniY2 = arr_Xs_taniY2A
        cov_iY1 = cov_iY1A
        cov_iY2 = cov_iY2A
    elif arr_bun[iRow] == 2:
        arr_Xs_taniY1 = arr_Xs_taniY1B
        arr_Xs_taniY2 = arr_Xs_taniY2B
        cov_iY1 = cov_iY1B
        cov_iY2 = cov_iY2B
    elif arr_bun[iRow] == 3:
        arr_Xs_taniY1 = arr_Xs_taniY1C
        arr_Xs_taniY2 = arr_Xs_taniY2C
        cov_iY1 = cov_iY1C
        cov_iY2 = cov_iY2C
    # -----
    dY1 = distance.mahalanobis(mx_diff_Y1[iRow,:], arr_Xs_taniY1, cov_iY1)
    dY2 = distance.mahalanobis(mx_diff_Y2[iRow,:], arr_Xs_taniY2, cov_iY2)
    arr_dY1.append(round(dY1,4))
    arr_dY2.append(round(dY2,4))
    #print("iRow:{}, マハラノビス距離の計算結果:{}".format(iRow,dY2))
# ------
#print("arr_dY3: ",arr_dY3)
mx_MHdistY1 = np.reshape(np.array(arr_dY1), (3, 9))
mx_MHdistY2 = np.reshape(np.array(arr_dY2), (3, 9))
#print("---- mx_MHdistY1 ----")
#print(mx_MHdistY1)
#print("---- mx_MHdistY2 ----")
#print(mx_MHdistY2)

#=================================================
# MAIN PROGRAM(8) : MAHARANOBIS　HEATMAP DRAWING
#=================================================
# マハラノビス距離のマトリックスを生成する
arr_index   = list(range(3))
arr_columns = list(range(9))
# -----
# Y1類の場合
df_mahaY1 = pd.DataFrame(mx_MHdistY1, index=arr_index, columns=arr_columns)
#print("---- df_mahaY1 ----")
#print(df_mahaY1)
# ------------------
# ヒートマップへ出力する
fig = plt.figure(figsize=(14, 6))
ax1 = fig.add_subplot(1, 2, 1)
ax1.set_title("Y1 Distance:({})".format(pic_signal))
sns.heatmap(df_mahaY1, ax=ax1, annot=True, cbar=True, fmt='.2f')
# -----
# Y2類の場合
df_mahaY2 = pd.DataFrame(mx_MHdistY2, index=arr_index, columns=arr_columns)
#print("---- df_mahaY2 ----")
#print(df_mahaY2)
# ------------------
# ヒートマップへ出力する
ax2 = fig.add_subplot(1, 2, 2)
ax2.set_title("Y2 Distance:({})".format(pic_signal))
sns.heatmap(df_mahaY2, ax=ax2, annot=True, cbar=True, fmt='.2f')
# show plots
fig.tight_layout()
plt.show()

```

QEU:FOUNDER ： “まずは一枚目の事例を出力してみましょう・・・。この画像は、（被検査体）ワークに回転や移動はなく、ライトの明るさのみが変わっているだけです。”

![imageRL3-26-2](/2022-07-14-QEUR21_SOARTM6/imageRL3-26-2.jpg)

D先生 ：“マハラノビス距離は非常に小さくなっています。なんか、これは実験成功の予感・・・（笑）。”

QEU:FOUNDER ： “それはどうかな？次にワークに回転と移動を加えてみました。”

![imageRL3-26-3](/2022-07-14-QEUR21_SOARTM6/imageRL3-26-3.jpg)

D先生 ：“あれ？マハラノビス距離が部分的に極端に大きくなっています。どんなデータ（単位空間）で学習したんですか？”

**（学習した内容）**

- **画像20件：　ライト変動あり、ワークの移動と回転無し**
- **画像20件：　ライト変動あり、ワークの移動と回転あり**

QEU:FOUNDER ： “そうだね。今回の学習データはあまりよくないね・・・。被検査物を移動と回転した画像だけにすべきだった。数ももうちょっとほしい。”

D先生 ：“学習データを修正して、検証をやり直しましょう。あとは、不良事象の画像が必要ですね。”

## ～　まとめ　～

### ・・・　前回のつづきです　・・・

QEU:FOUNDER ： “大人物が生まれる時代は終わった・・・。これからは、あまり大きなことをすることはできないですよ。”

[![MOVIE1](http://img.youtube.com/vi/cgJcI0GRZ1U/0.jpg)](http://www.youtube.com/watch?v=cgJcI0GRZ1U "特ダネ！安倍家と統一教会に支配された日本国。安倍晋三の祖父・岸信介から続く自民党とカルトの危険な関係。安倍氏が亡くなった権力の空白に動き出した警察権力の動き。")

C部長 : “こういうデータ（↓）がメディアを通さずディスクローズされる時代ですから。・・・しかし、この情報（↓）は本当なのだろうか・・・。”

![imageRL3-26-4](/2022-07-14-QEUR21_SOARTM6/imageRL3-26-4.jpg)

QEU:FOUNDER ： “皆が訴えれば、あとで真実が明らかになるのではないでしょうか。「（先日おなくなりになり）残念なお方」は、たぶん「ある言葉の違いがわかっていなかった」のじゃないかと思います。”

- **正しいことをする**
- **良いことをする**
- **良くする**

QEU:FOUNDER ： “小生が長年、**ヨハネ福音書**を読んで考えてきたことです。3種のことばは、その意味が全く違います。”

C部長 : “へ？ちがうんですかねぇ・・・。”

QEU:FOUNDER ： “**「良いこと（をする）」は神のみが行う**ことができます。**人間にできるのは「正しいことをする」ことだけ**です。ややこしいことに、**「正しくないこと」を行っても良くすることができます**。つまり、（良くするとは）結果論なんだよね。そして、ある選ばれた人たち（政治家や経営者など）は、「良くすること」を要求されます。たぶん、あの残念なお方は、一族の先人が行っていたことを「良いこと」と思っていたのではないでしょうか？なぜなら、その当時に、人々は豊かになり、生活が良くなったから・・・。”

![imageRL3-26-5](/2022-07-14-QEUR21_SOARTM6/imageRL3-26-5.jpg)

D先生 : “時代が変わって、正しいことが変わってしまったことへの認識はないんですね。待てよ、ひょっとして、イケメンたちも同様な認識違いをしているのかもしれない・・・。”

![imageRL3-26-6](/2022-07-14-QEUR21_SOARTM6/imageRL3-26-6.jpg)

QEU:FOUNDER ： “それは否定はしない。なぜなら、**彼への支持は伸びていないから**ねぇ・・・。多分、特に経済政策が他党と違うからだろう・・・。でも、小生は彼の経済政策を支持しているよ。たとえ正しくなくとも・・・。”

D先生 : “正しくないと、ダメじゃないですか・・・。”

[![MOVIE2](http://img.youtube.com/vi/oxWi18bMzJs/0.jpg)](http://www.youtube.com/watch?v=oxWi18bMzJs "【衆院選2021】選挙公約プレゼン@ニコニコ生放送【れいわニューディール】")

QEU:FOUNDER ： “正しくないゆえに良くすることができるんですよ・・・。”
