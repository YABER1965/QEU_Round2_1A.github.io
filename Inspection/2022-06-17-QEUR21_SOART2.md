---
title: QEUR21_SOART2:　予備実験～SOARTメトリックスを使ってみる（その2）
date: 2022-06-17
tags: ["QEUシステム", "メトリックス", "Python言語", "機械学習", "マハラノビス距離", "DX", "Blender", "SOART法", "異常判別"]
excerpt: Python言語とSOART法を使った異常判別
---

## QEUR21_SOART2:　予備実験～SOARTメトリックスを使ってみる（その2）

## ～　「データの体積」とは・・・　～

D先生 ： “今回は実際にテクノメトリックスを計算するんですよね。”

![imageRL2-4-1](/2022-06-17-QEUR21_SOART2/imageRL2-4-1.jpg)

QEU:FOUNDER ： “例によってBlenderを使ってやってみよう。Blenderの自動化プログラムを見せる必要はないかな・・・。いままでの事例を真似れば自分で（pythonプログラムを）作れると思います。それでは画像の出力結果を見てみましょう。”

![imageRL2-4-2](/2022-06-17-QEUR21_SOART2/imageRL2-4-2.jpg)

D先生 ： “あれ？前回とは雰囲気が違う・・・。計測する物体の大きさと明るさが変わるようになった・・・。なぜ出力方法を変えたんですか？”

![imageRL2-4-3](/2022-06-17-QEUR21_SOART2/imageRL2-4-3.jpg)

QEU:FOUNDER ： “**「体積ひずみ(Y2)」は計測する物体の大きさと明るさに反応するメトリックス**です。あとはプログラムをドン・・・。”

```python
# -------------------- プログラムの始まり -------------------
# -*- coding: utf-8 -*-
# filename: soaRT_Drawing_3DScatter.py
# soaRTメトリックスの生成と散布図の生成（図形の大きさと明るさ用）
# ---------------------------------------------------
# ライブラリをインポートする
import cv2
from fastai.vision.all import *
import seaborn as sns
import pandas as pd
import numpy as np
import joblib
from scipy.spatial import distance
import matplotlib.pyplot as plt

#=================================================
# READ CSV_FILE FUNCTION
#=================================================
# TS画像ファイルを読んで、TSテンソルを出力する
def read_TSpics(pic_tani, pic_signal): 

    # ------------------
    # 標準画像(Tani)
    filename = foldername + pic_tani
    img_tani = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)
    # リサイズ
    img_rezTani = cv2.resize(img_tani , newsize)
    #cv2.imshow("img_rezTani",img_rezTani)
    #cv2.waitKey(0)
    #cv2.destroyAllWindows()

    # ------------------
    # 信号画像(Signal)
    filename = foldername + pic_signal + '.png'
    img_signal = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)
    # リサイズ
    img_rezSig = cv2.resize(img_signal , newsize)
    #cv2.imshow("img_rezSig",img_rezSig)
    #cv2.waitKey(0)
    #cv2.destroyAllWindows()

    # ------------------
    # 画像データのテンソル化(T,S)
    img_tensorT = tensor(1.0-img_rezTani/255)  # 標準画像(ポジ変換)
    img_tensorS = tensor(1.0-img_rezSig/255)  # 信号画像(ポジ変換)
    
    return img_tensorT, img_tensorS

# ---------------------------
# newRTメトリックスを計算する(テンソル活用版)
def calc_newRT(len_temp, max_jy_index, tsr_sig_matrix, tsr_tani_array): 

    # ---------------------------
    # 変数の初期化
    L1_loss = torch.nn.L1Loss()
    btY1_yarray, Y2_yarray = [], []

    # 繰り返し
    for i in range(len_temp):

        y = tsr_sig_matrix[i]
        x = tsr_tani_array

        xx = torch.dot(x,x)
        xy = torch.dot(x,y)
        beta = xy/xx
        #print("i:{}, beta:{}".format(i,beta))

        mDistance   = L1_loss(y, beta*x)
        #print("mDistance: ", mDistance.item())
        #print("yres:{}".format(yres))
        
        btY1_yarray.append(beta)
        Y2_yarray.append(mDistance.item())

    return btY1_yarray, Y2_yarray

# ---------------------------
# soaRTメトリックスを計算する(テンソル活用版)
def calc_soaRT(len_temp, max_jy_index, tsr_sig_matrix, tsr_tani_array): 

    # ---------------------------
    # 変数の初期化
    L1_loss  = torch.nn.L1Loss()
    tsr_zero = torch.zeros(max_jy_index)
    btY1_yarray, Y2_yarray, Y3_yarray = [], [], []

    # 繰り返し
    for i in range(len_temp):

        x = tsr_tani_array
        y = tsr_sig_matrix[i]

        # 回転を計測
        xx = torch.dot(x,x)
        xy = torch.dot(x,y)
        beta = xy/xx
        #print("i:{}, beta:{}".format(i,beta))

        # 体積ひずみを計測
        vol_xtani = L1_loss(beta*x, tsr_zero)
        vol_ysig  = L1_loss(y, tsr_zero)
        ratio_vol = vol_ysig/vol_xtani
        #ratio_vol = vol_xtani/vol_ysig

        # せん断ひずみを計測
        mDistance   = L1_loss(y, beta*ratio_vol*x)
        #print("mDistance: ", mDistance.item())
        #print("yres:{}".format(yres))
        
        btY1_yarray.append(beta.item())
        Y2_yarray.append(ratio_vol.item())
        Y3_yarray.append(mDistance.item())

    return btY1_yarray, Y2_yarray, Y3_yarray

# ---------------------------
# RTメトリックスを計算する(テンソル活用版)
def calc_RTmetrics(len_temp, max_jy_index, tsr_sig_matrix, tsr_tani_array): 

    # ---------------------------
    # 変数の初期化
    lnr_yarray, btY1_yarray = [], []
    st_yarray, sb_yarray, se_yarray, ve_yarray = [], [], [], []
    yita_yarray, Y2_yarray = [], []

    # 有効除数の計算
    yuko = torch.dot(tsr_tani_array, tsr_tani_array)

    # 線形式の計算
    for i in range(len_temp):
        lnr_yitem  = torch.dot(tsr_sig_matrix[i], tsr_tani_array)
        btY1_yitem = lnr_yitem / yuko
        lnr_yarray.append(lnr_yitem.item())
        btY1_yarray.append(btY1_yitem.item())

    # 全変動ST及び各種中間指標SB,SE,VE,η
    for i in range(len_temp):
        sum_item  = torch.dot(tsr_sig_matrix[i], tsr_sig_matrix[i])
        st_yarray.append(sum_item.item())
        sb_yarray.append(lnr_yarray[i] ** 2 / yuko.item())
        se_yarray.append(st_yarray[i] - sb_yarray[i])

        # 異常処理
        temp_ve = se_yarray[i] / float(max_jy_index - 1.0)
        if temp_ve < 0.0000001:
            #comment = 'ゼロ異常発生！！'
            #print(comment)
            ve_yarray.append(-1.0)   
            yita_yarray.append(-1.0)  
            Y2_yarray.append(-1.0) 
        else:
            temp_Y2 = math.sqrt(temp_ve)
            ve_yarray.append(temp_ve)   
            yita_yarray.append(1.0 / temp_ve)  
            Y2_yarray.append(temp_Y2) 

    return btY1_yarray, Y2_yarray

#=================================================
# READ/OUTPUT CSV_FILE FUNCTION
#=================================================
# コントロールCSVファイルを読み込み表示する
def read_csvfile(file_readcsv): 
 
    # 画像ファイルの読み込み
    df = pd.read_csv(file_readcsv) 
    dfC = df[df["rtm"] == "signal"]
    dfC = dfC[dfC["camNO"] == 1]
    arr_nmSignal = dfC.loc[:,"file_name"].values
    arr_powers = dfC.loc[:,"diff_power"].values
    arr_posZs = dfC.loc[:,"diff_posZ"].values
    len_namPics = len(arr_nmSignal)
    #print(dfC)
  
    return len_namPics, arr_powers, arr_posZs, arr_nmSignal
    
# CSVファイルを出力する
def output_csvfile(mx_output): 

    #print(mx_output)

    # データフレームを作成
    arr_columns = ["picname", "posZs", "powers", "primY1", "primY2", "newY1", "newY2", "so-aY1", "soaY2", "soaY3", "cos", "dist"]
    df_metrics = pd.DataFrame(mx_output, columns=arr_columns)
    print("------------ primitive, new, soaRTメトリックスのデータフレーム -------------")  
    print(df_metrics) 

    # CSV ファイル (soaRT_{}_3Dscatter.csv.csv) として出力
    file_csvout = foldername + "soaRT_{}_3Dscatter.csv".format(pic_tani.replace(".png","")) # ファイルパス名の生成
    df_metrics.to_csv(file_csvout)
    print("CSVファイルの出力完了 : {}".format(file_csvout)) 

#=================================================
# MAIN PROGRAM(1) : 読み込み画像の対象を設定する
#=================================================
# 読み込み先の指定
foldername = "./ARRAY_RTCNN/"
newsize = (900, 500)
# -----
# RTベクトル長
rmax_jy_idx  = newsize[0]*newsize[1]

# -----
# CSVファイルの読み込み
file_cnv_input = foldername + "labels3_rectangle.csv"  # ファイルパス名の生成 
len_rmx, arr_powers, arr_posZs, arr_nmSignal = read_csvfile(file_cnv_input)
# -----
# 信号空間画像(計測ベクトル)
# 画像ファイル名(RECTANGULAR)
print(arr_nmSignal)
# Z方向への移動量
print(arr_posZs)
# ライトの光量
print(arr_powers)

# 単位空間画像(標準ベクトル)
#pic_tani = "average_bevelsq.png"
#pic_tani = "average_beveltri.png"
#pic_tani = "average_circle.png"
#pic_tani = "average_pentagon.png"
pic_tani = "average_rectangle2.png"
#pic_tani = "average_square.png"
#pic_tani = "average_torus.png"
#pic_tani = "average_triangle.png"

# initialise
metrics_cos = torch.nn.CosineSimilarity(dim=0)
L1_loss     = torch.nn.L1Loss()
arr_cos     = []
arr_dist    = []

# -----
# メトリックスの画像毎の繰り返し
for i in range(len_rmx):        # len_rmx

    #=================================================
    # MAIN PROGRAM(2) : 画像をテンソル化する(T,S)
    #=================================================
    # TS画像ファイルを読んで、TSテンソルを出力する
    img_tensorT, img_tensorS = read_TSpics(pic_tani, arr_nmSignal[i])
    print(img_tensorS)

    #=================================================
    # MAIN PROGRAM(3) : 畳み込みRTメトリックスを実行する
    #=================================================
    # ベクトル化
    img_arrayT = img_tensorT.flatten()
    #print(img_arrayT)
    img_arrayS = img_tensorS.flatten()
    # -----
    cSimilarity = metrics_cos(img_arrayS, img_arrayT)
    #print("cSimilarity: ", cSimilarity.item())
    mDistance = L1_loss(img_arrayS, img_arrayT)
    #print("mDistance: ", mDistance.item())
    # -----
    arr_cos.append(cSimilarity.item())
    arr_dist.append(mDistance.item())
    if i == 0:
        img_mxS = img_arrayS
    else:
        img_mxS = torch.vstack((img_mxS, img_arrayS))
# ------
# RTメトリックスを生成する
btY1_Parray, Y2_Parray = calc_RTmetrics(len_rmx, rmax_jy_idx, img_mxS, img_arrayT)
btY1_Narray, Y2_Narray = calc_newRT(len_rmx, rmax_jy_idx, img_mxS, img_arrayT)
btY1_Sarray, Y2_Sarray, Y3_Sarray = calc_soaRT(len_rmx, rmax_jy_idx, img_mxS, img_arrayT)
# ---------------------------
# メトリックスの計算結果を出力する
print("btY1_Narray: ", btY1_Narray)
print("Y2_Narray: ", Y2_Narray)
print("btY1_Sarray: ", btY1_Sarray)
print("Y2_Sarray: ", Y2_Sarray)
print("Y3_Sarray: ", Y3_Sarray)

#=================================================
# CSVファイルに出力し、グラフを表示する
#=================================================
mx_temp = np.vstack([arr_nmSignal, arr_posZs, arr_powers, btY1_Parray, Y2_Parray, btY1_Narray, Y2_Narray, btY1_Sarray, Y2_Sarray, Y3_Sarray, arr_cos, arr_dist])
mx_output = mx_temp.T
#print(mx_output)

# CSVファイルを出力する
#output_csvfile(mx_output)

# 散布図を出力する(せん断ひずみ類)
x  = arr_posZs
y  = arr_powers
z1 = Y2_Parray
z2 = Y2_Narray
z3 = Y3_Sarray
z0 = [0.0]*len(Y2_Sarray)
fig = plt.figure(figsize=(12, 10))
ax = fig.add_subplot(projection='3d')
#ax.scatter(x, y, z1, label="Primitive", color="green")
ax.scatter(x, y, z2, label="New", color="yellow")
ax.scatter(x, y, z3, label="SOA", color="red")
ax.scatter(x, y, z0, label="GROUND", color="blue")
ax.set_xlabel('Z-position')
ax.set_ylabel('Lidht-Power')
ax.set_zlabel('Techno-Metrics')
ax.grid(True)
ax.legend(loc='best')
plt.show()

# 散布図を出力する(体積ひずみ類)
x  = arr_posZs
y  = arr_powers
z  = Y2_Sarray
z0 = [0.0]*len(Y2_Sarray)
fig = plt.figure(figsize=(12, 10))
ax = fig.add_subplot(projection='3d')
ax.scatter(x, y, z0, label="GROUND", color="blue")
ax.scatter(x, y, z, label="SOAY2", color="red")
ax.set_xlabel('Z-position')
ax.set_ylabel('Lidht-Power')
ax.set_zlabel('Y2-Techno-Metrics')
ax.grid(True)
ax.legend(loc='best')
plt.show() 

```

QEU:FOUNDER ： “まずは分析結果を一つ紹介しましょう。新RT法のSN比(Y2)とSOART法のSN比(Y3)を比較しましょう。ここで、青色のプロットはバラツキを見やすくするためにZ=0のデータを追加したものです。”

![imageRL2-4-4](/2022-06-17-QEUR21_SOART2/imageRL2-4-4.jpg)

QEU:FOUNDER ： “ちょっと驚いたのだが、メトリックスY2(新RT)とY3(soaRT)の差異は思ったほど大きくなかった。あとは**Y2とY3を「空間的に比較する」と一部に上下が逆転する箇所があります**。それが面白い・・・。”

D先生 ： “ん？面白いですか？FOUNDERの考え方を察すると、もともと空間全部にわたってSOA-SN比が新RTのSN比よりも小さいと思っていたんでしょう。・・・でも、物体のサイズが小さい場合にはSN比が逆に高くなっていましたね。”

QEU:FOUNDER ： “一方、**物体サイズが単位空間と同じレベル(Z～0)であれば、すべてのSOASN比(Y3)は新SN比(Y2)よりも小さくなっているでしょう**。多分、これだけでも判別パフォーマンスには十分に効果あります。よく考えれば、物体サイズによる判別パフォーマンスを向上させることは、SOASN比(Y3)の力だけではできないです。「体積ひずみ（Y2）」を機械学習に積極的に使えばいいんですよ。”

![imageRL2-4-5](/2022-06-17-QEUR21_SOART2/imageRL2-4-5.jpg)

D先生 ： “三次元散布図（↑）によるとSOART法のY2メトリックスは明るさと物体サイズの簡単な関数になっています。なるほど・・・、**このメトリックスをディープラーニング（機械学習）に入力すれば予測精度もさらにあがる**でしょう。”

![imageRL2-4-6](/2022-06-17-QEUR21_SOART2/imageRL2-4-6.jpg)

QEU:FOUNDER ： “前回の外観検査自動機のトライアルの結果を思い出してください。**端子が正常なサンプルでも高いマハラノビス値（異常値）が出てきました。この異常の原因の一つは「明るさの変化」によるものでしょう。**パフォーマンスが従来RTよりも改善した新RT法でも明るさの変化は依然としてSN比の増加となって出てくるので、不良との区別がつかなかったんです。”

D先生 ： “前回は2つのライトの明るさをランダムに変化させていましたからね。・・・ということは、次のステップは「外観検査自動機プロジェクトの再トライ」ですね？”

QEU:FOUNDER ： “そうです・・・。今回の予備実験ではSOART法のY3の値が新RT法のY2より低い値が出ることがわかりました。・・・ということは、SOART法の異常検出精度は前回よりも確実にあがります。ただし、この方法でどれだけ改善するのかはわかりません。さあ、いよいよやってみましょう！つきましてはカンパをください！！”

### [＞寄付のお願い(Donate me)＜](https://www.paypal.com/paypalme/QEUglobal?v=1&utm_source=unp&utm_medium=email&utm_campaign=RT000481&utm_unptid=29844400-7613-11ec-ac72-3cfdfef0498d&ppid=RT000481&cnac=HK&rsta=en_GB%28en-HK%29&cust=5QPFDMW9B2T7Q&unptid=29844400-7613-11ec-ac72-3cfdfef0498d&calc=f860991d89600&unp_tpcid=ppme-social-business-profile-creat-ed&page=main%3Aemail%3ART000481&pgrp=main%3Aemail&e=cl&mchn=em&s=ci&mail=sys&appVersion=1.71.0&xt=104038)

D先生 ：“よろしくお願いします。”

## ～　まとめ　～

QEU:FOUNDER ： “あ～らあら、大好きなV国の女の子にこんなことを言われちゃって・・・。”

![imageRL2-4-7](/2022-06-17-QEUR21_SOART2/imageRL2-4-7.jpg)

QEU:FOUNDER ： “たった数年前に全従業員の前で**「青雲の志」を披露したオッサン**・・・。ただし、これは「聞いた話」で本当かは知らんがね・・・（笑）。”

### オッサン（海外工場のあいさつにて）：「私の使命はこの会社で終身雇用制を実現することにある・・・。」

D先生 : “FOUNDER・・・、ウソはいけません。いい年して、昨今のJ国の非常事態を理解できないお花畑がいるわけがありませんから・・・。”

QEU:FOUNDER ： “すまん、これはＳＦでした・・・（笑）。**そもそも外国人が「給料が上がらん国」に来て、幸せになるわけないじゃん・・・。**”

![imageRL2-4-8](/2022-06-17-QEUR21_SOART2/imageRL2-4-8.jpg)

D先生 : “これからは、**「（J国に）居ていただいてありがとう」と思わんと**・・・。”

[![MOVIE1](http://img.youtube.com/vi/DHdUCDoqXEs/0.jpg)](http://www.youtube.com/watch?v=DHdUCDoqXEs " れいわ新選組　衆議院議員　大石あきこ　キムテヨン　JR奈良駅東口コラボ街宣　2022.5.9　17:30～")

C部長 : “こんな人がたくさん出てくれればいいのに・・・。”

QEU:FOUNDER ： “小生は本国の給料を下げる外国人の流入政策には反対ですが、それでも好きになって「居ていただける」人をちゃんと盛り立てるべきだと思います。”
