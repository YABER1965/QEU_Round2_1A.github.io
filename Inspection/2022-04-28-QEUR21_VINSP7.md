---
title: QEUR21_VINSP7: オリエンテーション ～ 旧プロジェクト技術明細書(両目法_日本語版)
date: 2022-04-28
tags: ["QEUシステム", "Python言語", "外観検査", "RT法", "機械学習", "マハラノビス距離", "DX", "Blender"]
excerpt: Python言語を使った自動外観検査事例、技術論文
---

## QEUR21_VINSP7: オリエンテーション ～ 旧プロジェクト技術明細書(両目法_日本語版)

## ～　コレを加えるのを忘れていたワ・・・　～

QEU:FOUNDER ： “ファイブアイズのプロジェクト技術説明書をアップしました。あとで気が付いたのだが、両目法について説明していなかった・・・(笑)。”

D先生 ： “**両目法(double-eyed scheme)**はQEUプロジェクトの自動検査技術のマイルストーンの一つです。 “

QEU:FOUNDER ： “本当に何回もトライ・エラーをしたよね、これからも（失敗を）やるだろうけど・・・。このノウハウを一応シェアしておきたい。あとね・・・、追加説明として「自動検査には基本、ディープラーニングを使わない」という件を説明します。そのかわり、判別エンジンはSVM（サポート・ベクトル・マシン）になります。”

![image2-08A-1](/2022-04-28-QEUR21_VINSP7/image2-08A-1.jpg)

D先生 ： “FOUNDERは思いっきり「ディープラーニング推し(NNer)」のようにみえますが、実はそうでもない？“

QEU:FOUNDER ： “要するに適材適所・・・。ディープラーニングがなぜこれほど有効なのか、それは***‘Universal Approximation Theorem’***が論拠になります。もちろん、これはJeremy Howardの講義の受け売りだが・・・。”

![image2-08A-2](/2022-04-28-QEUR21_VINSP7/image2-08A-2.jpg)

QEU:FOUNDER ： “（当該プロセスから十分な）データさえ得られれば、あらゆる種類プロセスの関数近似ができることを「数学的に証明」しました。ただし、そのために「どのようなデータがどれだけ必要か？」ということ、さらには「満足できる近似に到達することを評価すること」とは別・・・。”

D先生 ： “万が一、流出不良が発生したとき、どのように是正するのか・・・・。 **ディープラーニングを現場に適用することは結構難しい**ですね。“

QEU:FOUNDER ： “逆にいうと、RTメトリックスなどのタグチメソッドの力を借りてこそ、SVM程度の学習器でも外観検査自動機への「まな板」に上がっているんです‘。結局、QEUシステムの結論は「T法（RT法）ってスゴイ！（残りはねぇ・・・）」ってことになってきたなァ・・・（笑）。そういえば・・・、ぜひカンパください。”

## [＞寄付のお願い(donate)＜](https://www.paypal.com/paypalme/QEUglobal?v=1&utm_source=unp&utm_medium=email&utm_campaign=RT000481&utm_unptid=29844400-7613-11ec-ac72-3cfdfef0498d&ppid=RT000481&cnac=HK&rsta=en_GB%28en-HK%29&cust=5QPFDMW9B2T7Q&unptid=29844400-7613-11ec-ac72-3cfdfef0498d&calc=f860991d89600&unp_tpcid=ppme-social-business-profile-creat-ed&page=main%3Aemail%3ART000481&pgrp=main%3Aemail&e=cl&mchn=em&s=ci&mail=sys&appVersion=1.71.0&xt=104038)

D先生 ： “どうぞ、よろしく。”

## ～　本文　～

## 【背景技術】
### 【０００２】
コンピューターによる画像認識手法はAIコンテストなどを通じて新しい手法が次々と開発されており、最近ではﾃﾞｨｰﾌﾟﾗｰﾆﾝｸﾞが高性能なエンジンとして高く評価されている(図1)。

**(図1 : 画像認識技術の変遷)**

![image2-08A-3](/2022-04-28-QEUR21_VINSP7/image2-08A-3.jpg)

### 【０００３】
機械学習の解析フローを図に示す(図2)。入力データの前処理も認識技術にとって重要な技術だが、あまり進歩がない。

**(図2 : 機械学習の作業手順)**

![image2-08A-4](/2022-04-28-QEUR21_VINSP7/image2-08A-4.jpg)

### 【０００４】
データの前処理の主な方法を下表に示す（図3、4）。画像の情報量を圧縮する方法としては、現在のところ主成分分析（PCA）により寄与率の低い高次の主成分を削除することが一般的である。

**(図3 : 機械学習における前処理の種類)**

![image2-08A-5](/2022-04-28-QEUR21_VINSP7/image2-08A-5.jpg)

**(図4 : 画像判別における前処理)**

![image2-08A-6](/2022-04-28-QEUR21_VINSP7/image2-08A-6.jpg)

## 【発明の概要】
### 【発明が解決しようとする課題】
### 【０００５】
コンピューターによる画像認識のパフォーマンス(判別精度)は年々向上しているが、それは学習手法（コア技術）の改善によるものであり、前処理の工夫による認識パフォーマンス改善の事例は少ない。

### 【０００６】
さらには、現在の画像認識パフォーマンスは主に静止画像ベースで行われており、自動車の自動運転などの場合には、さらに多くの種類のノイズや立体画像への考慮が必要になる。

### 【課題を解決するための手段】
### 【０００７】
***本発明は品質改善と品質改善で使用されているタグチメソッドのひとつであるRT(Recognition Taguchi)法を改善して画像認識の前処理プロセスとして使用する。***ここで、RT法はマハラノビス距離と同じように対象と単位空間（対象）の間の類似度の指標としてRT距離(D)というメトリックスを使用する（図5）。

**（図5 : 距離計算の考え方）**

![image2-08A-7](/2022-04-28-QEUR21_VINSP7/image2-08A-7.jpg)

### 【０００８】
本発明は、従来のRT法の感度(β)とSN比(η)の定義を変更して誤差因子を採用できるようにしたものである（図6,7）。以降、従来のRT法を片目法とし、本発明のRT法を両目法と呼ぶことにする。

**（図6：片目法-従来のRT法のSN比の定義）**

![image2-08A-8](/2022-04-28-QEUR21_VINSP7/image2-08A-8.jpg)

**(図7：両目法-本発明のRT法のSN比の定義)**

![image2-08A-9](/2022-04-28-QEUR21_VINSP7/image2-08A-9.jpg)

### 【０００９】
さて、本発明の誤差因子はユーザーの要求に合わせて任意に設定できるが、本文書の事例では立体物の画像認識に使用するものとする（図8）。このとき、下図のように3台のカメラを設置して、異なる角度から画像を採取する。従来の「片目法」は、CENTERのカメラ1台を使用する。一方、本発明の「両目法」は三種類(CENTER,LEFT,RIGHT)のカメラを使用する。

**（図8 : カメラの配置）**

![image2-08A-10](/2022-04-28-QEUR21_VINSP7/image2-08A-10.jpg)

### 【００１０】
それぞれ片目法と両目法とRTマルチ法を使用した画像認識の解析フローを以下に示す(図9,10)。両者の解析フローは一見は同じであるが、使用する画像データの種類と数、及び感度とSN比のメトリックスの定義が違う。

**（図9：従来片目RT（マルチ）法のSN比の解析ﾌﾛｰ）**

![image2-08A-11](/2022-04-28-QEUR21_VINSP7/image2-08A-11.jpg)

**(図10：本発明の両目RT（マルチ）法の解析ﾌﾛｰ)**

![image2-08A-12](/2022-04-28-QEUR21_VINSP7/image2-08A-12.jpg)

### 【００１１】
単位空間画像は、ユーザーがCENTERカメラの画像として選択した複数の画像を平均化処理することで得られる(図11,12)。

**(図11：単位空間の平均化処理)**

![image2-08A-13](/2022-04-28-QEUR21_VINSP7/image2-08A-13.jpg)

**(図12：単位空間のアウトプット)**

![image2-08A-14](/2022-04-28-QEUR21_VINSP7/image2-08A-14.jpg)

### 【００１２】
マルチRT法は、中間出力としてRT距離のマトリックスを生成する。そのために、画像を適切に分割してマトリックスを生成する（図13,14）。下図の事例では、画像を4x4=16に分割し、各々の領域でRT距離を計算している。

**（図13：分割設計）**

![image2-08A-15](/2022-04-28-QEUR21_VINSP7/image2-08A-15.jpg)

**（図14：RT距離マトリックス）**

![image2-08A-16](/2022-04-28-QEUR21_VINSP7/image2-08A-16.jpg)

### 【００１３】
マルチRT法の最終出力は、ステップ１のRT距離のマトリックスから再度RT距離値を計算することで得られる。RT距離の値は物体の特徴が単位空間に類似していると小さくなり、そうでないと大きくなる。つまり、複数の物体の単位空間を用意すれば、評価対象物がどの物体に最も類似しているのかを評価できる(図15)。

**（図15：類似度の比較）**

![image2-08A-17](/2022-04-28-QEUR21_VINSP7/image2-08A-17.jpg)

## 【実施例1】

### 【００１４】
本発明を物体の外観検査作業の自動化に応用した事例を以下に示す。外観検査の自動化において、3DCADやCGソフトウェアを使用して、単位空間を量産開始前に準備することができる。この事例では、**Blender**という 三次元CGソフトウェアを使用している(図16)。三次元CGソフトウェアは、仮想空間に複数のカメラを取り付けて同時に画像を撮影することができる(図17)。

**（図16 : Blenderの活用事例）**

![image2-08A-18](/2022-04-28-QEUR21_VINSP7/image2-08A-18.jpg)

**（図17  : 画像[左-中央-右]）**

![image2-08A-19](/2022-04-28-QEUR21_VINSP7/image2-08A-19.jpg)

### 【００１５】
本事例研究において、物体の外観を極力変えずに立体の一部の立体感を変えることを試みた。サルの頭のモデルにおいて、目と鼻を少し飛び出すように加工した（図18,19,20）。この物体形状の変化が従来の前処理（片目法）と本発明の前処理（両目法）によって、どのように検出できるかを試みた。

**（図18 : 正常な画像）**

![image2-08A-20](/2022-04-28-QEUR21_VINSP7/image2-08A-20.jpg)

**（図19 : 異常な画像[1]）**

![image2-08A-21](/2022-04-28-QEUR21_VINSP7/image2-08A-21.jpg)

**（図20 : 異常な画像[2]）**

![image2-08A-22](/2022-04-28-QEUR21_VINSP7/image2-08A-22.jpg)

### 【００１６】
従来の片目RT法を用いたときのステップ1（中間）RT距離のマトリックス計算結果を以下に示す（図21,22）。三次元CGの立体モデルで変更した部分は目と鼻だけであるため、マトリックスの周辺のセルの距離の値にはモデル変更前後で大きな変化がない（比率が1.0付近）。

**(図21 : 画像の比較)**

![image2-08A-23](/2022-04-28-QEUR21_VINSP7/image2-08A-23.jpg)

**(図22 : RT距離の比較)**

![image2-08A-24](/2022-04-28-QEUR21_VINSP7/image2-08A-24.jpg)

### 【００１７】
片目法を使用した、ステップ２（最終段階）のRT距離を計算した結果を下図に示す（図23）。ここで、メトリックスY1とY2はRT距離を計算するための感度(β)とSN比(η)の派生物である。片目法において、散布図の分布は非線形な挙動を示している。

**(図23 : RT距離の分布)**

![image2-08A-25](/2022-04-28-QEUR21_VINSP7/image2-08A-25.jpg)

### 【００１８】
本発明の両目RT法を用いたステップ1（中間）段階のRT距離のマトリックス計算結果を以下に示す（図24,25）。メトリックスY1とY2の計算法が違うので片目法と両目法の数値には差異がある。周辺部のセルの値がほとんど変わらず、中心部のセルの値が変わる。この傾向は片目法と同じである。

**（図24 : 立体画像比較[正常-異常]）**

![image2-08A-26](/2022-04-28-QEUR21_VINSP7/image2-08A-26.jpg)

**（図25 : 立体RT距離比較[正常-異常]）**

![image2-08A-27](/2022-04-28-QEUR21_VINSP7/image2-08A-27.jpg)

### 【００１９】
両目法を使用した、ステップ２（最終段階）のRT距離を下図に示す（図26）。ここで、Y1-Y2散布図は線形な分布を示している。

**（図26 : 立体RT距離の分布[両目]）**

![image2-08A-28](/2022-04-28-QEUR21_VINSP7/image2-08A-28.jpg)

### 【００２０】
さらに、誤判定の可能性を評価するために片目法と両目法を使用した、ステップ2（最終段階）のRT距離の変化を比較した（図12,13）。両目法のRT距離の変動は片目法の距離の変動よりも小さい。よって、両目法を使った場合のｴﾗｰ（誤判別）の可能性は片目法を使った場合よりも小さい。

**（図27：片目法におけるRT距離の比較）**

![image2-08A-29](/2022-04-28-QEUR21_VINSP7/image2-08A-29.jpg)

**（図28：両目法におけるRT距離の比較）**

![image2-08A-30](/2022-04-28-QEUR21_VINSP7/image2-08A-30.jpg)

## 【産業上の利用可能性】

### 【００２１】
本発明（両目法）は誤差因子を種々に定義することにより、産業上のあらゆるｺﾝﾋﾟｭｰﾀ認識技術に適用できる。特に、立体物の認識に適用する場合には、外観検査の自動化や自動車の自動運転などに使用できる。

### 【００２２】
画像で物体を認識する場合、1枚の画像だけでは正しい判断ができないことがある。例えば、下図の画像には三人がいるが、真ん中の人が小さいと見える（図29）。しかし、真ん中の人がカメラから遠い位置にいるとも考えられる（図30）。

**（図29：一枚の画像でわかること）**

![image2-08A-31](/2022-04-28-QEUR21_VINSP7/image2-08A-31.jpg)

**（図30：現実の立体の状況）**

![image2-08A-32](/2022-04-28-QEUR21_VINSP7/image2-08A-32.jpg)

### 【００２３】
物体間の距離を推測することは自動運転では重要であるが、現在の技術では難しい。本発明は物体認識と同時に物体間距離も同時に評価できるため、自動運転の安全性を改善する効果がある。

### 【００２４】
本発明は外観検査機に適用した場合にも大きな効果がある。製品(または部品)の欠陥においてピンやボス高さ寸法の過大や過小は1枚の画像を入力したｺﾝﾋﾟｭｰﾀ処理では発見しにくい。ほとんどの製品は転写による加工で製造されているので、欠陥のある部分のみが異なり、残りの部分は全く同じである。異なる角度から取った2枚の画像を比較することにより異常を発見しやすい。
