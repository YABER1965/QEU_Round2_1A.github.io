---
title: QEUR21_SOARTM5 – SOART法をもう一度試してみる(SOART2-その6)
date: 2022-07-13
tags: ["QEUシステム", "メトリックス", "Python言語", "機械学習", "マハラノビス距離", "DX", "Blender", "SOART法", "異常判別"]
excerpt: Python言語とSOART法を使った異常判別
---

## QEUR21_SOARTM5 – SOART法をもう一度試してみる(SOART2-その6)

## ～　わかっちゃいるが、手間がかかるのはちょっと・・・　～

D先生 ：“次は**畳み込みRT法と「Feature_Engineering」**のステップになります。Feature_Engineeringは広義ではすべての前処理を指すんですが・・・。”

![imageRL3-25-1](/2022-07-13-QEUR21_SOARTM5/imageRL3-25-1.jpg)

QEU:FOUNDER ; “一つのピン毎にワンセットのRTメトリックス（感度x6,SN比x6）を出力するようにします。単位空間を作る場合には3種(A,B,C)のみにしています。それでは、プログラムをドン！！”

```python
# -------------------- プログラムの始まり -------------------
# -*- coding: utf-8 -*-
# filename: soaRT2_multi_step2.py
# 複数画像を読み込み、マハラノビス距離を出力するための分散共分散行列を生成する 
# SOART2法用（マルチ-step2）
# Step2の単位空間は3種類(A,B,C)とする
# ---------------------------------------------------
# モジュールのインポート
import cv2
from fastai.vision.all import *
import pandas as pd
import numpy as np
import seaborn as sns
from scipy.spatial import distance

#=================================================
# MAIN PROGRAM(1) : 画像名csvファイルを読み込む
#=================================================
# VR画像ファイルを読み込み表示する
def read_vrImgfile(file_readcsv): 
 
    # 畳み込みファイルの読み込み
    df = pd.read_csv(file_readcsv) 
    #df = df[df["rtm"]=="tani"]  # キャンセルすると、移動、回転画像も使うことになる
    num_VRfs = len(df)
    # ------------------
    # file_nameのリストを生成する
    mx_Xs = df.loc[:,"file_name":"label"].values
    arr_VRsignal = df.loc[:,"file_name"].values
    #print("----- mx_Xs -----")
    #print(mx_Xs)
  
    return num_VRfs, mx_Xs, arr_VRsignal

# ---------------------------
# CSVファイル(実験)情報を読み込み表示する
foldername   = "./ARRAY_RTCNN/"
file_VRinput = foldername + "labels0_NORMAL.csv"  # ファイルパス名の生成 
num_VRfs, mx_Xs, arr_VRsignal = read_vrImgfile(file_VRinput)
#print(arr_VRsignal)

#=================================================
# MAIN PROGRAM(2) : パラメタの準備
#=================================================
# インスタンス化
L1_loss  = torch.nn.L1Loss()
MSE_loss = torch.nn.MSELoss()

# 画像リサイズのパラメタ
newsize = (900, 300)
# テンソルイメージ処理のパラメタ
cmax_sp_col, cmax_sp_row   = newsize[0], newsize[1]  #(900, 300)
# ストライド量
stride_sp_row, stride_sp_col = 5, 5
# RT法処理のサイズ
crtm_sp_row, crtm_sp_col = 5, 5
# STEP1処理後のマトリックスサイズ
max_sp_row, max_sp_col = 60, 180

# ---------------------------
# テンソル行列の処理(for)開始点のベクトルを生成する
row_sp_range, col_sp_range, mx_noPin = [], [], np.zeros([max_sp_row, max_sp_col])
sum_row = 0
while sum_row <= cmax_sp_row-crtm_sp_row:
    row_sp_range.append(sum_row)
    sum_row  += stride_sp_row
# -----
sum_col = 0
while sum_col <= cmax_sp_col-crtm_sp_col:
    col_sp_range.append(sum_col)
    sum_col  += stride_sp_col
#print("--- row_sp_range ---")
#print(row_sp_range)
#print("--- col_sp_range ---")
#print(col_sp_range)
# ---------------------------
# STEP1処理後のマトリックスの各要素がどのPIN番号に当たるのかを示す
for row in range(max_sp_row):
    for col in range(max_sp_col):
        irow, jcol  = int(row/20), int(col/20)
        mx_noPin[row, col] = irow*9 + jcol
#print("--- mx_noPin ---")
#print(mx_noPin)

#=================================================
# INRODUCING IMAGE FUNCTIONS
#=================================================
# 計測画像ファイルを読んで、テンソルを出力する
def read_pictures(pic_signal): 

    # ------------------
    # 単位画像(C)
    filenameC = foldername + "average_pic.png"
    imgC = cv2.imread(filenameC, cv2.IMREAD_GRAYSCALE)
    img_cropC = imgC[212:856,47:1867]
    # リサイズ
    img_resizeC = cv2.resize(img_cropC , newsize)

    # ------------------
    # 信号画像(S)
    filenameS = foldername + pic_signal
    imgS = cv2.imread(filenameS, cv2.IMREAD_GRAYSCALE)
    img_cropS = imgS[212:856,47:1867]
    # リサイズ
    img_resizeS = cv2.resize(img_cropS , newsize)

    # ------------------
    # 単位、信号画像データのテンソル化
    img_tani    = tensor(img_resizeC/255)  # 単位空間（標準ベクトル）
    img_signal  = tensor(img_resizeS/255)  # 信号空間（計測ベクトル）
    
    return img_tani, img_signal

# ---------------------------
# soaRT(Step1)メトリックスを計算する(テンソル活用版)
def calc_soaRT_step1(L1_loss, MSE_loss, tsr_sig_array, tsr_tani_array): 

    y = tsr_sig_array
    x = tsr_tani_array
    tsr_zero = torch.zeros(len(x))

    # 体積ひずみを計測
    vol_xtani = MSE_loss(x, tsr_zero) + 0.0001
    vol_ysig  = MSE_loss(y, tsr_zero) + 0.0001
    ratio_vol = vol_ysig/vol_xtani

    # せん断ひずみを計測
    mDistance   = L1_loss(y, ratio_vol*x)
    #print("mDistance: ", mDistance.item())

    return ratio_vol.item(), mDistance.item()

# ---------------------------
# 畳み込みSOARTメトリックスを生成する
def create_CRTmetric(L1_loss, MSE_loss, iCnt_file, tani_image, signal_images):

    # 畳み込みSOARTメトリックスをCSVファイルに出力するための行列（マトリックス）を初期化
    arr_iCnt, arr_noPin, arr_soaY2, arr_soaY3 = [], [], [], []
    # --------------------------
    iCnt_pix  = 0
    cnt_row   = 0
    for row in row_sp_range:
        cnt_col = 0
        for col in col_sp_range:
            # ------
            # 単位空間の空間ベクトルを生成する
            tsr_tani_array = tani_image[row:row+crtm_sp_row,col:col+crtm_sp_col].flatten()
            #print(tsr_tani_array)
            # ------
            # 信号空間の空間マトリックスを生成する
            tsr_sig_array  = signal_images[row:row+crtm_sp_row,col:col+crtm_sp_col].flatten()
            #print("----- tsr_sig_array -----")
            #print(tsr_sig_array)
            # ------
            # RTメトリックスを計算する
            val_Y2, val_Y3 = calc_soaRT_step1(L1_loss, MSE_loss, tsr_sig_array, tsr_tani_array)
            # ------
            # リストを生成する  
            arr_iCnt.append(iCnt_pix)  # 画素NO
            arr_noPin.append(mx_noPin[cnt_row, cnt_col])    # PINNO
            arr_soaY2.append(round(val_Y2, 5))  # Y2類
            arr_soaY3.append(round(val_Y3, 5))  # Y3類
            # ------
            # COUNT UP
            iCnt_pix  = iCnt_pix + 1
            cnt_col   = cnt_col + 1
        # ------
        # COUNT UP
        cnt_row = cnt_row + 1
    # ---------------------------
    # マトリックス化
    temp_file  = np.array([[iCnt_file]*len(arr_noPin)]).T
    temp_noPin = np.array([arr_noPin]).T
    temp_iCnt  = np.array([arr_iCnt]).T
    temp_soaY2 = np.array([arr_soaY2]).T
    temp_soaY3 = np.array([arr_soaY3]).T
    mx_metrics = np.concatenate([temp_file, temp_noPin, temp_iCnt, temp_soaY2, temp_soaY3], axis=1)
    # 結果のテキスト出力する
    #print("--- mx_metrics ---")
    #print(mx_metrics)

    return mx_metrics

# ------------------
# マハラノビス距離の補正リストを生成する
def adjust_values(acc_adj_dYs, raw_idx, adj_dys): 
 
    # インディックスを抽出して補正する
    for i in range(len(raw_idx)):
        acc_adj_dYs[int(raw_idx[i])] = adj_dys[i]
  
    return acc_adj_dYs

#=================================================
# READ TANI SPACE CSV_FILE FUNCTIONS
#=================================================
# ファイルを読み込み表示する(分散共分散逆行列)
def read_invcorr(code_cnv_input): 

    # 相関逆行列ファイルの読み込み
    file_cnv_input = foldername + code_cnv_input + ".csv"  # ファイルパス名の生成 
    df = pd.read_csv(file_cnv_input)
    # 選択項目の読み込み
    # Xsマトリックス
    mx_Xs = df.loc[:,"0":"1"].values
    #print("----- mx_Xs -----")
    #print(mx_Xs)
  
    return mx_Xs

# ------------------
# ファイルを読み込み表示する(単位空間の中心)
def read_taniXs(code_cnv_input): 
 
    # 単位空間の中心ファイルの読み込み
    file_cnv_input = foldername + code_cnv_input + ".csv"  # ファイルパス名の生成
    df = pd.read_csv(file_cnv_input) 
    # 選択項目の読み込み
    # Xsマトリックス
    mx_Xs = df.loc[:,"0":"1"].values
    #print("----- mx_Xs -----")
    #print(mx_Xs)
  
    return mx_Xs.flatten()

# ------------------
# SOART(Step1)の項目数（Y2, Y3）
def read_mahaStep1():

    acc_mx_tani, acc_mx_covi = [], []

    # PINNO毎にCSVファイルを出力する
    for iPin in range(9*3):

        # ファイルを読み込み表示する(相関逆行列)
        code_invcorr  = "invCor_pin{}".format(iPin)
        cov_iY = read_invcorr(code_invcorr)
        #print(cov_iY)
        # ------------------
        # ファイルを読み込み表示する(単位空間の中心)
        code_taniXs   = "taniXs_pin{}".format(iPin)
        arr_Xs_tani = read_taniXs(code_taniXs)
        #print(arr_Xs_tani)
        # ------------------
        # 単位空間データを累積する
        acc_mx_tani.append(arr_Xs_tani)
        acc_mx_covi.append(cov_iY)
    # ------------------
    # 出力
    #print("--- acc_mx_covi ---")
    #print(acc_mx_covi)
    #print("--- acc_mx_tani ---")
    #print(acc_mx_tani)

    return acc_mx_tani, acc_mx_covi

#=================================================
# CREATING STEP1 METRICS FUNCTIONS(SIGNAL)
#=================================================
# Step1メトリックスを生成する
def create_mtxStep1(pic_signal, acc_mx_tani, acc_mx_covi):

    # データフレームのコラム初期化
    arr_columns = ["fileno", "pinno", "pix", "Y2", "Y3"]
    # 計測画像ファイルを読んで、テンソルを出力する
    tani_image, signal_images = read_pictures(pic_signal)
    # SOARTメトリックス(STEP1)を生成する
    mx_metrics = create_CRTmetric(L1_loss, MSE_loss, iCnt_file, tani_image, signal_images)
    # データフレームを作成する
    df_metrics = pd.DataFrame(mx_metrics, columns=arr_columns)
    arr_pins   = df_metrics.loc[:,"pinno"].values

    # -------------
    # マハラノビス距離(Step1)配列の初期化
    arr_index, arr_mahadis = [], []
    # マハラノビス距離(Step1)を計算する
    for iCnt_maha in range(len(arr_pins)):

        slice_data  = df_metrics.loc[iCnt_maha,"Y2":"Y3"].values
        val_pins    = arr_pins[iCnt_maha]
        arr_Xs_tani = acc_mx_tani[int(val_pins)]
        cov_iY      = acc_mx_covi[int(val_pins)]
        dY = distance.mahalanobis(slice_data, arr_Xs_tani, cov_iY)
        arr_index.append(iCnt_maha)
        arr_mahadis.append(round(dY,2))
    # -------------
    # データフレームを作成する
    df_metrics["maha"] = arr_mahadis
    df_metrics["idx"]  = arr_index
    #print("------------ df_metrics -------------")  
    #print(df_metrics) 

    # -------------
    # Step1メトリックスの補正(adjust)
    arr_max_dYs = []
    acc_adj_dYs = np.zeros(len(arr_pins))
    for iCnt_adj in range(3*9):

        temp_dYs = df_metrics[df_metrics["pinno"]==iCnt_adj]
        raw_idx  = temp_dYs["idx"].values
        raw_dYs  = temp_dYs["maha"].values
        arr_max_dYs.append(np.amax(raw_dYs))
        adj_dys  = np.amax(raw_dYs) - raw_dYs
        # 補正リストを生成する
        acc_adj_dYs = adjust_values(acc_adj_dYs, raw_idx, adj_dys)
    # -----
    # リスト結果を表示する
    df_metrics["adj"]  = acc_adj_dYs
    #print("len_metrics:",len(df_metrics))
    #print("----- df_metrics -----")
    #print(df_metrics)

    return df_metrics

#=================================================
# MAIN PROGRAM(3) : SOART(Step1)の蓄積マトリックス(SIGNAL)を生成する
#=================================================
# 累積マトリックス
acc_mx_sigStep1 = []

# マハラノビス（STEP1）メトリックスデータを読む
acc_mx_tani, acc_mx_covi = read_mahaStep1()

# メンバ画像のデータをマトリックス化する
for iCnt_file in range(num_VRfs):   # num_VRfs

    # 読み込み先の指定
    pic_signal = arr_VRsignal[iCnt_file] + ".png"   # 計測画像(計測ベクトル)

    # Step1メトリックスを生成する
    df_metrics = create_mtxStep1(pic_signal, acc_mx_tani, acc_mx_covi)
    #print("len_metrics:",len(df_metrics))
    #print("----- df_metrics -----")
    #print(df_metrics)

    # 行列(マトリックス)を作る
    # STEP1処理後の信号マトリックスのサイズ
    arr_temp = df_metrics["adj"].values
    mx_metStep1 = arr_temp.reshape([max_sp_row, max_sp_col])
    #print("----- mx_metStep1 -----")
    #print(mx_metStep1)

    #----- mx_metStep1 -----
    #[[0.23 0.31 0.26 ... 0.18 0.27 0.31]
    # [0.26 0.25 0.2  ... 0.23 0.32 0.31]
    # [0.37 0.34 0.21 ... 0.14 0.22 0.39]
    # ...
    # [0.26 0.26 0.1  ... 0.04 0.19 0.28]
    # [0.26 0.28 0.23 ... 0.07 0.21 0.25]
    # [0.19 0.27 0.26 ... 0.18 0.22 0.28]]

    # 行列(マトリックス)を蓄積する
    acc_mx_sigStep1.append(np.array(mx_metStep1))
# ------
# 蓄積された信号マトリックスを表示する
#print("----- acc_mx_sigStep1 -----")
#print(acc_mx_sigStep1)


#=================================================
# READ STEP1 CSV_FILE FUNCTION(TANI)
#=================================================
# 単位空間（平均画像）のStep1データを読み込み表示する
def read_tanifile(file_readcsv): 
 
    # 畳み込みファイルの読み込み
    df = pd.read_csv(file_readcsv) 
    # ------------------
    # 選択項目の読み込み
    # Xsマトリックス
    mx_Xs = df.loc[:,"0":"179"].values
    #print("----- mx_Xs -----")
    #print(mx_Xs)
  
    return mx_Xs

#=================================================
# MAIN PROGRAM(4) : SOART(Step1)の蓄積マトリックス(TANI)を生成する
#=================================================
# 単位空間ファイルを読み込み表示する
file_tani_input = foldername + "step1_metrics_tani.csv"  # ファイルパス名の生成
mx_taniStep1 = read_tanifile(file_tani_input)
# ------
# 蓄積された単位マトリックスを表示する
#print("----- mx_taniStep1 -----")
#print(mx_taniStep1)

#=================================================
# READ CONVOLUTION CSV_FILE FUNCTION
#=================================================
# 畳み込み部品ファイルを読み込み表示する
def read_csvfile(file_readcsv): 
 
    # 畳み込みファイルの読み込み
    df = pd.read_csv(file_readcsv) 
    # ------------------
    # 選択項目の読み込み
    # Xsマトリックス
    mx_Xs = df.loc[:,"col1":"col5"].values
    #print("----- mx_Xs -----")
    #print(mx_Xs)
  
    return mx_Xs

#=================================================
# MAIN PROGRAM(5) : 畳み込みメトリックスの準備
#=================================================
# パラメタの設定
max_cnv_parts  = 8
# ファイル名の指定
nam_cnv_input = "基準用CSVデータ" 
code_cnv_input = ["NA"] * max_cnv_parts     # CSVコードの指定
code_cnv_input[0] = "bend1_cnv"     # CSVコードの指定
code_cnv_input[1] = "bend2_cnv"     # CSVコードの指定
code_cnv_input[2] = "bend3_cnv"     # CSVコードの指定
code_cnv_input[3] = "bend4_cnv"     # CSVコードの指定
code_cnv_input[4] = "line1_cnv"     # CSVコードの指定
code_cnv_input[5] = "line2_cnv"     # CSVコードの指定
code_cnv_input[6] = "datum1_cnv"    # CSVコードの指定
code_cnv_input[7] = "datum2_cnv"    # CSVコードの指定
# ------------------
# 畳み込み処理を実施する
for i in range(max_cnv_parts):
    # ---------------------------
    # CSVファイル(実験)情報を読み込み表示する
    # 畳み込みファイル
    file_cnv_input = foldername + code_cnv_input[i] + ".csv"  # ファイルパス名の生成 
    mx_conv = read_csvfile(file_cnv_input)
    if i == 0:    
        tensor_bend1 = tensor(mx_conv).float()
    elif i == 1:
        tensor_bend2 = tensor(mx_conv).float()
    elif i == 2:
        tensor_bend3 = tensor(mx_conv).float()
    elif i == 3:
        tensor_bend4 = tensor(mx_conv).float()
    elif i == 4:
        tensor_line1 = tensor(mx_conv).float()
    elif i == 5:
        tensor_line2 = tensor(mx_conv).float()
    elif i == 6:
        tensor_datum1 = tensor(mx_conv).float()
    elif i == 7:
        tensor_datum2 = tensor(mx_conv).float()
# ---------------------------
# 畳み込みカーネルを生成する
signal_kernels  = torch.stack([tensor_bend1, tensor_bend2, tensor_bend3, tensor_bend4, tensor_line1, tensor_line2])
tani_kernel     = tensor_datum1 + tensor_datum2
# カーネルを表示する
#print("--- signal_kernels ---")
#print(signal_kernels)
#print("--- tani_kernel ---")
#print(tani_kernel)


#=================================================
# MAIN PROGRAM(5) : 畳み込みRTメトリックスの準備
#=================================================
# STEP1処理後のマトリックスサイズ
conv_newsize = (180, 60)
# 畳み込み処理のパラメタ
max_cnv_col, max_cnv_row = conv_newsize[0], conv_newsize[1]  #(900, 300)
# 畳み込み処理のサイズ
cmx_cnv_row, cmx_cnv_col = 5, 5
# ストライド量
stride_cnv_row, stride_cnv_col = 5, 5

# ---------------------------
# [畳み込み] : テンソル行列の畳み込み処理開始点のベクトルを生成する
row_cnv_range, col_cnv_range = [], []
sum_row = 0
while sum_row <= max_cnv_row-cmx_cnv_row:
    row_cnv_range.append(sum_row)
    sum_row  += stride_cnv_row
# -----
sum_col = 0
while sum_col <= max_cnv_col-cmx_cnv_col:
    col_cnv_range.append(sum_col)
    sum_col  += stride_cnv_col
#print("--- row_cnv_range ---")
#print(row_cnv_range)
#print("--- col_cnv_range ---")
#print(col_cnv_range)

# ---------------------------
# STEP1処理後のマトリックスサイズ
rtm_newsize = (36, 12)
# テンソルイメージ処理のパラメタ
max_rtm_col, max_rtm_row = rtm_newsize[0], rtm_newsize[1]  #(900, 300)
# RT法処理のサイズ
dmx_rtm_row, dmx_rtm_col = 4, 4
# RT法処理のストライド量
stride_rtm_row, stride_rtm_col = 4, 4
# RTベクトル長と信号空間長
dmax_jy_idx  = 4 * 4    # 処理する領域のサイズ
len_dmx      = 6        # ベンド系とライン系

# ---------------------------
# [RTメトリックス] : テンソル行列の畳み込み処理開始点のベクトルを生成する
row_rtm_range, col_rtm_range = [], []
sum_row = 0
while sum_row <= max_rtm_row-dmx_rtm_row:
    row_rtm_range.append(sum_row)
    sum_row  += stride_rtm_row
# -----
sum_col = 0
while sum_col <= max_rtm_col-dmx_rtm_col:
    col_rtm_range.append(sum_col)
    sum_col  += stride_rtm_col
#print("--- row_rtm_range ---")
#print(row_rtm_range)
#print("--- col_rtm_range ---")
#print(col_rtm_range)


#=================================================
# CONVOLUTION FUNCTIONS
#=================================================
# 畳み込み処理を実施する
def apply_kernel(row, col, kernel, img_tensor):
    return (img_tensor[row:row+cmx_cnv_row,col:col+cmx_cnv_col] * kernel).sum()

# ---------------------------
# soaRT(Step2)メトリックスを計算する(テンソル活用版)
def calc_soaRT_step2(L1_loss, len_dmx, cmax_jy_idx, tsr_sig_matrix, tsr_tani_array): 

    # 変数の初期化
    btY1_yarray, Y2_yarray = [], []

    # 繰り返し
    for iCmx in range(len_dmx):

        y = tsr_sig_matrix[iCmx]
        x = tsr_tani_array

        # 回転を計測
        xx = torch.dot(x,x) + 0.0001
        xy = torch.dot(x,y) + 0.0001
        beta = xy/xx
        #print("iCmx:{}, beta:{}".format(iCmx, beta))

        # せん断ひずみを計測
        mDistance   = L1_loss(y, beta*x)
        #print("mDistance: ", mDistance.item())
        
        btY1_yarray.append(beta.item())
        Y2_yarray.append(mDistance.item())

    return btY1_yarray, Y2_yarray

# ---------------------------
# 畳み込みテンソルイメージを生成する
def create_tsrConv(tensor_Y1Y2):

    # 単位空間用の畳み込み処理を実施する
    tani_image = tensor([[apply_kernel(i,j, tani_kernel, tensor_Y1Y2) for j in col_cnv_range] for i in row_cnv_range])
    #print("----- tani_image -----")
    #print(tani_image)
    # ------------------
    # 信号空間用の畳み込み処理を実施する
    for i in range(max_cnv_parts-2):
        # ---------------------------
        # CSVファイル(実験)情報を読み込み表示する
        kernel = signal_kernels[i]
        calc_conv = tensor([[apply_kernel(i,j, kernel, tensor_Y1Y2) for j in col_cnv_range] for i in row_cnv_range])
        # -----
        if i == 0:    
            tsr_cvbend1 = tensor(calc_conv).float()
        elif i == 1:
            tsr_cvbend2 = tensor(calc_conv).float()
        elif i == 2:
            tsr_cvbend3 = tensor(calc_conv).float()
        elif i == 3:
            tsr_cvbend4 = tensor(calc_conv).float()
        elif i == 4:
            tsr_cvline1 = tensor(calc_conv).float()
        elif i == 5:
            tsr_cvline2 = tensor(calc_conv).float()
    # ---------------------------
    # 畳み込みテンソルイメージの生成  
    signal_images = torch.stack([tsr_cvbend1, tsr_cvbend2, tsr_cvbend3, tsr_cvbend4, tsr_cvline1, tsr_cvline2])
    # 結果の出力
    #print(signal_images.shape)     # torch.Size([6, 12, 36])
    #print("----- signal_images[0] -----")
    #print(signal_images[0])

    return tani_image, signal_images

# ---------------------------
# 畳み込みSOARTメトリックスを生成する
def create_CRTmetric(tani_image, signal_images):

    # 畳み込みSOARTメトリックスをCSVファイルに出力するための行列（マトリックス）を初期化
    mx_p0Y1, mx_p1Y1, mx_p2Y1 = np.zeros([3,9]), np.zeros([3,9]), np.zeros([3,9])
    mx_p3Y1, mx_p4Y1, mx_p5Y1 = np.zeros([3,9]), np.zeros([3,9]), np.zeros([3,9])
    # ----
    mx_p0Y2, mx_p1Y2, mx_p2Y2 = np.zeros([3,9]), np.zeros([3,9]), np.zeros([3,9])
    mx_p3Y2, mx_p4Y2, mx_p5Y2 = np.zeros([3,9]), np.zeros([3,9]), np.zeros([3,9])
    # ---------------------------
    cnt_row = 0
    for row in row_rtm_range:
        cnt_col = 0
        for col in col_rtm_range:
            # ------
            # 単位空間の空間ベクトルを生成する
            tsr_tani_array = tani_image[row:row+dmx_rtm_row,col:col+dmx_rtm_col].flatten()
            #print(tsr_tani_array)
            # ------
            # 信号空間の空間マトリックスを生成する
            temp_matrix = signal_images[0]
            tsr_sig_p0 = temp_matrix[row:row+dmx_rtm_row,col:col+dmx_rtm_col].flatten()
            temp_matrix = signal_images[1]
            tsr_sig_p1 = temp_matrix[row:row+dmx_rtm_row,col:col+dmx_rtm_col].flatten()
            temp_matrix = signal_images[2]
            tsr_sig_p2 = temp_matrix[row:row+dmx_rtm_row,col:col+dmx_rtm_col].flatten()
            temp_matrix = signal_images[3]
            tsr_sig_p3 = temp_matrix[row:row+dmx_rtm_row,col:col+dmx_rtm_col].flatten()
            temp_matrix = signal_images[4]
            tsr_sig_p4 = temp_matrix[row:row+dmx_rtm_row,col:col+dmx_rtm_col].flatten()
            temp_matrix = signal_images[5]
            tsr_sig_p5 = temp_matrix[row:row+dmx_rtm_row,col:col+dmx_rtm_col].flatten()
            # -----
            tsr_sig_matrix = torch.stack([tsr_sig_p0, tsr_sig_p1, tsr_sig_p2, tsr_sig_p3, tsr_sig_p4, tsr_sig_p5])
            #print("----- tsr_sig_matrix -----")
            #print(tsr_sig_matrix)
            # ------
            # soaRT(Step2)メトリックスを計算する(テンソル活用版)
            btY1_yarray, Y2_yarray = calc_soaRT_step2(L1_loss, len_dmx, dmax_jy_idx, tsr_sig_matrix, tsr_tani_array)
            # ------
            # CSV出力用のマトリックスを生成する  
            # Y1類
            mx_p0Y1[cnt_row, cnt_col] = round(btY1_yarray[0],3)
            mx_p1Y1[cnt_row, cnt_col] = round(btY1_yarray[1],3)
            mx_p2Y1[cnt_row, cnt_col] = round(btY1_yarray[2],3)
            mx_p3Y1[cnt_row, cnt_col] = round(btY1_yarray[3],3)
            mx_p4Y1[cnt_row, cnt_col] = round(btY1_yarray[4],3)
            mx_p5Y1[cnt_row, cnt_col] = round(btY1_yarray[5],3)
            # -----
            # Y2類
            mx_p0Y2[cnt_row, cnt_col] = round(Y2_yarray[0],3)
            mx_p1Y2[cnt_row, cnt_col] = round(Y2_yarray[1],3)
            mx_p2Y2[cnt_row, cnt_col] = round(Y2_yarray[2],3)
            mx_p3Y2[cnt_row, cnt_col] = round(Y2_yarray[3],3)
            mx_p4Y2[cnt_row, cnt_col] = round(Y2_yarray[4],3)
            mx_p5Y2[cnt_row, cnt_col] = round(Y2_yarray[5],3)
            # ------
            # COUNT UP
            #print(cnt_row, cnt_col)
            cnt_col = cnt_col + 1
        # ------
        # COUNT UP
        cnt_row = cnt_row + 1
    # ---------------------------
    # 行列（マトリックス）を生成する
    mx_Y1A   = np.concatenate([[mx_p0Y1[:,0:2].flatten()], [mx_p1Y1[:,0:2].flatten()], [mx_p2Y1[:,0:2].flatten()], [mx_p3Y1[:,0:2].flatten()], [mx_p4Y1[:,0:2].flatten()], [mx_p5Y1[:,0:2].flatten()]], axis=0)
    mx_Y1B   = np.concatenate([[mx_p0Y1[:,2:7].flatten()], [mx_p1Y1[:,2:7].flatten()], [mx_p2Y1[:,2:7].flatten()], [mx_p3Y1[:,2:7].flatten()], [mx_p4Y1[:,2:7].flatten()], [mx_p5Y1[:,2:7].flatten()]], axis=0)
    mx_Y1C   = np.concatenate([[mx_p0Y1[:,7:9].flatten()], [mx_p1Y1[:,7:9].flatten()], [mx_p2Y1[:,7:9].flatten()], [mx_p3Y1[:,7:9].flatten()], [mx_p4Y1[:,7:9].flatten()], [mx_p5Y1[:,7:9].flatten()]], axis=0)
    # ------
    mx_Y2A   = np.concatenate([[mx_p0Y2[:,0:2].flatten()], [mx_p1Y2[:,0:2].flatten()], [mx_p2Y2[:,0:2].flatten()], [mx_p3Y2[:,0:2].flatten()], [mx_p4Y2[:,0:2].flatten()], [mx_p5Y2[:,0:2].flatten()]], axis=0)
    mx_Y2B   = np.concatenate([[mx_p0Y2[:,2:7].flatten()], [mx_p1Y2[:,2:7].flatten()], [mx_p2Y2[:,2:7].flatten()], [mx_p3Y2[:,2:7].flatten()], [mx_p4Y2[:,2:7].flatten()], [mx_p5Y2[:,2:7].flatten()]], axis=0)
    mx_Y2C   = np.concatenate([[mx_p0Y2[:,7:9].flatten()], [mx_p1Y2[:,7:9].flatten()], [mx_p2Y2[:,7:9].flatten()], [mx_p3Y2[:,7:9].flatten()], [mx_p4Y2[:,7:9].flatten()], [mx_p5Y2[:,7:9].flatten()]], axis=0)

    return mx_Y1A.T, mx_Y1B.T, mx_Y1C.T, mx_Y2A.T, mx_Y2B.T, mx_Y2C.T


#=================================================
# MAIN PROGRAM(6) : 畳み込みRTメトリックスを生成する
#=================================================
# 畳み込みテンソルイメージを生成する
tani_image, signal_images = create_tsrConv(torch.tensor(mx_taniStep1).float())
# 畳み込みSOARTメトリックスを生成する
mx_tani_Y1AT, mx_tani_Y1BT, mx_tani_Y1CT, mx_tani_Y2AT, mx_tani_Y2BT, mx_tani_Y2CT = create_CRTmetric(tani_image, signal_images)
# 単位メトリックス(Y1-A,B,C)
#print("----- mx_tani_Y1AT -----")
#print(mx_tani_Y1AT)
# 単位メトリックス(Y2-A,B,C)
#print("----- mx_tani_Y2AT -----")
#print(mx_tani_Y2AT)

# ---------------------------
# 信号Step1メトリックスの番号指定
# 累積メトリックス
acc_diff_Y1A, acc_diff_Y2A = [], []
acc_diff_Y1B, acc_diff_Y2B = [], []
acc_diff_Y1C, acc_diff_Y2C = [], []

# 信号マトリックスの処理
for iVrf in range(num_VRfs):   # 画像の数

    # 畳み込みテンソルイメージを生成する
    tani_image, signal_images = create_tsrConv(torch.tensor(acc_mx_sigStep1[iVrf]).float())
    # 畳み込みSOARTメトリックスを生成する
    mx_sig_Y1AT, mx_sig_Y1BT, mx_sig_Y1CT, mx_sig_Y2AT, mx_sig_Y2BT, mx_sig_Y2CT = create_CRTmetric(tani_image, signal_images)

    # ---------------------------
    # [Diff]マトリックスの差異
    mx_diff_Y1A = mx_sig_Y1AT - mx_tani_Y1AT
    mx_diff_Y2A = mx_sig_Y2AT - mx_tani_Y2AT
    mx_diff_Y1B = mx_sig_Y1BT - mx_tani_Y1BT
    mx_diff_Y2B = mx_sig_Y2BT - mx_tani_Y2BT
    mx_diff_Y1C = mx_sig_Y1CT - mx_tani_Y1CT
    mx_diff_Y2C = mx_sig_Y2CT - mx_tani_Y2CT
    # 差異メトリックス(Y1-A,B,C)
    #print("----- mx_diff_Y1A, iVrf: {} -----".format(iVrf))
    #print(mx_diff_Y1A)
    # 差異メトリックス(Y2-A,B,C)
    #print("----- mx_diff_Y2A, iVrf: {} -----".format(iVrf))
    #print(mx_diff_Y2A)

    # ---------------------------
    # 信号Step1メトリックスの番号指定
    # 累積メトリックス
    if iVrf == 0:
        acc_diff_Y1A = mx_diff_Y1A
        acc_diff_Y2A = mx_diff_Y2A
        acc_diff_Y1B = mx_diff_Y1B
        acc_diff_Y2B = mx_diff_Y2B
        acc_diff_Y1C = mx_diff_Y1C
        acc_diff_Y2C = mx_diff_Y2C
    else:
        acc_diff_Y1A = np.concatenate([acc_diff_Y1A, mx_diff_Y1A], axis = 0)
        acc_diff_Y2A = np.concatenate([acc_diff_Y2A, mx_diff_Y2A], axis = 0)
        acc_diff_Y1B = np.concatenate([acc_diff_Y1B, mx_diff_Y1B], axis = 0)
        acc_diff_Y2B = np.concatenate([acc_diff_Y2B, mx_diff_Y2B], axis = 0)
        acc_diff_Y1C = np.concatenate([acc_diff_Y1C, mx_diff_Y1C], axis = 0)
        acc_diff_Y2C = np.concatenate([acc_diff_Y2C, mx_diff_Y2C], axis = 0)

# ---------------------------
# 累積差異メトリックス(Y1-A,B,C)
print("acc_diff_Y1A: ",acc_diff_Y1A.shape)
print("----- acc_diff_Y1A -----")
print(acc_diff_Y1A)
# 累積差異メトリックス(Y2-A,B,C)
print("----- acc_diff_Y2A -----")
print(acc_diff_Y2A)


#=================================================
# OUTFILE CSV FUNCTIONS
#=================================================
# CSVファイルに出力する(分散共分散逆行列)
def save_invcorr(mx_result, code_invcorr): 

    # データフレームを作成
    arr_index = list(range(max_iRow_items))
    arr_columns = list(range(max_iRow_items))
    df_metrics = pd.DataFrame(mx_result, index=arr_index, columns=arr_columns)
    #print("------------ 分散共分散逆行列のデータフレーム -------------")  
    #print(df_metrics) 
    # CSV ファイル (Rtm_covYX.csv) として出力
    file_csvout = foldername + code_invcorr + ".csv" # ファイルパス名の生成
    df_metrics.to_csv(file_csvout)
    print("CSVファイルの出力完了 : {}".format(file_csvout)) 
    
    return df_metrics

# ---------------------------
# CSVファイルに出力する(単位空間の中心)
def save_taniXs(mx_result, code_taniXs): 

    # ---------------------------
    # データフレームを作成
    arr_columns = list(range(max_iRow_items))
    df_metrics = pd.DataFrame(mx_result, columns=arr_columns)
    #print("------------ 単位空間の中心のデータフレーム -------------")  
    #print(df_metrics) 
    # CSV ファイル (Rtm_aveYX.csv) として出力
    file_csvout = foldername + code_taniXs + ".csv" # ファイルパス名の生成
    df_metrics.to_csv(file_csvout)
    print("CSVファイルの出力完了 : {}".format(file_csvout)) 
    
    return df_metrics

#=================================================
# MAIN PROGRAM(7) : マハラノビス距離計算用の逆行列を計算する
#=================================================
# 項目数（感度またはSN比6件）
max_iRow_items = 6

# -----
# 単位空間のマハラノビス計算用データ（分散共分散行列）を生成する
def calc_tanimx(mx_Xs_tani): 
    arr_Xs_tani = []
    for kItem in range(max_iRow_items):
        # 中央値を計算する
        mean_X_tani = np.mean(mx_Xs_tani[kItem, :])
        arr_Xs_tani.append(mean_X_tani)
    #print("---- arr_Xs_tani ----")
    #print(arr_Xs_tani)
    # ------------------
    # 単位空間を用いた学習(1) : 分散共分散行列を計算する
    cov = np.cov(mx_Xs_tani.T)
    # 分散共分散行列の逆行列を計算する
    cov_i = np.linalg.pinv(cov)
    #print("---- cov_i ----")
    #print(cov_i)
    
    return arr_Xs_tani, cov_i

# ---------------------------
# CSVファイルに出力する(相関逆行列)
# ---------------------------
# Y1類の場合
arr_Xs_Y1A, cov_iY1A = calc_tanimx(acc_diff_Y1A)
arr_Xs_Y1B, cov_iY1B = calc_tanimx(acc_diff_Y1B)
arr_Xs_Y1C, cov_iY1C = calc_tanimx(acc_diff_Y1C)
# -----
# Y2類の場合
arr_Xs_Y2A, cov_iY2A = calc_tanimx(acc_diff_Y2A)
arr_Xs_Y2B, cov_iY2B = calc_tanimx(acc_diff_Y2B)
arr_Xs_Y2C, cov_iY2C = calc_tanimx(acc_diff_Y2C)
print(arr_Xs_Y2A)
print(cov_iY2A)

# ---------------------------
# CSVファイルに出力する(分散共分散逆行列)
# ---------------------------
# Y1類の場合
save_invcorr(cov_iY1A, "Rtm_covY1A")
save_invcorr(cov_iY1B, "Rtm_covY1B")
save_invcorr(cov_iY1C, "Rtm_covY1C")
# -----
# Y2類の場合
save_invcorr(cov_iY2A, "Rtm_covY2A")
save_invcorr(cov_iY2B, "Rtm_covY2B")
save_invcorr(cov_iY2C, "Rtm_covY2C")

# ---------------------------
# CSVファイルに出力する(単位空間の中心)
# ---------------------------
# Y1類の場合
save_taniXs([arr_Xs_Y1A], "Rtm_aveY1A")
save_taniXs([arr_Xs_Y1B], "Rtm_aveY1B")
save_taniXs([arr_Xs_Y1C], "Rtm_aveY1C")
# -----
# Y2類の場合
save_taniXs([arr_Xs_Y2A], "Rtm_aveY2A")
save_taniXs([arr_Xs_Y2B], "Rtm_aveY2B")
save_taniXs([arr_Xs_Y2C], "Rtm_aveY2C")

```

QEU:FOUNDER ： “今回も中間段階です。本来は特に言うことはないですが・・・。まずは、CSVファイルの出力結果から・・・。”

![imageRL3-25-2](/2022-07-13-QEUR21_SOARTM5/imageRL3-25-2.jpg)

QEU:FOUNDER ： “これらのCSVファイルの中身はこんな感じです。”

![imageRL3-25-3](/2022-07-13-QEUR21_SOARTM5/imageRL3-25-3.jpg)

D先生 ：“次は特徴量マップの出力ですが、前回と同様に感度のマハラノビス距離とSN比のそれを分けるんですよね？”

QEU:FOUNDER ： “もちろん・・・。”

## ～　まとめ　～

### ・・・　前回のつづき（ヨハネ福音書-第11章）　・・・

するとユダヤ人たちは言った、「ああ、なんと彼を愛しておられたことか」。
しかし、彼らのある人たちは言った、「あの盲人の目をあけたこの人でも、ラザロを死なせないようには、できなかったのか」。
イエスはまた激しく感動して、墓にはいられた。それは洞穴であって、そこに石がはめてあった。
イエスは言われた、「石を取りのけなさい」。死んだラザロの姉妹マルタが言った、「主よ、もう臭くなっております。四日もたっていますから」。
イエスは彼女に言われた、「もし信じるなら神の栄光を見るであろうと、あなたに言ったではないか」。
人々は石を取りのけた。すると、イエスは目を天にむけて言われた、「父よ、わたしの願いをお聞き下さったことを感謝します。
あなたがいつでもわたしの願いを聞きいれて下さることを、よく知っています。しかし、こう申しますのは、そばに立っている人々に、あなたがわたしをつかわされたことを、信じさせるためであります」。
こう言いながら、大声で「ラザロよ、出てきなさい」と呼ばわれた。
すると、死人は手足を布でまかれ、顔も顔おおいで包まれたまま、出てきた。イエスは人々に言われた、「彼をほどいてやって、帰らせなさい」。

C部長 : “よくわかりません。何を言いたい？”

[![MOVIE1](http://img.youtube.com/vi/zf-04KJPceI/0.jpg)](http://www.youtube.com/watch?v=zf-04KJPceI "特ダネ！ここだけでしか聞けない。安倍晋三襲撃事件の真相深掘り。自民党とマスコミが絶対に隠したい安倍氏の裏に統一教会・アメリカ・CIAの関係。元朝日新聞・記者佐藤章")

QEU:FOUNDER ： “**（我々は、）日々正しいことをするだけでいい**のではないでしょうか。皆が正しいことをすれば、歴史はよくなる。皆が良くないことをすれば、歴史は悪くなるのでしょう。ちなみに、この動画（↑）で述べられた物語って、とてもダイナミックだと思いませんか？”

D先生 : “はい・・・、まるで戦国史のような・・・。”

[![MOVIE1](http://img.youtube.com/vi/jmKXeLweUcw/0.jpg)](http://www.youtube.com/watch?v=jmKXeLweUcw "【カリスマ政治家】ヨシップ・ブロズ・チトー 伝説まとめ")

QEU:FOUNDER ： “また、例えばこのお方（↑）は歴史的評価において「プラスとマイナスの側面はあるが、プラスが凌駕する」といわれています。このような「超のつく大人物が将来的に出てくるか」どうか・・・。”

D先生 : “大人物の輩出は今後は難しいでしょう・・・。情報量が比較にならない大量に流通する現在において、ネガティブな情報の発信は命取りです。これは民主主義のためとも言えますが・・・。”

QEU:FOUNDER ： “先日、惜しくも亡くなった、「あのお方」は大人物を目指したんだと思いますよ。彼の一族の先人がそうだったように・・・。でも、情報共有の時代に変わってしまっていて、昔のように「（中途はともかく）終わりよければすべてよし」にはならなくなったんですよね。そして、ネガティブな情報をもみ消せばもみ消すほど、悪い方向に進んでしまった・・・。”

C部長 : “本来、自分がやりたかったこと（自分の考える正義）も、その結果として多少変質してしまったんじゃないかなぁ・・・。”

![imageRL3-25-4](/2022-07-13-QEUR21_SOARTM5/imageRL3-25-4.jpg)

QEU:FOUNDER ： “だから、我々のイケメンも人物的なスケールは小さくなるが、日々正しいことをするだけでいいのではないでしょうか。あまり大きなことをすると、情報流通量が昔とはケタ違いの現代では逆効果ではないかと・・・。ちなみに、ヨハネ福音書のラザロは小人物ですが、正教会では「聖人」と扱われています。”

![imageRL3-25-5](/2022-07-13-QEUR21_SOARTM5/imageRL3-25-5.jpg)

D先生 : “ラザロはマタイ福音書のような「共観福音書」には出てこない人物です。おそらく、(福音書)作者の創作でしょう。FOUNDERは作者を古代ギリシャ人だとみているんでしょ？ヨハネ福音書によれば、偉大なことをすることが人間の価値ではない。正しいことをすることがより重要なのだと・・・・。”

C部長 : “あれ？D先生が担当していたイケメン（左）がなぜか「NOT　FOUND」なっています。”

QEU:FOUNDER ： “彼は大人物を目指しすぎて、多少無理をし過ぎではないかと・・・。”

D先生 : “真ん中のイケメンのように、**「（国会の）可視化をします」**といっているのは最も賢いやり方ですね。”
