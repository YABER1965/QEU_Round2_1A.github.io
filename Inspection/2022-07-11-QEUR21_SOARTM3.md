---
title: QEUR21_SOARTM3 – SOART法をもう一度試してみる(SOART2-その4)
date: 2022-07-11
tags: ["QEUシステム", "メトリックス", "Python言語", "機械学習", "マハラノビス距離", "DX", "Blender", "SOART法", "異常判別"]
excerpt: Python言語とSOART法を使った異常判別
---

## QEUR21_SOARTM3 – SOART法をもう一度試してみる(SOART2-その4)

## ～　これでSTEP1の特性を把握できた　～

### ・・・　前回の続きです　・・・

D先生： “マルチ法のSTEP2に進む前に、一旦休みとして**画像データをマハラノビス変換**してみませんか？”

![imageRL3-22-1](/2022-07-11-QEUR21_SOARTM3/imageRL3-22-1.jpg)

QEU:FOUNDER ; “確かに、仮説ばかりで突っ走るのもよいないです。開発プロセスの途中に**確認のステップを設ける**必要があります。”

![imageRL3-22-2](/2022-07-11-QEUR21_SOARTM3/imageRL3-22-2.jpg) 

QEU:FOUNDER ; “今回使っているのは、2次元のシンプルなマハラノビス変換です。上図のようにX1方向に伸びた楕円の分布が与えられた場合、これをマハラノビス変換すると円状分布に変換されます。そして、マハラノビス距離は原点からの距離です。つまり、今回の場合には、Y2メトリックスは「明るさ」であるので、明るさを補正した画像が出力されます。”

D先生 : “逆にいうと、マハラノビス変換には楕円分布が理想なのだか現実のY2-Y3空間の分布はかなり**いびつな分散状態**になっています。だから、マハラノビス変換は今回のケースには適切な変換法ではないかもしれません。そういえば、20枚の画像で単位ベクトルと分散共分散行列を再学習したんでしょ？どうなりましたか？”

![imageRL3-22-2](/2022-07-11-QEUR21_SOARTM3/imageRL3-22-2.jpg)

QEU:FOUNDER ： “非常に規則正しい分布にはなりました。しかし分布が非対称で、Blenderの環境を調べてみると左右ライトの配置が少しずれていた・・・。まあ、いいや・・・（笑）。”

D先生 : “Step1の処理でどのような「（変換）画像」が得られるか、とても楽しみですね。”

QEU:FOUNDER ： “それでは解析プログラムをドン！！”

```python
# -------------------- プログラムの始まり -------------------
# -*- coding: utf-8 -*-
# filename: soaRT2_analysis_step1.py
# マハラノビス距離の分析用
# SOART2法用（マルチ法-step1）
# ---------------------------------------------------
# モジュールのインポート
import cv2
from fastai.vision.all import *
import pandas as pd
import numpy as np
import seaborn as sns
from scipy.spatial import distance

#=================================================
# MAIN PROGRAM(1) : 画像名csvファイルを読み込む
#=================================================
# VR画像ファイルを読み込み表示する
def read_vrImgfile(file_readcsv): 
 
    # 畳み込みファイルの読み込み
    df = pd.read_csv(file_readcsv) 
    df = df[df["rtm"]=="tani"]
    num_VRfs = len(df)
    # ------------------
    # file_nameのリストを生成する
    mx_Xs = df.loc[:,"file_name":"label"].values
    arr_VRsignal = df.loc[:,"file_name"].values
    #print("----- mx_Xs -----")
    #print(mx_Xs)
  
    return num_VRfs, mx_Xs, arr_VRsignal

# ---------------------------
# CSVファイル(実験)情報を読み込み表示する
foldername = "./ARRAY_RTCNN/"
file_VRinput = foldername + "labels0_NORMAL.csv"  # ファイルパス名の生成 
num_VRfs, mx_Xs, arr_VRsignal = read_vrImgfile(file_VRinput)
print(arr_VRsignal)

#=================================================
# MAIN PROGRAM(2) : パラメタの準備
#=================================================
# 画像リサイズのパラメタ
newsize = (900, 300)
# テンソルイメージ処理のパラメタ
cmax_tsr_col, cmax_tsr_row   = newsize[0], newsize[1]  #(900, 300)
# ストライド量
stride_tsr_row, stride_tsr_col = 5, 5
# RT法処理のサイズ
crtm_tsr_row, crtm_tsr_col = 5, 5
# STEP1処理後のマトリックスサイズ
max_sp_row, max_sp_col = 60, 180

# ---------------------------
# テンソル行列の処理(for)開始点のベクトルを生成する
row_range, col_range, mx_noPin = [], [], np.zeros([max_sp_row, max_sp_col])
sum_row = 0
while sum_row <= cmax_tsr_row-crtm_tsr_row:
    row_range.append(sum_row)
    sum_row  += stride_tsr_row
# -----
sum_col = 0
while sum_col <= cmax_tsr_col-crtm_tsr_col:
    col_range.append(sum_col)
    sum_col  += stride_tsr_col
# -----
# STEP1処理後のマトリックスの各要素がどのPIN番号に当たるのかを示す
for row in range(max_sp_row):
    for col in range(max_sp_col):
        irow, jcol  = int(row/20), int(col/20)
        mx_noPin[row, col] = irow*9 + jcol
print("--- mx_noPin ---")
print(mx_noPin)

#=================================================
# FUNCTIONS
#=================================================
# 計測画像ファイルを読んで、テンソルを出力する
def read_pictures(pic_signal): 

    # ------------------
    # 単位画像(C)
    filenameC = foldername + "average_pic.png"
    imgC = cv2.imread(filenameC, cv2.IMREAD_GRAYSCALE)
    img_cropC = imgC[212:856,47:1867]
    # リサイズ
    img_resizeC = cv2.resize(img_cropC , newsize)

    # ------------------
    # 信号画像(S)
    filenameS = foldername + pic_signal
    imgS = cv2.imread(filenameS, cv2.IMREAD_GRAYSCALE)
    img_cropS = imgS[212:856,47:1867]
    # リサイズ
    img_resizeS = cv2.resize(img_cropS , newsize)

    # ------------------
    # 単位、信号画像データのテンソル化
    img_tani    = tensor(img_resizeC/255)  # 単位空間（標準ベクトル）
    img_signal  = tensor(img_resizeS/255)  # 信号空間（計測ベクトル）
    
    return img_tani, img_signal

# ---------------------------
# soaRT(Step1)メトリックスを計算する(テンソル活用版)
def calc_soaRT_step1(L1_loss, MSE_loss, tsr_sig_array, tsr_tani_array): 

    y = tsr_sig_array
    x = tsr_tani_array
    tsr_zero = torch.zeros(len(x))


    # 体積ひずみを計測
    vol_xtani = MSE_loss(x, tsr_zero) + 0.0001
    vol_ysig  = MSE_loss(y, tsr_zero) + 0.0001
    ratio_vol = vol_ysig/vol_xtani

    # せん断ひずみを計測
    mDistance   = L1_loss(y, ratio_vol*x)
    #print("mDistance: ", mDistance.item())
    #print("yres:{}".format(yres))

    return ratio_vol.item(), mDistance.item()

# ---------------------------
# 畳み込みSOARTメトリックスを生成する
def create_CRTmetric(L1_loss, MSE_loss, iCnt, tani_image, signal_images):

    # 畳み込みSOARTメトリックスをCSVファイルに出力するための行列（マトリックス）を初期化
    arr_noPin, arr_soaY2, arr_soaY3 = [], [], []
    # ---------------------------
    cnt_row = 0
    for row in row_range:
        cnt_col = 0
        for col in col_range:
            # ------
            # 単位空間の空間ベクトルを生成する
            tsr_tani_array = tani_image[row:row+crtm_tsr_row,col:col+crtm_tsr_col].flatten()
            #print(tsr_tani_array)
            # ------
            # 信号空間の空間マトリックスを生成する
            tsr_sig_array  = signal_images[row:row+crtm_tsr_row,col:col+crtm_tsr_col].flatten()
            #print("----- tsr_sig_array -----")
            #print(tsr_sig_array)
            # ------
            # RTメトリックスを計算する
            val_Y2, val_Y3 = calc_soaRT_step1(L1_loss, MSE_loss, tsr_sig_array, tsr_tani_array)
            # ------
            # リストを生成する  
            # PINNO
            arr_noPin.append(mx_noPin[cnt_row, cnt_col])
            # Y2類
            arr_soaY2.append(round(val_Y2, 5))
            # Y3類
            arr_soaY3.append(round(val_Y3, 5))
            # ------
            # COUNT UP
            #print(cnt_row, cnt_col)
            cnt_col = cnt_col + 1
        # ------
        # COUNT UP
        cnt_row = cnt_row + 1
    # ---------------------------
    # マトリックス化
    temp_file  = np.array([[iCnt]*len(arr_noPin)]).T
    temp_noPin = np.array([arr_noPin]).T
    temp_soaY2 = np.array([arr_soaY2]).T
    temp_soaY3 = np.array([arr_soaY3]).T
    mx_metrics = np.concatenate([temp_file, temp_noPin, temp_soaY2, temp_soaY3], axis=1)
    # 結果のテキスト出力する
    #print("--- mx_metrics ---")
    #print(mx_metrics)

    return mx_metrics


#=================================================
# MAIN PROGRAM(3) : マトリックスの生成
#=================================================
# インスタンス化
L1_loss  = torch.nn.L1Loss()
MSE_loss = torch.nn.MSELoss()

# -----
for iCnt in range(num_VRfs):   # num_VRfs
    # ---------------------------
    # 読み込み先の指定
    pic_signal = arr_VRsignal[iCnt] + ".png"   # 計測画像(計測ベクトル)
    # ---------------------------
    # 計測画像ファイルを読んで、テンソルを出力する
    tani_image, signal_images = read_pictures(pic_signal)
    #print(img_tani)
    # ---------------------------
    # 畳み込みSOARTメトリックスを生成する
    mx_metrics = create_CRTmetric(L1_loss, MSE_loss, iCnt, tani_image, signal_images)
    # 結果のテキスト出力する
    #print("--- mx_metrics ---")
    #print(mx_metrics)
    # マトリックスの累積
    if iCnt == 0:
        acc_metrics = mx_metrics
    else:
        acc_metrics = np.concatenate([acc_metrics, mx_metrics], axis = 0)
# -----
# 結果のテキスト出力する
#print("--- acc_metrics ---")
#print(acc_metrics)

# -----
# 画像番号を選択して、データフレームを作成
number_fileno  = 0      # 画像番号を選択
arr_columns = ["fileno", "pinno", "Y2", "Y3"]
df_metrics  = pd.DataFrame(acc_metrics, columns=arr_columns)
temp_data   = df_metrics[df_metrics["fileno"]==number_fileno]
print("------------ メトリックスのデータフレーム, PINNO:{} -------------".format(number_fileno))  
print(temp_data) 


#=================================================
# READ TANI SPACE CSV_FILE FUNCTION
#=================================================
# ファイルを読み込み表示する(分散共分散逆行列)
def read_invcorr(code_cnv_input): 

    # 相関逆行列ファイルの読み込み
    file_cnv_input = foldername + code_cnv_input + ".csv"  # ファイルパス名の生成 
    df = pd.read_csv(file_cnv_input)
    # 選択項目の読み込み
    # Xsマトリックス
    mx_Xs = df.loc[:,"0":"1"].values
    #print("----- mx_Xs -----")
    #print(mx_Xs)
  
    return mx_Xs

# ------------------
# ファイルを読み込み表示する(単位空間の中心)
def read_taniXs(code_cnv_input): 
 
    # 単位空間の中心ファイルの読み込み
    file_cnv_input = foldername + code_cnv_input + ".csv"  # ファイルパス名の生成
    df = pd.read_csv(file_cnv_input) 
    # 選択項目の読み込み
    # Xsマトリックス
    mx_Xs = df.loc[:,"0":"1"].values
    #print("----- mx_Xs -----")
    #print(mx_Xs)
  
    return mx_Xs.flatten()


#=================================================
# MAIN PROGRAM(5) : マハラノビスデータの読み込み
#=================================================
# SOART(Step1)の項目数（Y2, Y3）
x_array = []
acc_mx_tani = []
acc_mx_covi = []

# PINNO毎にCSVファイルを出力する
for iPin in range(9*3):

    # ------------------
    # ファイルを読み込み表示する(相関逆行列)
    code_invcorr  = "invCor_pin{}".format(iPin)
    cov_iY = read_invcorr(code_invcorr)
    #print(cov_iY)

    # ------------------
    # ファイルを読み込み表示する(単位空間の中心)
    code_taniXs   = "taniXs_pin{}".format(iPin)
    arr_Xs_tani = read_taniXs(code_taniXs)
    #print(arr_Xs_tani)

    # ------------------
    # 累積
    x_array.append(iPin)
    acc_mx_tani.append(arr_Xs_tani)
    acc_mx_covi.append(cov_iY)

# ------------------
# 出力
print("--- acc_mx_covi ---")
print(acc_mx_covi)
print("--- acc_mx_tani ---")
print(acc_mx_tani)


#=================================================
# MAIN PROGRAM(6) : マハラノビス距離を生成する
#=================================================
# データフレームを作成
#number_fileno  = 0
#arr_columns = ["fileno", "pinno", "Y2", "Y3"]
#df_metrics  = pd.DataFrame(acc_metrics, columns=arr_columns)
#temp_data   = df_metrics[df_metrics["fileno"]==number_fileno]
#print("------------ メトリックスのデータフレーム, PINNO:{} -------------".format(number_fileno))  
#print(temp_data) 

# データを抽出する
arr_pins  = temp_data.loc[:,"pinno"].values
mx_data   = temp_data.loc[:,"Y2":"Y3"].values
#print("------------ arr_pins -------------")  
#print(arr_pins) 
#print("------------ mx_data -------------")  
#print(mx_data) 

# -----
# 配列の初期化
arr_mahadis = []

# -----
for iCnt in range(len(arr_pins)):

    slice_data  = temp_data.loc[iCnt,"Y2":"Y3"].values
    val_pins    = arr_pins[iCnt]
    arr_Xs_tani = acc_mx_tani[int(val_pins)]
    cov_iY      = acc_mx_covi[int(val_pins)]
    dY = distance.mahalanobis(slice_data, arr_Xs_tani, cov_iY)
    arr_mahadis.append(int(dY*10))

# データを抽出する
mx_mahadis  = np.array(arr_mahadis).reshape([max_sp_row, max_sp_col])
print("------------ mx_mahadis -------------")  
print(mx_mahadis) 

#=================================================
# MAIN PROGRAM(7) : 解析結果を出力する
#=================================================
# 場所A
max_mahadis = np.amax(mx_mahadis[:20,:20])
out_mahadis = max_mahadis - mx_mahadis
df = pd.DataFrame(out_mahadis[:20,:40])
df.style.set_properties(**{'font-size':'6pt'}).background_gradient('Greys')

# 場所B
max_mahadis = np.amax(mx_mahadis[20:40,:20])
out_mahadis = max_mahadis - mx_mahadis
df = pd.DataFrame(out_mahadis[20:40,:40])
df.style.set_properties(**{'font-size':'6pt'}).background_gradient('Greys')

# 場所C
max_mahadis = np.amax(mx_mahadis[20:40,20:40])
out_mahadis = max_mahadis - mx_mahadis
df = pd.DataFrame(out_mahadis[20:40,20:60])
df.style.set_properties(**{'font-size':'6pt'}).background_gradient('Greys')

```

QEU:FOUNDER ： “小生も解析に取り組んだ当初には、こんな画像（↓）が得られました。”

![imageRL3-22-4](/2022-07-11-QEUR21_SOARTM3/imageRL3-22-4.jpg)

D先生： “あれ？**「ネガ画像」**になっていますね。まずい・・・、ポジに変換しなきゃ・・・。”

QEU:FOUNDER ： “・・・ということで、補正を行ったあとの画像です。ピンの場所を変えて解析しています。”

**（ピン場所A）**

![imageRL3-22-5](/2022-07-11-QEUR21_SOARTM3/imageRL3-22-5.jpg)

D先生： “この画像（↑）は「ポジ画像」にはなっています。でも、**ピンによって値がずれてしまいます。**”

QEU:FOUNDER ： “この値は適用している単位空間の影響です。つまり、補正もピン単位で行わなければならないことを示しています。・・・ついでに、他のピンの様子を見てみましょう。”

**（ピン場所B）**

![imageRL3-22-6](/2022-07-11-QEUR21_SOARTM3/imageRL3-22-6.jpg)

**（ピン場所C）**

![imageRL3-22-7](/2022-07-11-QEUR21_SOARTM3/imageRL3-22-7.jpg)

D先生 ：“なるほどね・・・。STEP1の処理を通して、**「明るさ補正」**が可能となりました。この情報をSOART2法のSTEP2に引き渡して**図形認識をする**わけですね。”

QEU:FOUNDER ： “すなわち、SOART2法では外観検査自動機のフローは以下のようになります。”

![imageRL3-22-8](/2022-07-11-QEUR21_SOARTM3/imageRL3-22-8.jpg)

D先生 : “いやぁ、複雑なプロセスですね・・・。”

QEU:FOUNDER ： “でも、よく考えてみれば、**ディープラーニングのレイア（層）というのは、このフローの処理を学習によって「自動でやってくれている」**ということなんですよ。”

![imageRL3-22-9](/2022-07-11-QEUR21_SOARTM3/imageRL3-22-9.jpg)

D先生： “しかし、ディープラーニングを複雑にすると、学習するためのデータ量が極端に増えるので良しあしですよね。”

## ～　まとめ　～

D先生 : “最近は、ここでも言うことがなくなっていますが・・・。”

QEU:FOUNDER ： “まあ、特別なことがなければ、何も言わんでいいんじゃない？”

C部長 : “それは結構、「なげやり」じゃない？”

[![MOVIE1](http://img.youtube.com/vi/yNqNojoreFg/0.jpg)](http://www.youtube.com/watch?v=yNqNojoreFg "安倍元首相の訃報に思い起こされた仏説を語る")

QEU:FOUNDER ： “・・・というか、**「歴史の大きな流れの中でどうしようもないこともあるのだ」**と思うようになりました。”
