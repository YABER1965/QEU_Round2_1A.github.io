---
title: QEUR21_SOART5:　本実験～SOARTメトリックスを使ってみる (その3) 
date: 2022-06-20
tags: ["QEUシステム", "メトリックス", "Python言語", "機械学習", "マハラノビス距離", "DX", "Blender", "SOART法", "異常判別"]
excerpt: Python言語とSOART法を使った異常判別
---

## QEUR21_SOART5:　本実験～SOARTメトリックスを使ってみる (その3) 

## ～　マハラノビス距離で学習(Learning)をする　～

D先生 ： “それでは次のステップにつづきます。**「Feature-Engineering」**って書いているけど、要するに「学習」ですね。今回の場合は正常品(NORMAL)をインプットしてマハラノビス距離をとります。”

**（処理フロー）**

![imageRL2-7-1](/2022-06-20-QEUR21_SOART5/imageRL2-7-1.jpg)

**（インプットデータの分類）**

![imageRL2-7-2](/2022-06-20-QEUR21_SOART5/imageRL2-7-2.jpg)

QEU:FOUNDER ： “今回はSOART法になって、Y3というメトリックスが追加になったのでプログラムが一層複雑になりました。これはしょうがないね・・・。”

```python
# -------------------- プログラムの始まり -------------------
# -*- coding: utf-8 -*-
# filename: soaRT_maharanobis_learning.py
# 複数画像を読み込み、マハラノビス距離を出力するための分散共分散行列を生成する 
# SOART法用（新新RT法）
# ファイブアイズ、単位空間を3種類に分ける
# ---------------------------------------------------
# モジュールのインポート
import cv2
from fastai.vision.all import *
import pandas as pd
import numpy as np

# -----
foldername = "./ARRAY_RTCNN/"
#=================================================
# READ CSV_FILE FUNCTION
#=================================================
# 畳み込みファイルを読み込み表示する
def read_csvfile(file_readcsv): 
 
    # 畳み込みファイルの読み込み
    df = pd.read_csv(file_readcsv) 
    # ------------------
    # 選択項目の読み込み
    # Xsマトリックス
    mx_Xs = df.loc[:,"col1":"col5"].values
    #print("----- mx_Xs -----")
    #print(mx_Xs)
  
    return mx_Xs

# ---------------------------
# LCR画像ファイルを読んで、テンソルを出力する
def read_LCRpics(pic_nameL, pic_nameC, pic_nameR, pic_nameU, pic_nameD): 

    # ------------------
    # 左(L)画像
    filename = foldername + pic_nameL
    imgL = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)
    img_cropL = imgL[212:856,47:1867]
    # リサイズ
    img_resizeL = cv2.resize(img_cropL , newsize)

    # ------------------
    # 中央(C)画像
    #filename = foldername + pic_nameC
    filename = foldername + "average_pic.png"
    imgC = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)
    img_cropC = imgC[212:856,47:1867]
    # リサイズ
    img_resizeC = cv2.resize(img_cropC , newsize)

    # ------------------
    # 右(R)画像
    filename = foldername + pic_nameR
    imgR = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)
    img_cropR = imgR[212:856,47:1867]
    # リサイズ
    img_resizeR = cv2.resize(img_cropR , newsize)
    # 画像出力
    #cv2.imshow("image(Right)", img_resizeR)
    #cv2.waitKey(0)
    #cv2.destroyAllWindows()

    # ------------------
    # 上(U)画像
    filename = foldername + pic_nameU
    imgU = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)
    img_cropU = imgU[212:856,47:1867]
    # リサイズ
    img_resizeU = cv2.resize(img_cropU , newsize)

    # ------------------
    # 下(D)画像
    filename = foldername + pic_nameD
    imgD = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)
    img_cropD = imgD[212:856,47:1867]
    # リサイズ
    img_resizeD = cv2.resize(img_cropD , newsize)

    # ------------------
    # 画像データのテンソル化(L,C,R)
    img_tensorL = tensor(img_resizeL/255)  # 信号空間(左)
    img_tensorC = tensor(img_resizeC/255)  # 単位空間（標準ベクトル）
    img_tensorR = tensor(img_resizeR/255)  # 信号空間(右)
    img_tensorU = tensor(img_resizeU/255)  # 信号空間(上)
    img_tensorD = tensor(img_resizeD/255)  # 単位空間（下）
    
    return img_tensorL, img_tensorC, img_tensorR, img_tensorU, img_tensorD

# ---------------------------
# 両目法RTメトリックスを計算する(テンソル活用版)
def calc_deyeRTmet(len_temp, max_jy_index, tsr_sig_matrix, tsr_tani_array): 

    # ---------------------------
    # 変数の初期化
    L1_loss = torch.nn.L1Loss()
    btY1_yarray, Y2_yarray = [], []

    # 繰り返し
    for i in range(len_temp):

        y = tsr_sig_matrix[i]
        x = tsr_tani_array

        xx = torch.dot(x,x)
        xy = torch.dot(x,y)
        beta = xy/xx
        #print("i:{}, beta:{}".format(i,beta))

        mDistance   = L1_loss(y, beta*x)
        #print("mDistance: ", mDistance.item())
        #print("yres:{}".format(yres))
        
        btY1_yarray.append(beta.item())
        Y2_yarray.append(mDistance.item())

    return round(Y2_yarray[0] - Y2_yarray[1], 5)

# ---------------------------
# 畳み込み処理を実施する
def apply_kernel(row, col, kernel, img_tensor):
    return (img_tensor[row:row+max_cnv_row,col:col+max_cnv_col] * kernel).sum()

# ---------------------------
# soaRTメトリックスを計算する(テンソル活用版)
def calc_soaRT(len_temp, max_jy_index, tsr_sig_matrix, tsr_tani_array): 

    # ---------------------------
    # 変数の初期化
    L1_loss = torch.nn.L1Loss()
    tsr_zero = torch.zeros(max_jy_index)
    btY1_yarray, Y2_yarray, Y3_yarray = [], [], []

    # 繰り返し
    for i in range(len_temp):

        y = tsr_sig_matrix[i]
        x = tsr_tani_array

        # 回転を計測
        xx = torch.dot(x,x)
        xy = torch.dot(x,y)
        beta = xy/xx
        #print("i:{}, beta:{}".format(i,beta))

        # 体積ひずみを計測
        vol_xtani = L1_loss(beta*x, tsr_zero)
        vol_ysig  = L1_loss(y, tsr_zero)
        ratio_vol = vol_ysig/vol_xtani

        # せん断ひずみを計測
        mDistance   = L1_loss(y, beta*ratio_vol*x)
        #print("mDistance: ", mDistance.item())
        #print("yres:{}".format(yres))
        
        btY1_yarray.append(beta.item())
        Y2_yarray.append(ratio_vol.item())
        Y3_yarray.append(mDistance.item())

    return btY1_yarray, Y2_yarray, Y3_yarray

#=================================================
# SUB PROGRAM(1) : ファイブアイズRTメトリックスの準備
#=================================================
# 1.ファイブアイズRTメトリックス
# 画像リサイズのパラメタ
newsize = (900, 300)
# テンソルイメージ処理のパラメタ
dmax_tsr_col, dmax_tsr_row   = newsize[0], newsize[1]  #(900, 300)
# ストライド量
stride_tsr_row, stride_tsr_col = 5, 5
# RT法処理のサイズ
drtm_tsr_row, drtm_tsr_col = 5, 5
# RTベクトル長と信号空間長
dmax_jy_idx  = 5*5
len_dmx      = 2  # 右と左

# ---------------------------
# 1.ファイブアイズRTメトリックス: テンソル行列の処理(for)開始点のベクトルを生成
row_range1, col_range1 = [], []
sum_row = 0
while sum_row <= dmax_tsr_row-drtm_tsr_row:
    row_range1.append(sum_row)
    sum_row  += stride_tsr_row
# -----
sum_col = 0
while sum_col <= dmax_tsr_col-drtm_tsr_col:
    col_range1.append(sum_col)
    sum_col  += stride_tsr_col

#=================================================
# SUB PROGRAM(2) : 畳み込みメトリックスの準備
#=================================================
# 2.畳み込み：画像の処理(for)開始点のベクトルを生成する
# パラメタの設定
max_cnv_parts  = 8
# 画像サンプルのサイズ
max_sp_row, max_sp_col = 60, 180
# 畳み込み部品のサイズ
max_cnv_row, max_cnv_col = 5, 5
# ストライド量
stride_cnv_row, stride_cnv_col = 5, 5
# ---------------------------
# 2.畳み込み：画像の処理(for)開始点のベクトルを生成する
row_range2, col_range2 = [], []
sum_row = 0
while sum_row <= max_sp_row-max_cnv_row:
    row_range2.append(sum_row)
    sum_row  += stride_cnv_row
# -----
sum_col = 0
while sum_col <= max_sp_col-max_cnv_col:
    col_range2.append(sum_col)
    sum_col  += stride_cnv_col
# ------------------
nam_cnv_input = "基準用CSVデータ" 
code_cnv_input = ["NA"] * 8 # CSVコードの指定
code_cnv_input[0] = "bend1_cnv" # CSVコードの指定
code_cnv_input[1] = "bend2_cnv" # CSVコードの指定
code_cnv_input[2] = "bend3_cnv" # CSVコードの指定
code_cnv_input[3] = "bend4_cnv" # CSVコードの指定
code_cnv_input[4] = "line1_cnv" # CSVコードの指定
code_cnv_input[5] = "line2_cnv" # CSVコードの指定
code_cnv_input[6] = "datum1_cnv" # CSVコードの指定
code_cnv_input[7] = "datum2_cnv" # CSVコードの指定
# ------------------
# 畳み込み処理を実施する
for i in range(max_cnv_parts):
    # ---------------------------
    # CSVファイル(実験)情報を読み込み表示する
    # 畳み込みファイル
    file_cnv_input = foldername + code_cnv_input[i] + ".csv"  # ファイルパス名の生成 
    mx_conv = read_csvfile(file_cnv_input)
    if i == 0:    
        tensor_bend1 = tensor(mx_conv).float()
    elif i == 1:
        tensor_bend2 = tensor(mx_conv).float()
    elif i == 2:
        tensor_bend3 = tensor(mx_conv).float()
    elif i == 3:
        tensor_bend4 = tensor(mx_conv).float()
    elif i == 4:
        tensor_line1 = tensor(mx_conv).float()
    elif i == 5:
        tensor_line2 = tensor(mx_conv).float()
    elif i == 6:
        tensor_datum1 = tensor(mx_conv).float()
    elif i == 7:
        tensor_datum2 = tensor(mx_conv).float()
# ---------------------------
# 畳み込みカーネルを生成する
signal_kernels  = torch.stack([tensor_bend1, tensor_bend2, tensor_bend3, tensor_bend4, tensor_line1, tensor_line2])
tani_kernel     = tensor_datum1 + tensor_datum2

#=================================================
# SUB PROGRAM(3) : 畳み込みRTメトリックスの準備
#=================================================
# 3. 畳み込みRTメトリックス
# テンソルイメージ処理のパラメタ
cmax_tsr_row, cmax_tsr_col = 12, 36
# ストライド量
stride_tsr_row, stride_tsr_col = 4, 4
# RT法処理のサイズ
crtm_tsr_row, crtm_tsr_col = 4, 4
# RTベクトル長と信号空間長
cmax_jy_idx, len_cmx  = 4*4, 6
# ---------------------------
# テンソル行列の処理(for)開始点のベクトルを生成する
row_range3, col_range3 = [], []
sum_row = 0
while sum_row <= cmax_tsr_row-crtm_tsr_row:
    row_range3.append(sum_row)
    sum_row  += stride_tsr_row
#print(row_range3)
# -----
sum_col = 0
while sum_col <= cmax_tsr_col-crtm_tsr_col:
    col_range3.append(sum_col)
    sum_col  += stride_tsr_col
#print(col_range3)

#=================================================
# FUNCTION(1) : ファイブアイズでモジュール化した部分
#=================================================
# ファイブアイズRTテンソルを生成する
def create_feyeRT(img_tensorL, img_tensorC, img_tensorR):

    # ファイブアイズRT法によるマトリックスの生成
    num_rows, num_cols = len(row_range1), len(col_range1)
    feyeY2 = []
    # ------
    cnt_row = 0
    for row in row_range1:
        cnt_col = 0
        for col in col_range1:
            # ------
            # 単位空間の空間ベクトルを生成する
            tsr_tani_array = img_tensorC[row:row+drtm_tsr_row,col:col+drtm_tsr_col].flatten()
            #print(tsr_tani_array)
            # ------
            # 信号空間の空間マトリックスを生成する
            tsr_sigL = img_tensorL[row:row+drtm_tsr_row,col:col+drtm_tsr_col].flatten()
            tsr_sigR = img_tensorR[row:row+drtm_tsr_row,col:col+drtm_tsr_col].flatten()
            # -----
            tsr_sig_matrix = torch.stack([tsr_sigL, tsr_sigR])
            #print("----- tsr_sig_matrix -----")
            #print(tsr_sig_matrix)
            # ------
            # ファイブアイズ法RTメトリックスを計算する
            temp_feyeY2 = calc_deyeRTmet(len_dmx, dmax_jy_idx, tsr_sig_matrix, tsr_tani_array)
            feyeY2.append(temp_feyeY2)
            # ------
            # COUNT UP
            cnt_col = cnt_col + 1
        # ------
        # COUNT UP.append
        cnt_row = cnt_row + 1

    # ---------------------------
    # 結果をテキスト出力する
    mx_fY2       = np.array(feyeY2).reshape([num_rows, num_cols])
    tensor_fY2   = tensor(mx_fY2)
    #print(tensor_fY2)

    return tensor_fY2

# 畳み込みテンソルイメージを生成する
def create_feyeConv(tensor_Y1Y2):

    # 単位空間用の畳み込み処理を実施する
    tani_image = tensor([[apply_kernel(i,j, tani_kernel, tensor_Y1Y2) for j in col_range2] for i in row_range2])
    #print("----- tani_image -----")
    #print(tani_image)
    # ------------------
    # 信号空間用の畳み込み処理を実施する
    for i in range(max_cnv_parts-2):
        # ---------------------------
        # CSVファイル(実験)情報を読み込み表示する
        kernel = signal_kernels[i]
        calc_conv = tensor([[apply_kernel(i,j, kernel, tensor_Y1Y2) for j in col_range2] for i in row_range2])
        # -----
        if i == 0:    
            tsr_cvbend1 = tensor(calc_conv).float()
        elif i == 1:
            tsr_cvbend2 = tensor(calc_conv).float()
        elif i == 2:
            tsr_cvbend3 = tensor(calc_conv).float()
        elif i == 3:
            tsr_cvbend4 = tensor(calc_conv).float()
        elif i == 4:
            tsr_cvline1 = tensor(calc_conv).float()
        elif i == 5:
            tsr_cvline2 = tensor(calc_conv).float()
    # ---------------------------
    # 畳み込みテンソルイメージの生成  
    signal_images = torch.stack([tsr_cvbend1, tsr_cvbend2, tsr_cvbend3, tsr_cvbend4, tsr_cvline1, tsr_cvline2])
    # 結果の出力
    #print(signal_images.shape)     # torch.Size([6, 12, 36])
    #print("----- signal_images[0] -----")
    #print(signal_images[0])

    return tani_image, signal_images

# 畳み込みSOARTメトリックスを生成する
def create_CRTmetric(tani_image, signal_images):

    # 畳み込みSOARTメトリックスをCSVファイルに出力するための行列（マトリックス）を初期化
    mx_p0Y1, mx_p1Y1, mx_p2Y1 = np.zeros([3,9]), np.zeros([3,9]), np.zeros([3,9])
    mx_p3Y1, mx_p4Y1, mx_p5Y1 = np.zeros([3,9]), np.zeros([3,9]), np.zeros([3,9])
    # ----
    mx_p0Y2, mx_p1Y2, mx_p2Y2 = np.zeros([3,9]), np.zeros([3,9]), np.zeros([3,9])
    mx_p3Y2, mx_p4Y2, mx_p5Y2 = np.zeros([3,9]), np.zeros([3,9]), np.zeros([3,9])
    # ----
    mx_p0Y3, mx_p1Y3, mx_p2Y3 = np.zeros([3,9]), np.zeros([3,9]), np.zeros([3,9])
    mx_p3Y3, mx_p4Y3, mx_p5Y3 = np.zeros([3,9]), np.zeros([3,9]), np.zeros([3,9])
    # ---------------------------
    cnt_row = 0
    for row in row_range3:
        cnt_col = 0
        for col in col_range3:
            # ------
            # 単位空間の空間ベクトルを生成する
            tsr_tani_array = tani_image[row:row+crtm_tsr_row,col:col+crtm_tsr_col].flatten()
            #print(tsr_tani_array)
            # ------
            # 信号空間の空間マトリックスを生成する
            temp_matrix = signal_images[0]
            tsr_sig_p0 = temp_matrix[row:row+crtm_tsr_row,col:col+crtm_tsr_col].flatten()
            temp_matrix = signal_images[1]
            tsr_sig_p1 = temp_matrix[row:row+crtm_tsr_row,col:col+crtm_tsr_col].flatten()
            temp_matrix = signal_images[2]
            tsr_sig_p2 = temp_matrix[row:row+crtm_tsr_row,col:col+crtm_tsr_col].flatten()
            temp_matrix = signal_images[3]
            tsr_sig_p3 = temp_matrix[row:row+crtm_tsr_row,col:col+crtm_tsr_col].flatten()
            temp_matrix = signal_images[4]
            tsr_sig_p4 = temp_matrix[row:row+crtm_tsr_row,col:col+crtm_tsr_col].flatten()
            temp_matrix = signal_images[5]
            tsr_sig_p5 = temp_matrix[row:row+crtm_tsr_row,col:col+crtm_tsr_col].flatten()
            # -----
            tsr_sig_matrix = torch.stack([tsr_sig_p0, tsr_sig_p1, tsr_sig_p2, tsr_sig_p3, tsr_sig_p4, tsr_sig_p5])
            #print("----- tsr_sig_matrix -----")
            #print(tsr_sig_matrix)
            # ------
            # RTメトリックスを計算する
            btY1_yarray, Y2_yarray, Y3_yarray = calc_soaRT(len_cmx, cmax_jy_idx, tsr_sig_matrix, tsr_tani_array)
            # ------
            # CSV出力用のマトリックスを生成する  
            # Y1類
            mx_p0Y1[cnt_row, cnt_col] = round(btY1_yarray[0],3)
            mx_p1Y1[cnt_row, cnt_col] = round(btY1_yarray[1],3)
            mx_p2Y1[cnt_row, cnt_col] = round(btY1_yarray[2],3)
            mx_p3Y1[cnt_row, cnt_col] = round(btY1_yarray[3],3)
            mx_p4Y1[cnt_row, cnt_col] = round(btY1_yarray[4],3)
            mx_p5Y1[cnt_row, cnt_col] = round(btY1_yarray[5],3)
            # -----
            # Y2類
            mx_p0Y2[cnt_row, cnt_col] = round(Y2_yarray[0],3)
            mx_p1Y2[cnt_row, cnt_col] = round(Y2_yarray[1],3)
            mx_p2Y2[cnt_row, cnt_col] = round(Y2_yarray[2],3)
            mx_p3Y2[cnt_row, cnt_col] = round(Y2_yarray[3],3)
            mx_p4Y2[cnt_row, cnt_col] = round(Y2_yarray[4],3)
            mx_p5Y2[cnt_row, cnt_col] = round(Y2_yarray[5],3)
            # -----
            # Y3類
            mx_p0Y3[cnt_row, cnt_col] = round(Y3_yarray[0],3)
            mx_p1Y3[cnt_row, cnt_col] = round(Y3_yarray[1],3)
            mx_p2Y3[cnt_row, cnt_col] = round(Y3_yarray[2],3)
            mx_p3Y3[cnt_row, cnt_col] = round(Y3_yarray[3],3)
            mx_p4Y3[cnt_row, cnt_col] = round(Y3_yarray[4],3)
            mx_p5Y3[cnt_row, cnt_col] = round(Y3_yarray[5],3)
            # ------
            # COUNT UP
            #print(cnt_row, cnt_col)
            cnt_col = cnt_col + 1
        # ------
        # COUNT UP
        cnt_row = cnt_row + 1
    # ---------------------------
    # 行列（マトリックス）を生成する
    mx_Y1A   = [mx_p0Y1[:,0:2], mx_p1Y1[:,0:2], mx_p2Y1[:,0:2], mx_p3Y1[:,0:2], mx_p4Y1[:,0:2], mx_p5Y1[:,0:2]]
    mx_Y1B   = [mx_p0Y1[:,2:7], mx_p1Y1[:,2:7], mx_p2Y1[:,2:7], mx_p3Y1[:,2:7], mx_p4Y1[:,2:7], mx_p5Y1[:,2:7]]
    mx_Y1C   = [mx_p0Y1[:,7:9], mx_p1Y1[:,7:9], mx_p2Y1[:,7:9], mx_p3Y1[:,7:9], mx_p4Y1[:,7:9], mx_p5Y1[:,7:9]]
    # ------
    mx_Y2A   = [mx_p0Y2[:,0:2], mx_p1Y2[:,0:2], mx_p2Y2[:,0:2], mx_p3Y2[:,0:2], mx_p4Y2[:,0:2], mx_p5Y2[:,0:2]]
    mx_Y2B   = [mx_p0Y2[:,2:7], mx_p1Y2[:,2:7], mx_p2Y2[:,2:7], mx_p3Y2[:,2:7], mx_p4Y2[:,2:7], mx_p5Y2[:,2:7]]
    mx_Y2C   = [mx_p0Y2[:,7:9], mx_p1Y2[:,7:9], mx_p2Y2[:,7:9], mx_p3Y2[:,7:9], mx_p4Y2[:,7:9], mx_p5Y2[:,7:9]]
    # ------
    mx_Y3A   = [mx_p0Y3[:,0:2], mx_p1Y3[:,0:2], mx_p2Y3[:,0:2], mx_p3Y3[:,0:2], mx_p4Y3[:,0:2], mx_p5Y3[:,0:2]]
    mx_Y3B   = [mx_p0Y3[:,2:7], mx_p1Y3[:,2:7], mx_p2Y3[:,2:7], mx_p3Y3[:,2:7], mx_p4Y3[:,2:7], mx_p5Y3[:,2:7]]
    mx_Y3C   = [mx_p0Y3[:,7:9], mx_p1Y3[:,7:9], mx_p2Y3[:,7:9], mx_p3Y3[:,7:9], mx_p4Y3[:,7:9], mx_p5Y3[:,7:9]]
    # ---------------------------
    # CHAIN化： Y1群,Y2群とY3群に振り分ける
    acc_mxY1 = [mx_Y1A, mx_Y1B, mx_Y1C]
    acc_mxY2 = [mx_Y2A, mx_Y2B, mx_Y2C]
    acc_mxY3 = [mx_Y3A, mx_Y3B, mx_Y3C]
    # 結果のテキスト出力する
    #print(mx_Y2A)

    return acc_mxY1, acc_mxY2, acc_mxY3


#=================================================
# FUNCTION(2) : ファイブアイズ畳み込みRTメトリックスを連続して実行する
#=================================================
def bind_process(img_tensorL, img_tensorC, img_tensorR, img_tensorU, img_tensorD):

    #=================================================
    # MAIN PROGRAM(1) : ファイブアイズRTメトリックスを実行する
    #=================================================
    # ファイブアイズRTテンソルを生成する
    tensor_LCRY2   = create_feyeRT(img_tensorL, img_tensorC, img_tensorR)
    tensor_UCDY2   = create_feyeRT(img_tensorU, img_tensorC, img_tensorD)

    #=================================================
    # MAIN PROGRAM(2) : 畳み込みメトリックスを実行する
    #=================================================
    # 畳み込みテンソルイメージを生成する
    tani_LCRimage, signal_LCRimages = create_feyeConv(tensor_LCRY2)
    tani_UCDimage, signal_UCDimages = create_feyeConv(tensor_UCDY2)

    #=================================================
    # MAIN PROGRAM(3) : 畳み込みRTメトリックスを実行する
    #=================================================
    # 畳み込みRTメトリックスを生成する
    acc_mxY1_LCR, acc_mxY2_LCR, acc_mxY3_LCR = create_CRTmetric(tani_LCRimage, sig-nal_LCRimages)
    acc_mxY1_UCD, acc_mxY2_UCD, acc_mxY3_UCD = create_CRTmetric(tani_UCDimage, sig-nal_UCDimages)

    return acc_mxY1_LCR, acc_mxY2_LCR, acc_mxY3_LCR, acc_mxY1_UCD, acc_mxY2_UCD, acc_mxY3_UCD


#=================================================
# MAIN PROGRAM(10) : csvファイルを読み込む
#=================================================
# VR画像ファイルを読み込み表示する
def read_vrImgfile(file_readcsv): 
 
    # 畳み込みファイルの読み込み
    df = pd.read_csv(file_readcsv) 
    df = df[df["rtm"]=="signal"]
    dfL = df.query("camNO == 0")
    dfC = df.query("camNO == 1")
    dfR = df.query("camNO == 2")
    dfU = df.query("camNO == 3")
    dfD = df.query("camNO == 4")
    # ------------------
    # file_nameのリストを生成する
    mx_Xs = df.loc[:,"file_name":"label"].values
    arr_VRfL = dfL.loc[:,"file_name"].values
    arr_VRfC = dfC.loc[:,"file_name"].values
    arr_VRfR = dfR.loc[:,"file_name"].values
    arr_VRfU = dfU.loc[:,"file_name"].values
    arr_VRfD = dfD.loc[:,"file_name"].values
    #print("----- mx_Xs -----")
    #print(mx_Xs)
  
    return mx_Xs, arr_VRfL, arr_VRfC, arr_VRfR, arr_VRfU, arr_VRfD

# ---------------------------
# CSVファイル(実験)情報を読み込み表示する
# カメラは3種類(左 - 中央 - 右)
#foldername = "./ARRAY_RTCNN/"
file_VRinput = foldername + "labels0_NORMAL.csv"  # ファイルパス名の生成 
mx_Xs, arr_VRfL, arr_VRfC, arr_VRfR, arr_VRfU, arr_VRfD = read_vrImgfile(file_VRinput)
num_VRfs = len(arr_VRfC)

# ---------------------------
# リストを生成する
# Y1類の場合
acc_p0Y1A, acc_p1Y1A, acc_p2Y1A, acc_p3Y1A, acc_p4Y1A, acc_p5Y1A    = np.array([]), np.array([]), np.array([]), np.array([]), np.array([]), np.array([])
acc_p6Y1A, acc_p7Y1A, acc_p8Y1A, acc_p9Y1A, acc_p10Y1A, acc_p11Y1A  = np.array([]), np.array([]), np.array([]), np.array([]), np.array([]), np.array([])
acc_p0Y1B, acc_p1Y1B, acc_p2Y1B, acc_p3Y1B, acc_p4Y1B, acc_p5Y1B    = np.array([]), np.array([]), np.array([]), np.array([]), np.array([]), np.array([])
acc_p6Y1B, acc_p7Y1B, acc_p8Y1B, acc_p9Y1B, acc_p10Y1B, acc_p11Y1B  = np.array([]), np.array([]), np.array([]), np.array([]), np.array([]), np.array([])
acc_p0Y1C, acc_p1Y1C, acc_p2Y1C, acc_p3Y1C, acc_p4Y1C, acc_p5Y1C    = np.array([]), np.array([]), np.array([]), np.array([]), np.array([]), np.array([])
acc_p6Y1C, acc_p7Y1C, acc_p8Y1C, acc_p9Y1C, acc_p10Y1C, acc_p11Y1C  = np.array([]), np.array([]), np.array([]), np.array([]), np.array([]), np.array([])
# -----
# Y2類の場合
acc_p0Y2A, acc_p1Y2A, acc_p2Y2A, acc_p3Y2A, acc_p4Y2A, acc_p5Y2A    = np.array([]), np.array([]), np.array([]), np.array([]), np.array([]), np.array([])
acc_p6Y2A, acc_p7Y2A, acc_p8Y2A, acc_p9Y2A, acc_p10Y2A, acc_p11Y2A  = np.array([]), np.array([]), np.array([]), np.array([]), np.array([]), np.array([])
acc_p0Y2B, acc_p1Y2B, acc_p2Y2B, acc_p3Y2B, acc_p4Y2B, acc_p5Y2B    = np.array([]), np.array([]), np.array([]), np.array([]), np.array([]), np.array([])
acc_p6Y2B, acc_p7Y2B, acc_p8Y2B, acc_p9Y2B, acc_p10Y2B, acc_p11Y2B  = np.array([]), np.array([]), np.array([]), np.array([]), np.array([]), np.array([])
acc_p0Y2C, acc_p1Y2C, acc_p2Y2C, acc_p3Y2C, acc_p4Y2C, acc_p5Y2C    = np.array([]), np.array([]), np.array([]), np.array([]), np.array([]), np.array([])
acc_p6Y2C, acc_p7Y2C, acc_p8Y2C, acc_p9Y2C, acc_p10Y2C, acc_p11Y2C  = np.array([]), np.array([]), np.array([]), np.array([]), np.array([]), np.array([])
# -----
# Y3類の場合
acc_p0Y3A, acc_p1Y3A, acc_p2Y3A, acc_p3Y3A, acc_p4Y3A, acc_p5Y3A    = np.array([]), np.array([]), np.array([]), np.array([]), np.array([]), np.array([])
acc_p6Y3A, acc_p7Y3A, acc_p8Y3A, acc_p9Y3A, acc_p10Y3A, acc_p11Y3A  = np.array([]), np.array([]), np.array([]), np.array([]), np.array([]), np.array([])
acc_p0Y3B, acc_p1Y3B, acc_p2Y3B, acc_p3Y3B, acc_p4Y3B, acc_p5Y3B    = np.array([]), np.array([]), np.array([]), np.array([]), np.array([]), np.array([])
acc_p6Y3B, acc_p7Y3B, acc_p8Y3B, acc_p9Y3B, acc_p10Y3B, acc_p11Y3B  = np.array([]), np.array([]), np.array([]), np.array([]), np.array([]), np.array([])
acc_p0Y3C, acc_p1Y3C, acc_p2Y3C, acc_p3Y3C, acc_p4Y3C, acc_p5Y3C    = np.array([]), np.array([]), np.array([]), np.array([]), np.array([]), np.array([])
acc_p6Y3C, acc_p7Y3C, acc_p8Y3C, acc_p9Y3C, acc_p10Y3C, acc_p11Y3C  = np.array([]), np.array([]), np.array([]), np.array([]), np.array([]), np.array([])

# -----
for i in range(num_VRfs):   # num_VRfs
    # ---------------------------
    # 読み込み先の指定
    pic_nameL = arr_VRfL[i] + ".png"   # 左カメラ画像(左)
    #pic_nameC = arr_VRfC[i] + ".png"   # 中央カメラ画像(中央)
    pic_nameC = "average_pic.png"   # 中央カメラ画像(中央)
    pic_nameR = arr_VRfR[i] + ".png"   # 右カメラ画像(右)
    pic_nameU = arr_VRfU[i] + ".png"   # 中央カメラ画像(上)
    pic_nameD = arr_VRfD[i] + ".png"   # 右カメラ画像(下)
    # ---------------------------
    # LCR画像ファイルを読んで、テンソルを出力する
    img_tensorL, img_tensorC, img_tensorR, img_tensorU, img_tensorD = read_LCRpics(pic_nameL, pic_nameC, pic_nameR, pic_nameU, pic_nameD)
    #print(img_tensorC)
    # ---------------------------
    # チェーン化された感度とSN比を出力する
    acc_mxY1_LCR, acc_mxY2_LCR, acc_mxY3_LCR, acc_mxY1_UCD, acc_mxY2_UCD, acc_mxY3_UCD = bind_process(img_tensorL, img_tensorC, img_tensorR, img_tensorU, img_tensorD)
    # -----
    mx_Y1_LCRA, mx_Y1_LCRB, mx_Y1_LCRC = acc_mxY1_LCR[0], acc_mxY1_LCR[1], acc_mxY1_LCR[2]
    mx_Y2_LCRA, mx_Y2_LCRB, mx_Y2_LCRC = acc_mxY2_LCR[0], acc_mxY2_LCR[1], acc_mxY2_LCR[2]
    mx_Y3_LCRA, mx_Y3_LCRB, mx_Y3_LCRC = acc_mxY3_LCR[0], acc_mxY3_LCR[1], acc_mxY3_LCR[2]
    mx_Y1_UCDA, mx_Y1_UCDB, mx_Y1_UCDC = acc_mxY1_UCD[0], acc_mxY1_UCD[1], acc_mxY1_UCD[2]
    mx_Y2_UCDA, mx_Y2_UCDB, mx_Y2_UCDC = acc_mxY2_UCD[0], acc_mxY2_UCD[1], acc_mxY2_UCD[2]
    mx_Y3_UCDA, mx_Y3_UCDB, mx_Y3_UCDC = acc_mxY3_UCD[0], acc_mxY3_UCD[1], acc_mxY3_UCD[2]
    # 結果をテキストに出力する
    #print("---- NO:{} ----".format(i))
    #print(mx_btY1_bindA[0])
    #print(mx_Y2_LCRA[0])
    # ---------------------------
    # チェーン化された感度とSN比を分解して再構成する
    # -----
    # Y1類の場合
    acc_p0Y1A = np.hstack([acc_p0Y1A, np.array(mx_Y1_LCRA[0]).flatten()])
    acc_p1Y1A = np.hstack([acc_p1Y1A, np.array(mx_Y1_LCRA[1]).flatten()])
    acc_p2Y1A = np.hstack([acc_p2Y1A, np.array(mx_Y1_LCRA[2]).flatten()])
    acc_p3Y1A = np.hstack([acc_p3Y1A, np.array(mx_Y1_LCRA[3]).flatten()])
    acc_p4Y1A = np.hstack([acc_p4Y1A, np.array(mx_Y1_LCRA[4]).flatten()])
    acc_p5Y1A = np.hstack([acc_p5Y1A, np.array(mx_Y1_LCRA[5]).flatten()])
    acc_p6Y1A = np.hstack([acc_p6Y1A, np.array(mx_Y1_UCDA[0]).flatten()])
    acc_p7Y1A = np.hstack([acc_p7Y1A, np.array(mx_Y1_UCDA[1]).flatten()])
    acc_p8Y1A = np.hstack([acc_p8Y1A, np.array(mx_Y1_UCDA[2]).flatten()])
    acc_p9Y1A = np.hstack([acc_p9Y1A, np.array(mx_Y1_UCDA[3]).flatten()])
    acc_p10Y1A = np.hstack([acc_p10Y1A, np.array(mx_Y1_UCDA[4]).flatten()])
    acc_p11Y1A = np.hstack([acc_p11Y1A, np.array(mx_Y1_UCDA[5]).flatten()])
    # -----
    acc_p0Y1B = np.hstack([acc_p0Y1B, np.array(mx_Y1_LCRB[0]).flatten()])
    acc_p1Y1B = np.hstack([acc_p1Y1B, np.array(mx_Y1_LCRB[1]).flatten()])
    acc_p2Y1B = np.hstack([acc_p2Y1B, np.array(mx_Y1_LCRB[2]).flatten()])
    acc_p3Y1B = np.hstack([acc_p3Y1B, np.array(mx_Y1_LCRB[3]).flatten()])
    acc_p4Y1B = np.hstack([acc_p4Y1B, np.array(mx_Y1_LCRB[4]).flatten()])
    acc_p5Y1B = np.hstack([acc_p5Y1B, np.array(mx_Y1_LCRB[5]).flatten()])
    acc_p6Y1B = np.hstack([acc_p6Y1B, np.array(mx_Y1_UCDB[0]).flatten()])
    acc_p7Y1B = np.hstack([acc_p7Y1B, np.array(mx_Y1_UCDB[1]).flatten()])
    acc_p8Y1B = np.hstack([acc_p8Y1B, np.array(mx_Y1_UCDB[2]).flatten()])
    acc_p9Y1B = np.hstack([acc_p9Y1B, np.array(mx_Y1_UCDB[3]).flatten()])
    acc_p10Y1B = np.hstack([acc_p10Y1B, np.array(mx_Y1_UCDB[4]).flatten()])
    acc_p11Y1B = np.hstack([acc_p11Y1B, np.array(mx_Y1_UCDB[5]).flatten()])
    # -----
    acc_p0Y1C = np.hstack([acc_p0Y1C, np.array(mx_Y1_LCRC[0]).flatten()])
    acc_p1Y1C = np.hstack([acc_p1Y1C, np.array(mx_Y1_LCRC[1]).flatten()])
    acc_p2Y1C = np.hstack([acc_p2Y1C, np.array(mx_Y1_LCRC[2]).flatten()])
    acc_p3Y1C = np.hstack([acc_p3Y1C, np.array(mx_Y1_LCRC[3]).flatten()])
    acc_p4Y1C = np.hstack([acc_p4Y1C, np.array(mx_Y1_LCRC[4]).flatten()])
    acc_p5Y1C = np.hstack([acc_p5Y1C, np.array(mx_Y1_LCRC[5]).flatten()])
    acc_p6Y1C = np.hstack([acc_p6Y1C, np.array(mx_Y1_UCDC[0]).flatten()])
    acc_p7Y1C = np.hstack([acc_p7Y1C, np.array(mx_Y1_UCDC[1]).flatten()])
    acc_p8Y1C = np.hstack([acc_p8Y1C, np.array(mx_Y1_UCDC[2]).flatten()])
    acc_p9Y1C = np.hstack([acc_p9Y1C, np.array(mx_Y1_UCDC[3]).flatten()])
    acc_p10Y1C = np.hstack([acc_p10Y1C, np.array(mx_Y1_UCDC[4]).flatten()])
    acc_p11Y1C = np.hstack([acc_p11Y1C, np.array(mx_Y1_UCDC[5]).flatten()])
    # -----
    # Y2類の場合
    acc_p0Y2A = np.hstack([acc_p0Y2A, np.array(mx_Y2_LCRA[0]).flatten()])
    acc_p1Y2A = np.hstack([acc_p1Y2A, np.array(mx_Y2_LCRA[1]).flatten()])
    acc_p2Y2A = np.hstack([acc_p2Y2A, np.array(mx_Y2_LCRA[2]).flatten()])
    acc_p3Y2A = np.hstack([acc_p3Y2A, np.array(mx_Y2_LCRA[3]).flatten()])
    acc_p4Y2A = np.hstack([acc_p4Y2A, np.array(mx_Y2_LCRA[4]).flatten()])
    acc_p5Y2A = np.hstack([acc_p5Y2A, np.array(mx_Y2_LCRA[5]).flatten()])
    acc_p6Y2A = np.hstack([acc_p6Y2A, np.array(mx_Y2_UCDA[0]).flatten()])
    acc_p7Y2A = np.hstack([acc_p7Y2A, np.array(mx_Y2_UCDA[1]).flatten()])
    acc_p8Y2A = np.hstack([acc_p8Y2A, np.array(mx_Y2_UCDA[2]).flatten()])
    acc_p9Y2A = np.hstack([acc_p9Y2A, np.array(mx_Y2_UCDA[3]).flatten()])
    acc_p10Y2A = np.hstack([acc_p10Y2A, np.array(mx_Y2_UCDA[4]).flatten()])
    acc_p11Y2A = np.hstack([acc_p11Y2A, np.array(mx_Y2_UCDA[5]).flatten()])
    # -----
    acc_p0Y2B = np.hstack([acc_p0Y2B, np.array(mx_Y2_LCRB[0]).flatten()])
    acc_p1Y2B = np.hstack([acc_p1Y2B, np.array(mx_Y2_LCRB[1]).flatten()])
    acc_p2Y2B = np.hstack([acc_p2Y2B, np.array(mx_Y2_LCRB[2]).flatten()])
    acc_p3Y2B = np.hstack([acc_p3Y2B, np.array(mx_Y2_LCRB[3]).flatten()])
    acc_p4Y2B = np.hstack([acc_p4Y2B, np.array(mx_Y2_LCRB[4]).flatten()])
    acc_p5Y2B = np.hstack([acc_p5Y2B, np.array(mx_Y2_LCRB[5]).flatten()])
    acc_p6Y2B = np.hstack([acc_p6Y2B, np.array(mx_Y2_UCDB[0]).flatten()])
    acc_p7Y2B = np.hstack([acc_p7Y2B, np.array(mx_Y2_UCDB[1]).flatten()])
    acc_p8Y2B = np.hstack([acc_p8Y2B, np.array(mx_Y2_UCDB[2]).flatten()])
    acc_p9Y2B = np.hstack([acc_p9Y2B, np.array(mx_Y2_UCDB[3]).flatten()])
    acc_p10Y2B = np.hstack([acc_p10Y2B, np.array(mx_Y2_UCDB[4]).flatten()])
    acc_p11Y2B = np.hstack([acc_p11Y2B, np.array(mx_Y2_UCDB[5]).flatten()])
    # -----
    acc_p0Y2C = np.hstack([acc_p0Y2C, np.array(mx_Y2_LCRC[0]).flatten()])
    acc_p1Y2C = np.hstack([acc_p1Y2C, np.array(mx_Y2_LCRC[1]).flatten()])
    acc_p2Y2C = np.hstack([acc_p2Y2C, np.array(mx_Y2_LCRC[2]).flatten()])
    acc_p3Y2C = np.hstack([acc_p3Y2C, np.array(mx_Y2_LCRC[3]).flatten()])
    acc_p4Y2C = np.hstack([acc_p4Y2C, np.array(mx_Y2_LCRC[4]).flatten()])
    acc_p5Y2C = np.hstack([acc_p5Y2C, np.array(mx_Y2_LCRC[5]).flatten()])
    acc_p6Y2C = np.hstack([acc_p6Y2C, np.array(mx_Y2_UCDC[0]).flatten()])
    acc_p7Y2C = np.hstack([acc_p7Y2C, np.array(mx_Y2_UCDC[1]).flatten()])
    acc_p8Y2C = np.hstack([acc_p8Y2C, np.array(mx_Y2_UCDC[2]).flatten()])
    acc_p9Y2C = np.hstack([acc_p9Y2C, np.array(mx_Y2_UCDC[3]).flatten()])
    acc_p10Y2C = np.hstack([acc_p10Y2C, np.array(mx_Y2_UCDC[4]).flatten()])
    acc_p11Y2C = np.hstack([acc_p11Y2C, np.array(mx_Y2_UCDC[5]).flatten()])
    # -----
    # Y3類の場合
    acc_p0Y3A = np.hstack([acc_p0Y3A, np.array(mx_Y3_LCRA[0]).flatten()])
    acc_p1Y3A = np.hstack([acc_p1Y3A, np.array(mx_Y3_LCRA[1]).flatten()])
    acc_p2Y3A = np.hstack([acc_p2Y3A, np.array(mx_Y3_LCRA[2]).flatten()])
    acc_p3Y3A = np.hstack([acc_p3Y3A, np.array(mx_Y3_LCRA[3]).flatten()])
    acc_p4Y3A = np.hstack([acc_p4Y3A, np.array(mx_Y3_LCRA[4]).flatten()])
    acc_p5Y3A = np.hstack([acc_p5Y3A, np.array(mx_Y3_LCRA[5]).flatten()])
    acc_p6Y3A = np.hstack([acc_p6Y3A, np.array(mx_Y3_UCDA[0]).flatten()])
    acc_p7Y3A = np.hstack([acc_p7Y3A, np.array(mx_Y3_UCDA[1]).flatten()])
    acc_p8Y3A = np.hstack([acc_p8Y3A, np.array(mx_Y3_UCDA[2]).flatten()])
    acc_p9Y3A = np.hstack([acc_p9Y3A, np.array(mx_Y3_UCDA[3]).flatten()])
    acc_p10Y3A = np.hstack([acc_p10Y3A, np.array(mx_Y3_UCDA[4]).flatten()])
    acc_p11Y3A = np.hstack([acc_p11Y3A, np.array(mx_Y3_UCDA[5]).flatten()])
    # -----
    acc_p0Y3B = np.hstack([acc_p0Y3B, np.array(mx_Y3_LCRB[0]).flatten()])
    acc_p1Y3B = np.hstack([acc_p1Y3B, np.array(mx_Y3_LCRB[1]).flatten()])
    acc_p2Y3B = np.hstack([acc_p2Y3B, np.array(mx_Y3_LCRB[2]).flatten()])
    acc_p3Y3B = np.hstack([acc_p3Y3B, np.array(mx_Y3_LCRB[3]).flatten()])
    acc_p4Y3B = np.hstack([acc_p4Y3B, np.array(mx_Y3_LCRB[4]).flatten()])
    acc_p5Y3B = np.hstack([acc_p5Y3B, np.array(mx_Y3_LCRB[5]).flatten()])
    acc_p6Y3B = np.hstack([acc_p6Y3B, np.array(mx_Y3_UCDB[0]).flatten()])
    acc_p7Y3B = np.hstack([acc_p7Y3B, np.array(mx_Y3_UCDB[1]).flatten()])
    acc_p8Y3B = np.hstack([acc_p8Y3B, np.array(mx_Y3_UCDB[2]).flatten()])
    acc_p9Y3B = np.hstack([acc_p9Y3B, np.array(mx_Y3_UCDB[3]).flatten()])
    acc_p10Y3B = np.hstack([acc_p10Y3B, np.array(mx_Y3_UCDB[4]).flatten()])
    acc_p11Y3B = np.hstack([acc_p11Y3B, np.array(mx_Y3_UCDB[5]).flatten()])
    # -----
    acc_p0Y3C = np.hstack([acc_p0Y3C, np.array(mx_Y3_LCRC[0]).flatten()])
    acc_p1Y3C = np.hstack([acc_p1Y3C, np.array(mx_Y3_LCRC[1]).flatten()])
    acc_p2Y3C = np.hstack([acc_p2Y3C, np.array(mx_Y3_LCRC[2]).flatten()])
    acc_p3Y3C = np.hstack([acc_p3Y3C, np.array(mx_Y3_LCRC[3]).flatten()])
    acc_p4Y3C = np.hstack([acc_p4Y3C, np.array(mx_Y3_LCRC[4]).flatten()])
    acc_p5Y3C = np.hstack([acc_p5Y3C, np.array(mx_Y3_LCRC[5]).flatten()])
    acc_p6Y3C = np.hstack([acc_p6Y3C, np.array(mx_Y3_UCDC[0]).flatten()])
    acc_p7Y3C = np.hstack([acc_p7Y3C, np.array(mx_Y3_UCDC[1]).flatten()])
    acc_p8Y3C = np.hstack([acc_p8Y3C, np.array(mx_Y3_UCDC[2]).flatten()])
    acc_p9Y3C = np.hstack([acc_p9Y3C, np.array(mx_Y3_UCDC[3]).flatten()])
    acc_p10Y3C = np.hstack([acc_p10Y3C, np.array(mx_Y3_UCDC[4]).flatten()])
    acc_p11Y3C = np.hstack([acc_p11Y3C, np.array(mx_Y3_UCDC[5]).flatten()])
# ---------------------------
# データを結合して単位空間を生成する
# Y1類の場合
mx_Xs_Y1A  = np.vstack([acc_p0Y1A, acc_p1Y1A, acc_p2Y1A, acc_p3Y1A, acc_p4Y1A, acc_p5Y1A, acc_p6Y1A, acc_p7Y1A, acc_p8Y1A, acc_p9Y1A, acc_p10Y1A, acc_p11Y1A])
mx_Xs_Y1B  = np.vstack([acc_p0Y1B, acc_p1Y1B, acc_p2Y1B, acc_p3Y1B, acc_p4Y1B, acc_p5Y1B, acc_p6Y1B, acc_p7Y1B, acc_p8Y1B, acc_p9Y1B, acc_p10Y1B, acc_p11Y1B])
mx_Xs_Y1C  = np.vstack([acc_p0Y1C, acc_p1Y1C, acc_p2Y1C, acc_p3Y1C, acc_p4Y1C, acc_p5Y1C, acc_p6Y1C, acc_p7Y1C, acc_p8Y1C, acc_p9Y1C, acc_p10Y1C, acc_p11Y1C])
# -----
# Y2類の場合
mx_Xs_Y2A  = np.vstack([acc_p0Y2A, acc_p1Y2A, acc_p2Y2A, acc_p3Y2A, acc_p4Y2A, acc_p5Y2A, acc_p6Y2A, acc_p7Y2A, acc_p8Y2A, acc_p9Y2A, acc_p10Y2A, acc_p11Y2A])
mx_Xs_Y2B  = np.vstack([acc_p0Y2B, acc_p1Y2B, acc_p2Y2B, acc_p3Y2B, acc_p4Y2B, acc_p5Y2B, acc_p6Y2B, acc_p7Y2B, acc_p8Y2B, acc_p9Y2B, acc_p10Y2B, acc_p11Y2B])
mx_Xs_Y2C  = np.vstack([acc_p0Y2C, acc_p1Y2C, acc_p2Y2C, acc_p3Y2C, acc_p4Y2C, acc_p5Y2C, acc_p6Y2C, acc_p7Y2C, acc_p8Y2C, acc_p9Y2C, acc_p10Y2C, acc_p11Y2C])
# -----
# Y3類の場合
mx_Xs_Y3A  = np.vstack([acc_p0Y3A, acc_p1Y3A, acc_p2Y3A, acc_p3Y3A, acc_p4Y3A, acc_p5Y3A, acc_p6Y3A, acc_p7Y3A, acc_p8Y3A, acc_p9Y3A, acc_p10Y3A, acc_p11Y3A])
mx_Xs_Y3B  = np.vstack([acc_p0Y3B, acc_p1Y3B, acc_p2Y3B, acc_p3Y3B, acc_p4Y3B, acc_p5Y3B, acc_p6Y3B, acc_p7Y3B, acc_p8Y3B, acc_p9Y3B, acc_p10Y3B, acc_p11Y3B])
mx_Xs_Y3C  = np.vstack([acc_p0Y3C, acc_p1Y3C, acc_p2Y3C, acc_p3Y3C, acc_p4Y3C, acc_p5Y3C, acc_p6Y3C, acc_p7Y3C, acc_p8Y3C, acc_p9Y3C, acc_p10Y3C, acc_p11Y3C])
# 結果をテキストに出力する
print("mx_Xs_Y2A.shape: ", mx_Xs_Y2A.shape)

#=================================================
# MAIN PROGRAM(11) : 逆行列を計算する
#=================================================
# 項目数（SN比6件　x 2: LCR/UCD）
max_iRow_items = 12

# -----
# 単位空間のマハラノビス計算用データ（分散共分散行列）を生成する
def calc_tanimx(mx_Xs_tani): 
    arr_Xs_tani = []
    for kItem in range(max_iRow_items):
        # 中央値を計算する
        mean_X_tani = np.mean(mx_Xs_tani[kItem, :])
        arr_Xs_tani.append(mean_X_tani)
    #print("---- arr_Xs_tani ----")
    #print(arr_Xs_tani)
    # ------------------
    # 単位空間を用いた学習(1) : 分散共分散行列を計算する
    cov = np.cov(mx_Xs_tani)
    # 分散共分散行列の逆行列を計算する
    cov_i = np.linalg.pinv(cov)
    #print("---- cov_i ----")
    #print(cov_i)
    
    return arr_Xs_tani, cov_i

# ---------------------------
# CSVファイルに出力する(相関逆行列)
# ---------------------------
# Y1類の場合
arr_Xs_Y1A, cov_iY1A = calc_tanimx(mx_Xs_Y1A)
arr_Xs_Y1B, cov_iY1B = calc_tanimx(mx_Xs_Y1B)
arr_Xs_Y1C, cov_iY1C = calc_tanimx(mx_Xs_Y1C)
# -----
# Y2類の場合
arr_Xs_Y2A, cov_iY2A = calc_tanimx(mx_Xs_Y2A)
arr_Xs_Y2B, cov_iY2B = calc_tanimx(mx_Xs_Y2B)
arr_Xs_Y2C, cov_iY2C = calc_tanimx(mx_Xs_Y2C)
# -----
# Y3類の場合
arr_Xs_Y3A, cov_iY3A = calc_tanimx(mx_Xs_Y3A)
arr_Xs_Y3B, cov_iY3B = calc_tanimx(mx_Xs_Y3B)
arr_Xs_Y3C, cov_iY3C = calc_tanimx(mx_Xs_Y3C)
print(arr_Xs_Y2A)
print(cov_iY2A)

#=================================================
# MAIN PROGRAM(12) : CSVファイルに学習結果を出力する
#=================================================
# OUT CSV FUNCTION(12-1)
#=================================================
# CSVファイルに出力する(分散共分散逆行列)
def save_invcorr(mx_result, code_invcorr): 

    # データフレームを作成
    arr_index = list(range(max_iRow_items))
    arr_columns = list(range(max_iRow_items))
    df_metrics = pd.DataFrame(mx_result, index=arr_index, columns=arr_columns)
    #print("------------ 分散共分散逆行列のデータフレーム -------------")  
    #print(df_metrics) 
    # CSV ファイル (Rtm_covYX.csv) として出力
    file_csvout = foldername + code_invcorr + ".csv" # ファイルパス名の生成
    df_metrics.to_csv(file_csvout)
    print("CSVファイルの出力完了 : {}".format(file_csvout)) 
    
    return df_metrics

# ---------------------------
# CSVファイルに出力する(相関逆行列)
# ---------------------------
# Y1類の場合
save_invcorr(cov_iY1A, "Rtm_covY1A")
save_invcorr(cov_iY1B, "Rtm_covY1B")
save_invcorr(cov_iY1C, "Rtm_covY1C")
# -----
# Y2類の場合
save_invcorr(cov_iY2A, "Rtm_covY2A")
save_invcorr(cov_iY2B, "Rtm_covY2B")
save_invcorr(cov_iY2C, "Rtm_covY2C")
# -----
# Y3類の場合
save_invcorr(cov_iY3A, "Rtm_covY3A")
save_invcorr(cov_iY3B, "Rtm_covY3B")
save_invcorr(cov_iY3C, "Rtm_covY3C")

#=================================================
# OUT CSV FUNCTION(12-2)
#=================================================
# CSVファイルに出力する(単位空間の中心)
def save_taniXs(mx_result, code_taniXs): 

    # ---------------------------
    # データフレームを作成
    arr_columns = list(range(max_iRow_items))
    df_metrics = pd.DataFrame(mx_result, columns=arr_columns)
    #print("------------ 単位空間の中心のデータフレーム -------------")  
    #print(df_metrics) 
    # CSV ファイル (Rtm_aveYX.csv) として出力
    file_csvout = foldername + code_taniXs + ".csv" # ファイルパス名の生成
    df_metrics.to_csv(file_csvout)
    print("CSVファイルの出力完了 : {}".format(file_csvout)) 
    
    return df_metrics

# ---------------------------
# CSVファイルに出力する(単位空間の中心)
# ---------------------------
# Y1類の場合
save_taniXs([arr_Xs_Y1A], "Rtm_aveY1A")
save_taniXs([arr_Xs_Y1B], "Rtm_aveY1B")
save_taniXs([arr_Xs_Y1C], "Rtm_aveY1C")
# -----
# Y2類の場合
save_taniXs([arr_Xs_Y2A], "Rtm_aveY2A")
save_taniXs([arr_Xs_Y2B], "Rtm_aveY2B")
save_taniXs([arr_Xs_Y2C], "Rtm_aveY2C")
# -----
# Y3類の場合
save_taniXs([arr_Xs_Y3A], "Rtm_aveY3A")
save_taniXs([arr_Xs_Y3B], "Rtm_aveY3B")
save_taniXs([arr_Xs_Y3C], "Rtm_aveY3C")

```

QEU:FOUNDER ： “学習した結果が、**「単位空間ベクトル」と「分散共分散行列」の形**で出てきました。”

![imageRL2-7-3](/2022-06-20-QEUR21_SOART5/imageRL2-7-3.jpg)

D先生 ： “今回はこの程度しか説明できません。次回から特徴量マップによる性能評価になります。つきましてはカンパください！！”

### [＞寄付のお願い(Donate me)＜](https://www.paypal.com/paypalme/QEUglobal?v=1&utm_source=unp&utm_medium=email&utm_campaign=RT000481&utm_unptid=29844400-7613-11ec-ac72-3cfdfef0498d&ppid=RT000481&cnac=HK&rsta=en_GB%28en-HK%29&cust=5QPFDMW9B2T7Q&unptid=29844400-7613-11ec-ac72-3cfdfef0498d&calc=f860991d89600&unp_tpcid=ppme-social-business-profile-creat-ed&page=main%3Aemail%3ART000481&pgrp=main%3Aemail&e=cl&mchn=em&s=ci&mail=sys&appVersion=1.71.0&xt=104038)

QEU:FOUNDER ：“よろしくお願いします。”

## ～　まとめ　～

### ・・・　前回のつづきです　・・・

D先生 : “自分が相手より上か下かを判別し、上だと判断すると搾取する。しかし、まあ下品な搾取だこと・・・。しかも公衆の面前で・・・。上に立つ人（オッサン）がこんなレベルだから、ハラスメント（↑）が国中にはびこるんですよ。”

![imageRL2-7-4](/2022-06-20-QEUR21_SOART5/imageRL2-7-4.jpg)

C部長 : “我々が注目しているイケメン勢力に頑張っていただくしかないですね。”

![imageRL2-7-5](/2022-06-20-QEUR21_SOART5/imageRL2-7-5.jpg)

QEU:FOUNDER ： “より良い人に政治を任せることも大事・・・。でも、それ以上に重要なことは**「各個人が考え方とか行動様式を変えること」**じゃないのか？”

![imageRL2-7-6](/2022-06-20-QEUR21_SOART5/imageRL2-7-6.jpg)

C部長 : “ボクになんかしろって、いわれても・・・・。”

![imageRL2-7-7](/2022-06-20-QEUR21_SOART5/imageRL2-7-7.jpg)

D先生 : “**不要なハラスメントをやめれば？**・・・思えてる？この大事件（↑）を・・・。2010年にC国の某大企業で〇殺が相次いだ事件・・・。だれが悪いとは言わない。でもハラスメントが一因であることは間違いないだろう。その会社は、その後工程の自動化を推し進め、**現在のindustry5.0をけん引する「協働ロボット(cobot: collaborative robot)」の概念を発明しました**。C国のほうがＪ国よりもよっぽど立派・・・。だから、これほど差がついた・・・。”

![imageRL2-7-8](/2022-06-20-QEUR21_SOART5/imageRL2-7-8.jpg)

C部長 : “うちのような小さな会社がこんな大それたことを・・・。”

D先生 : “**外観検査自動機を導入することぐらいはできるでしょ？**システムの「ひな形」は我々が作ったので、それを自分らで改良して・・・。工場では検査作業と不良流出がハラスメントのきっかけになることをしっているでしょ？”

![imageRL2-7-9](/2022-06-20-QEUR21_SOART5/imageRL2-7-9.jpg)

C部長 : “そりゃそうですが・・・。他にも、もっと大規模なハラスメント（↑）があったわけで・・・。”

![imageRL2-7-10](/2022-06-20-QEUR21_SOART5/imageRL2-7-10.jpg)

QEU:FOUNDER ： “**そんなハラスメント性を含んだメディアは見なけりゃ良い**。そして、自分のやれることをがんばる。我々も初心を曲げずに継続してきたからこそ、「ここまで」来たんだから・・・。”
