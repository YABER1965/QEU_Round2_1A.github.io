---
title: QEUR21_SOART1:　予備実験～SOARTメトリックスを使ってみる（その1）
date: 2022-06-17
tags: ["QEUシステム", "メトリックス", "Python言語", "機械学習", "マハラノビス距離", "DX", "Blender", "SOART法", "異常判別"]
excerpt: Python言語とSOART法を使った異常判別
---

## QEUR21_SOART1:　予備実験～SOARTメトリックスを使ってみる（その1）

## ～　これ・・・、いったい何の役に立つの？　～

D先生 ： “それでは、SOART メトリックスを使ってみましょう。さっき準備をしていたら、うまいことに前回の新RT法の開発時の実験データが残っていました。“

![imageRL2-3-1](/2022-06-17-QEUR21_SOART1/imageRL2-3-1.jpg)

QEU:FOUNDER ： “ラッキー！Blender（3Dレンダー）のセッティングを説明せずに始められますね。”

![imageRL2-3-2](/2022-06-17-QEUR21_SOART1/imageRL2-3-2.jpg)

QEU:FOUNDER ： “それではプログラムをドン！！”

```python
# -------------------- プログラムの始まり -------------------
# -*- coding: utf-8 -*-
# filename: soaRT_create_metrics.py
# primRT, newRT, soaRTメトリックスの生成(種別差異)
# ---------------------------------------------------
# ライブラリをインポートする
import cv2
from fastai.vision.all import *
import seaborn as sns
import pandas as pd
import numpy as np
import joblib
from scipy.spatial import distance
import matplotlib.pyplot as plt

#=================================================
# READ CSV_FILE FUNCTION
#=================================================
# TS画像ファイルを読んで、TSテンソルを出力する
def read_TSpics(pic_tani, pic_signal): 

    # ------------------
    # 標準画像(Tani)
    filename = foldername + pic_tani
    img_tani = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)
    # リサイズ
    img_rezTani = cv2.resize(img_tani , newsize)

    # ------------------
    # 信号画像(Signal)
    filename = foldername + pic_signal
    img_signal = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)
    # リサイズ
    img_rezSig = cv2.resize(img_signal , newsize)

    # ------------------
    # 画像データのテンソル化(T,S)
    img_tensorT = tensor(1.0-img_rezTani/255)  # 標準画像(ポジ変換)
    img_tensorS = tensor(1.0-img_rezSig/255)  # 信号画像(ポジ変換)
    
    return img_tensorT, img_tensorS

# ---------------------------
# newRTメトリックスを計算する(テンソル活用版)
def calc_newRT(len_temp, max_jy_index, tsr_sig_matrix, tsr_tani_array): 

    # ---------------------------
    # 変数の初期化
    L1_loss = torch.nn.L1Loss()
    btY1_yarray, Y2_yarray = [], []

    # 繰り返し
    for i in range(len_temp):

        y = tsr_sig_matrix[i]
        x = tsr_tani_array

        # 回転を計測
        xx = torch.dot(x,x)
        xy = torch.dot(x,y)
        beta = xy/xx
        #print("i:{}, beta:{}".format(i,beta))

        # 全ひずみを計測
        mDistance   = L1_loss(y, beta*x)
        #print("i:{}, beta:{}".format(i,beta))
        #print("mDistance: ", mDistance.item())
        #print("yres:{}".format(yres))
        
        btY1_yarray.append(beta)
        Y2_yarray.append(mDistance.item())

    return btY1_yarray, Y2_yarray

# ---------------------------
# soaRTメトリックスを計算する(テンソル活用版)
def calc_soaRT(len_temp, max_jy_index, tsr_sig_matrix, tsr_tani_array): 

    # ---------------------------
    # 変数の初期化
    L1_loss  = torch.nn.L1Loss()
    tsr_zero = torch.zeros(max_jy_index)
    btY1_yarray, Y2_yarray, Y3_yarray = [], [], []

    # 繰り返し
    for i in range(len_temp):

        x = tsr_tani_array
        y = tsr_sig_matrix[i]

        # 回転を計測
        xx = torch.dot(x,x)
        xy = torch.dot(x,y)
        beta = xy/xx
        #print("i:{}, beta:{}".format(i,beta))

        # 体積ひずみを計測
        vol_xtani = L1_loss(beta*x, tsr_zero)
        vol_ysig  = L1_loss(y, tsr_zero)
        ratio_vol = vol_ysig/vol_xtani

        # せん断ひずみを計測
        mDistance   = L1_loss(y, beta*ratio_vol*x)
        #print("mDistance: ", mDistance.item())
        #print("yres:{}".format(yres))
        
        btY1_yarray.append(beta.item())
        Y2_yarray.append(ratio_vol.item())
        Y3_yarray.append(mDistance.item())

    return btY1_yarray, Y2_yarray, Y3_yarray

# ---------------------------
# primitiveRTメトリックスを計算する(テンソル活用版)
def calc_RTmetrics(len_temp, max_jy_index, tsr_sig_matrix, tsr_tani_array): 

    # ---------------------------
    # 変数の初期化
    lnr_yarray, btY1_yarray = [], []
    st_yarray, sb_yarray, se_yarray, ve_yarray = [], [], [], []
    yita_yarray, Y2_yarray = [], []

    # 有効除数の計算
    yuko = torch.dot(tsr_tani_array, tsr_tani_array)

    # 線形式の計算
    for i in range(len_temp):
        lnr_yitem  = torch.dot(tsr_sig_matrix[i], tsr_tani_array)
        btY1_yitem = lnr_yitem / yuko
        lnr_yarray.append(lnr_yitem.item())
        btY1_yarray.append(btY1_yitem.item())

    # 全変動ST及び各種中間指標SB,SE,VE,η
    for i in range(len_temp):
        sum_item  = torch.dot(tsr_sig_matrix[i], tsr_sig_matrix[i])
        st_yarray.append(sum_item.item())
        sb_yarray.append(lnr_yarray[i] ** 2 / yuko.item())
        se_yarray.append(st_yarray[i] - sb_yarray[i])

        # 異常処理
        temp_ve = se_yarray[i] / float(max_jy_index - 1.0)
        if temp_ve < 0.0000001:
            #comment = 'ゼロ異常発生！！'
            #print(comment)
            ve_yarray.append(-1.0)   
            yita_yarray.append(-1.0)  
            Y2_yarray.append(-1.0) 
        else:
            temp_Y2 = math.sqrt(temp_ve)
            ve_yarray.append(temp_ve)   
            yita_yarray.append(1.0 / temp_ve)  
            Y2_yarray.append(temp_Y2) 

    return btY1_yarray, Y2_yarray

#=================================================
# MAIN PROGRAM(1) : 読み込み画像の対象を設定する
#=================================================
# 読み込み先の指定
foldername = "./ARRAY_RTCNN/"
newsize = (900, 500)
# -----
# RTベクトル長と信号空間長
rmax_jy_idx, len_rmx  = newsize[0]*newsize[1], 6

# 信号空間画像(計測ベクトル)
arr_nmSignal = ["NA"]*len_rmx
arr_nmSignal[0] = "camera1_1_0_0_89_0_0_0_square.png"
arr_nmSignal[1] = "camera1_1_0_0_89_0_0_1_circle.png"
arr_nmSignal[2] = "camera1_1_0_0_89_0_0_2_triangle.png"
arr_nmSignal[3] = "camera1_1_0_0_89_0_0_3_rectangle.png"
arr_nmSignal[4] = "camera1_1_0_0_89_0_0_4_pentagon.png"
arr_nmSignal[5] = "camera1_1_0_0_89_0_0_5_bevelsq.png"

# 単位空間画像(標準ベクトル)
pic_tani = "average_square.png"     # NO0
#pic_tani = "average_circle.png"    # NO1
#pic_tani = "average_triangle.png"  # NO2
#pic_tani = "average_rectangle.png" # NO3
#pic_tani = "average_pentagon.png"  # NO4
#pic_tani = "average_bevelsq.png"   # NO5

# initialise
metrics_cos = torch.nn.CosineSimilarity(dim=0)
L1_loss     = torch.nn.L1Loss()
arr_cos     = []
arr_dist    = []

# -----
# メトリックスの画像毎の繰り返し
for i in range(len_rmx):

    #=================================================
    # MAIN PROGRAM(2) : 画像をテンソル化する(T,S)
    #=================================================
    # TS画像ファイルを読んで、TSテンソルを出力する
    img_tensorT, img_tensorS = read_TSpics(pic_tani, arr_nmSignal[i])
    #print(img_tensorS)

    #=================================================
    # MAIN PROGRAM(3) : 畳み込みRTメトリックスを実行する
    #=================================================
    # ベクトル化
    img_arrayT = img_tensorT.flatten()
    #print(img_arrayT)
    img_arrayS = img_tensorS.flatten()
    # -----
    # コサイン類似度とマンハッタン距離
    cSimilarity = metrics_cos(img_arrayS, img_arrayT)
    #print("cSimilarity: ", cSimilarity.item())
    mDistance = L1_loss(img_arrayS, img_arrayT)
    #print("mDistance: ", mDistance.item())
    # -----
    arr_cos.append(cSimilarity.item())
    arr_dist.append(mDistance.item())
    if i == 0:
        img_mxS = img_arrayS
    else:
        img_mxS = torch.vstack((img_mxS, img_arrayS))
# ------
# RTメトリックスを生成する
btY1_Parray, Y2_Parray = calc_RTmetrics(len_rmx, rmax_jy_idx, img_mxS, img_arrayT)
btY1_Narray, Y2_Narray = calc_newRT(len_rmx, rmax_jy_idx, img_mxS, img_arrayT)
btY1_Sarray, Y2_Sarray, Y3_Sarray = calc_soaRT(len_rmx, rmax_jy_idx, img_mxS, img_arrayT)
# ---------------------------
# メトリックスの計算結果を出力する
print("btY1_Narray: ", btY1_Narray)
print("Y2_Narray: ", Y2_Narray)
print("btY1_Sarray: ", btY1_Sarray)
print("Y2_Sarray: ", Y2_Sarray)
print("Y3_Sarray: ", Y3_Sarray)

#=================================================
# MAIN PROGRAM(4) : CSVファイルに出力する
#=================================================
#print(arr_nmSignal)
#print(btY1_yarray)
#print(Y2_yarray)
mx_temp = np.vstack([arr_nmSignal, btY1_Parray, Y2_Parray, btY1_Narray, Y2_Narray, btY1_Sarray, Y2_Sarray, Y3_Sarray, arr_cos, arr_dist])
mx_output = mx_temp.T
#print(mx_output)

# データフレームを作成
arr_columns = ["picname", "primY1", "primY2", "newY1", "newY2", "soaY1", "soaY2", "soaY3", "cos", "dist"]
df_metrics = pd.DataFrame(mx_output, columns=arr_columns)
print("------------ primitiveRTメトリックスのデータフレーム -------------")  
print(df_metrics) 

## CSV ファイル (soaRT_{}.csv.csv) として出力
file_csvout = foldername + "soaRT_{}.csv".format(pic_tani.replace(".png","")) # ファイルパス名の生成
df_metrics.to_csv(file_csvout)
print("CSVファイルの出力完了 : {}".format(file_csvout)) 

```

QEU:FOUNDER ： “SOART法の計算は関数になっています。このコード（↓）を読めば、「ノリ」がわかります。”

![imageRL2-3-3](/2022-06-17-QEUR21_SOART1/imageRL2-3-3.jpg)

D先生 ： “なるほど、こういう風に計算しているんですか・・・。**新RT法の原理に「体積ひずみ」の計算を付け加えた感じ**ですね。”

**（新RT法の原理）**

![imageRL2-3-4](/2022-06-17-QEUR21_SOART1/imageRL2-3-4.jpg)

**（新RT法の計算ロジック）**

![imageRL2-3-5](/2022-06-17-QEUR21_SOART1/imageRL2-3-5.jpg)

QEU:FOUNDER ： “それでは、計測した物体形状を変えた場合のSOARTメトリックスの特性を見てみましょう。”

![imageRL2-3-6](/2022-06-17-QEUR21_SOART1/imageRL2-3-6.jpg)

D先生 ： “なんだ・・・、新RT法とSOART法は変わらないじゃないですか・・・。”

QEU:FOUNDER ： “次は物体を移動させて、メトリックスを計測してみた。対象は円形(circle)ね・・・。”

![imageRL2-3-7](/2022-06-17-QEUR21_SOART1/imageRL2-3-7.jpg)

D先生 ： “これも、新RT法とSOART法は変わらないです。じゃあ・・・、回転は？”

![imageRL2-3-8](/2022-06-17-QEUR21_SOART1/imageRL2-3-8.jpg)

D先生 ： “これも同じじゃないですか！！じゃあ、SOARTメトリックスの「ご利益」って、何なんですか！！”

![imageRL2-3-9](/2022-06-17-QEUR21_SOART1/imageRL2-3-9.jpg)

QEU:FOUNDER ： “今回の事例では「垂直ひずみ」を使いこなせなかったんです。「データの体積」に変化がなかったから・・・。”

**(新RT法の変動分解)**

### データ差異（標準-計測） → Y1（回転）　+　Y2（全ひずみ）

**(SOART法の変動分解)**

### データ差異（標準-計測） → Y1（回転）　+　Y2（垂直ひずみ）　+　Y3（せん断ひずみ）

QEU:FOUNDER ： “・・・というわけで、次回につづく。”

## ～　まとめ　～

C部長 : “いよいよヒートアップしてきたイケメン・バトルだ・・・！！”

![imageRL2-3-10](/2022-06-17-QEUR21_SOART1/imageRL2-3-10.jpg)

C部長 : “バトルカードの提出をお願いします。・・・というか、このワタシがドン！！”

[![MOVIE1](http://img.youtube.com/vi/bB3exJzNORs/0.jpg)](http://www.youtube.com/watch?v=bB3exJzNORs "【街宣LIVE】水道橋博士 東京都・中野駅北口（2022年6月16日）")

D先生 : “コレ・・・、演説やってるの？・・・それとも、路上で「芸」やっているの？”

QEU:FOUNDER ： “**新境地を開きつつある**んじゃないでしょうか・・・。”
