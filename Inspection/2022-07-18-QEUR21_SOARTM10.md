---
title: QEUR21_SOARTM10 – Automatic visual inspection method using RT-Multi-method (SOART method)
date: 2022-07-18
tags: ["QEUシステム", "メトリックス", "Python言語", "機械学習", "マハラノビス距離", "DX", "Blender", "SOART法", "異常判別"]
excerpt: Python言語とSOART法を使った異常判別
---

## QEUR21_SOARTM10 – Automatic visual inspection method using RT-Multi-method (SOART method)

### [Technology field]
This invention relates to a method used to automate visual inspection by modifying the RT-Multi-method. The invention is hereinafter referred to as SOART method.


### [Technology background]
AOI (Automatic Optical Inspection) machines are getting popular for visual inspection of "highly transferable products" such as PCBs. Its concept is to compare standard image with measured one to detect differences (Fig. 1).


**(Fig. 1: Defect detection by image comparison)**

![imageRL3-30-1](/2022-07-18-QEUR21_SOARTM9/imageRL3-30-1.jpg)

On the other hand, the Taguchi Methods's MTS (Mahalanobis-Taguchi System) is applied to inspect special defect events that cannot be detected by conventional AOI machines The MTS (Mahalanobis-Taguchi System) of the Taguchi Methods is applied to inspect special defects that cannot be detected by conventional AOI machines (Fig. 2). Its concept is to calculate the variance-covariance matrix of the pattern information measured from the passed products as a "unit space" to calculate the distance from the center of its unit space. MTS is simply a framework for numerical processing, and no special "feature-engineering" method has been proposed for application to visual inspection.


**(Fig. 2: Mahalanobis-Taguchi System)**

![imageRL3-30-2](/2022-07-18-QEUR21_SOARTM9/imageRL3-30-2.jpg)

**(Fig. 3: Definition of Mahalanobis Distance)**

![imageRL3-30-3](/2022-07-18-QEUR21_SOARTM9/imageRL3-30-3.jpg)

Recent development in deep learning technology have dramatically improved the accuracy of image discrimination. CNN (Convolutional Neural Network) is especially considered a promising method. However, CNN is not only computationally expensive but also it spends high training costs. In many cases, the cost and benefits would not be balanced for use in a system for a specific product in a factory, let alone for general-purpose applications such as automated driving. 


**(Fig. 4: Convolutional Neural Networks,CNN)**

![imageRL3-30-4](/2022-07-18-QEUR21_SOARTM9/imageRL3-30-4.jpg)


### [Problems to be solved by this invention]

Many AOI machines have very strict control over light sources. This is because without strict control of the light source, the highly accurate 2D and 3D information necessary for anomaly determination cannot be obtained (Fig. 5).


**(Fig. 5: Automatic Visual inspection Technology)**

![imageRL3-30-5](/2022-07-18-QEUR21_SOARTM9/imageRL3-30-5.jpg)

However, visual inspections performed by humans in manufacturing workshop are not so tightly controlled. Due to technical, cost, or other constraints, most products cannot be precisely fixtured, and light sources controlled. Wire harness (Fig. 6) is shown as an example.


**(Fig. 6: Wire Harness)**

![imageRL3-30-6](/2022-07-18-QEUR21_SOARTM9/imageRL3-30-6.jpg)

The extremely large number of defective modes are detected in visual inspection, and their inspection know-how are different each other. Therefore, it is very time-consuming and costly to train an automatic inspection system onsite, by using actual products.

However, since inspection work is a process that does not add value to the product, it is necessary to reduce costs as much as possible from a managerial standpoint. Since most automated machines use preset programmable logic controllers (PLCs) developed in the 1980s, it is optimal to be able to inspect them with an equivalent computer. Figure 7 shows an example of a commercial PLC made with a Raspberry Pi or Arduino, a one-board computer that is widely used in industry as of 2020.


**(Fig. 7: Example of PLC using a one-board PC)**

![imageRL3-30-7](/2022-07-18-QEUR21_SOARTM9/imageRL3-30-7.jpg)

One-board computers are not only inexpensive but also they have low power consumption, which can reduce costs if applied to automated inspections.


### [Means to solve problems]

SOART method modifies the RT Multi-method, one of the Taguchi methods, and uses the convolutional RT method and the Mahalanobis distance together to compute features. Whereas, RT method compares the standard vector quantity with the measurement vector quantity in a multivariate analysis and outputs two metrics: sensitivity, which indicates the amount of image rotation, and SN ratio, which indicates distortion (Fig. 8). Figure 9 shows a flow diagram of SOART method.


**(Fig. 8: Concept of RT Metrics)**

![imageRL3-30-8](/2022-07-18-QEUR21_SOARTM9/imageRL3-30-8.jpg)

**(Fig. 9: SOART method calculation flow chart)**

![imageRL3-30-9](/2022-07-18-QEUR21_SOARTM9/imageRL3-30-9.jpg)

SN ratio of SOART method uses the Manhattan distance. The conventional RT method uses the Euclidean distance. When using a computer program, the programming effort and computation time are the same whether Manhattan distance or Euclidean distance is used, and Manhattan distance has higher recognition accuracy. The Euclidean distance uses the sum of squares of the data, so if there are a few large values can raise the value of metrics. On the other hand, the Manhattan distance uses absolute value sums, so the metrics will respond to features with small values.


**(Fig. 10: Manhattan Distance Concept)**

![imageRL3-30-10](/2022-07-18-QEUR21_SOARTM9/imageRL3-30-10.jpg)

The first step of RT metrics calculation of the SOART method outputs a "data volume ratio" instead of sensitivity. This introduces the concept of material mechanics. If the difference obtained by comparing the standard vector and the measurement vector is considered as the total strain, the total strain can be divided into "strain with volume change (volume ratio)" and "strain with no volume change (shear strain).


**(Fig. 11: Strain decomposition in materials mechanics)**

![imageRL3-30-11](/2022-07-18-QEUR21_SOARTM9/imageRL3-30-11.jpg)

When the volume ratio changes in image data, there are two cases: "when the color (brightness) changes" and "when the size (of the figure) changes" (Fig. 12). The results of the case study experiment are shown in Figure 13.


**(Fig. 12: Change in volume ratio of data)**

![imageRL3-30-12](/2022-07-18-QEUR21_SOARTM9/imageRL3-30-12.jpg)

**(Fig. 13: Case Study Results)**

![imageRL3-30-13](/2022-07-18-QEUR21_SOARTM9/imageRL3-30-13.jpg)

The second stage of RT metrics calculation uses convolution. Here, the convolution is applied with components arbitrarily adopted by the user. Whereas, bend systems (4 types), line systems (2 types), and datum systems (2 types) (Fig. 14 and 15) are defined. Datum system parts are synthesized for calculation.


**(Fig. 14: Convolution parts – Bend series)**

![imageRL3-30-14](/2022-07-18-QEUR21_SOARTM9/imageRL3-30-14.jpg)

**(Fig. 15: Convolutional parts - line and datum series)**

![imageRL3-30-15](/2022-07-18-QEUR21_SOARTM9/imageRL3-30-15.jpg)

The RT-Multi-method divides the image (data) into sub-data, calculates the lower RT metrics from each of the sub-data, and then reintegrates these metrics to calculate the upper RT metrics (Fig. 16).


**(Fig. 16: Multi-method)**

![imageRL3-30-16](/2022-07-18-QEUR21_SOARTM9/imageRL3-30-16.jpg)

There is an inherent problem with the traditional RT Multi-method approach: the sensitivity metrics output by RT method indicates image rotation. The sensitivity (amount of rotation) of the segmented sub-image A as well as the sensitivity of the segmented image B will necessarily be of the same magnitude. In other words, there is waste in the multi-method metrics in the image. Therefore, in the calculation of the lower RT metrics, the volume ratio metric, which responds to the brightness and size of the image, is used instead of the sensitivity metric.


### [Example_1]

In this case study, we experiment with a case of connector terminal inspection in a wire harness (Fig. 17). Blender which is a widely popular 3D rendering software (Fig. 18) is used instead of a real test.


**(Fig. 17: Connector terminal inspection)**

![imageRL3-30-17](/2022-07-18-QEUR21_SOARTM9/imageRL3-30-17.jpg)

**(Fig. 18: Workspace of Blender)**

![imageRL3-30-18](/2022-07-18-QEUR21_SOARTM9/imageRL3-30-18.jpg)

The connector is used one with 3 vertical x 9 horizontal PINs, and the pin numbers are defined as shown in Figure 19. The standard information was created from the average of 20 images in which only the brightness of the light was changed. In the first stage of RT metrics calculation, the unit space was 50 images with the brightness of the lights and the rotation and movement of the workpiece added. The distribution of the scatter plots displayed as Y2 for the volume ratio and Y3 for SN ratio is shown in Figure 20.


**(Fig. 19: Pin number and standard image)**

![imageRL3-30-19](/2022-07-18-QEUR21_SOARTM9/imageRL3-30-19.jpg)

**(Fig. 20: Relationship between volume ratio (Y2) and SN ratio (Y3))**

![imageRL3-30-20](/2022-07-18-QEUR21_SOARTM9/imageRL3-30-20.jpg)

According to the above figure, the distribution shape of Y2-Y3 metrics is so complex that it is not a simple elliptical distribution which 2D Mahalanobis distance assumes. However, it seems that the Mahalanobis distance is enough to compensate for noise of brightness (Y2) to some extent. Therefore, to calculate the Mahalanobis distance, a variance-covariance matrix was calculated for each pin and graphed (Fig. 21).


**(Fig. 21: Variation of variance and covariance for each pin)**

![imageRL3-30-21](/2022-07-18-QEUR21_SOARTM9/imageRL3-30-21.jpg)

An example of a heatmap image of the distribution of Mahalanobis distances at a pin is shown in Figure 22. Whereas, when calculating the lower Mahalanobis distance, the measurement target is corrected to a positive value and the background is corrected to a value close to zero. The large difference between the background values of the right and left pins in the figure is due to the fact that the unit space used for each pin is different, and only the value for the pin in question is actually used.


**(Fig. 22: Distribution of Lower Mahalanobis Distance)**

![imageRL3-30-22](/2022-07-18-QEUR21_SOARTM9/imageRL3-30-22.jpg)

Even after the second stage of computation of the convolutional RT metrics, the (upper) Mahalanobis distance is computed in the same way. Whereas three unit spaces (left - center - right) are applied. The mean vector and variance-covariance matrix are 6-dimensional (Fig. 23), because the convolution RT metrics for the bend (4-dimensional) and line (2-dimensional) systems are output.


**(Fig. 23: Mean vector and variance-covariance matrix)**

![imageRL3-30-23](/2022-07-18-QEUR21_SOARTM9/imageRL3-30-23.jpg)

After completion of the above training, a feature map is created by inputting any image. In the feature map, the Mahalanobis distance was calculated from the sensitivity and SN ratio of each pin, respectively. The feature map of a good connector is shown in Figure 24 and Figure 25.


**(Fig. 24: Feature Map of passed product, negative shift)**

![imageRL3-30-24](/2022-07-18-QEUR21_SOARTM9/imageRL3-30-24.jpg)

**(Fig. 25: Feature Map of passed product, negative shift)**

![imageRL3-30-25](/2022-07-18-QEUR21_SOARTM9/imageRL3-30-25.jpg)

The above figure shows that the sensitivity behavior of the feature map is correlated with workpiece movement. On the other hand, SN ratio is not affected by workpiece movement. In other words, SOART method eliminates the effects of light brightness and workpiece rotation and movement by adapting the Multi-method. As a result, SN ratio can detect the anomaly level of the workpiece only.

Next, let us experiment if we can detect when a pin is tilted to be defective. Figure 26 shows the case at pin address 3-1 and Figure 27 shows an anomaly case at address 4-1. looking at the distribution of SN ratio, the Mahalanobis distance value is higher at the PIN address where the defect occurred.

**(Fig. 26: Defective product, PIN address is 3-1)**

![imageRL3-30-26](/2022-07-18-QEUR21_SOARTM9/imageRL3-30-26.jpg)

**(Fig. 27: Defective product, PIN address is 4-1)**

![imageRL3-30-27](/2022-07-18-QEUR21_SOARTM9/imageRL3-30-27.jpg)

However, the sensitivity increases at the corners and SN ratio also increases as the workpiece rotates. The system must either learn by SVM (support vector machine) or apply other means to detect anomaly correctly, otherwise the user must accept over-detection. Of course, it would be most ideal to increase the accuracy of the jig that holds the workpiece to suppress rotation.

Finally, the feature map is shown as the case of defective mode in which the terminals are vertically retracted. It is originally impossible to detect terminal retraction by a single image. However, it can detect depending on the angle.

**(Fig. 28: Feature map, defective at PIN address 3-1, not detected)**

![imageRL3-30-28](/2022-07-18-QEUR21_SOARTM9/imageRL3-30-28.jpg)

**(Fig. 29: Feature map, defective at PIN address 3-1, detected.)**

![imageRL3-30-29](/2022-07-18-QEUR21_SOARTM9/imageRL3-30-29.jpg)

If depth is to be measured, an additional camera must be installed to apply **RT double-eye method (Fig. 30)**.

**(Fig. 30: Flow chart of RT double-eye method)**

![imageRL3-30-30](/2022-07-18-QEUR21_SOARTM9/imageRL3-30-30.jpg)


### [Industrial applicability]

SOART method can be used for all relatively simple visual inspections without higher precision. It requires lower hardware specification requirements and less training data than conventional methods. As a result, it is significantly less expensive to implement than conventional methods.

Furthermore, SOART method uses metrics to discriminate, which allows for abstraction. This means that digital twin can be used instead of the actual measurement to achieve quite high degree of accuracy (Fig. 31).


**(Fig. 31: Concept of Digital Twin)**

![imageRL3-30-31](/2022-07-18-QEUR21_SOARTM9/imageRL3-30-31.jpg)

Since a very simple system detects product abnormalities, detection accuracy may be slightly lower in some cases. However, since the reliability of visual inspection by humans is not that high (Fig. 32), the decision to introduce the system should be made after considering the balance with the cost of introduction.


**(Fig. 32: Performance of human visual inspection)**

![imageRL3-30-32](/2022-07-18-QEUR21_SOARTM9/imageRL3-30-32.jpg)


### [Supplement]

SOART method is an abbreviation for **“the state of art Recognition Taguchi method (the latest version of RT method)”**. Although the concept is from RT method of the Taguchi methods, it should be considered as a different method from the Taguchi method because many concepts have already left the Taguchi method.
